# Comparing `tmp/gpudb-7.1.9.1-cp39-cp39-win_amd64.whl.zip` & `tmp/gpudb-7.1.9.2-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,36 +1,36 @@
-Zip file size: 476196 bytes, number of entries: 34
--rw-rw-rw-  2.0 fat     2276 b- defN 23-Mar-22 09:25 gpudb/__init__.py
--rw-rw-rw-  2.0 fat  2193478 b- defN 23-Mar-22 09:25 gpudb/gpudb.py
--rw-rw-rw-  2.0 fat   178829 b- defN 23-Mar-22 09:25 gpudb/gpudb_multihead_io.py
--rw-rw-rw-  2.0 fat    76983 b- defN 23-Mar-22 09:25 gpudb/gpudb_table_monitor.py
--rw-rw-rw-  2.0 fat    82432 b- defN 23-Mar-22 09:27 gpudb/protocol.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat    33494 b- defN 23-Mar-22 09:25 gpudb/packages/enum34.py
--rw-rw-rw-  2.0 fat    40175 b- defN 23-Mar-22 09:25 gpudb/packages/kinetica_tabulate.py
--rw-rw-rw-  2.0 fat     4413 b- defN 23-Mar-22 09:25 gpudb/packages/ordereddict.py
--rw-rw-rw-  2.0 fat    14620 b- defN 23-Mar-22 09:25 gpudb/packages/pymmh3.py
--rw-rw-rw-  2.0 fat      543 b- defN 23-Mar-22 09:25 gpudb/packages/avro/__init__.py
--rw-rw-rw-  2.0 fat      860 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/__init__.py
--rw-rw-rw-  2.0 fat    12739 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/datafile.py
--rw-rw-rw-  2.0 fat    32986 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/io.py
--rw-rw-rw-  2.0 fat    18581 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/ipc.py
--rw-rw-rw-  2.0 fat     8181 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/protocol.py
--rw-rw-rw-  2.0 fat    25722 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/schema.py
--rw-rw-rw-  2.0 fat     5442 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/tool.py
--rw-rw-rw-  2.0 fat     8051 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py2/txipc.py
--rw-rw-rw-  2.0 fat      395 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/HandshakeRequest.avsc
--rw-rw-rw-  2.0 fat      537 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/HandshakeResponse.avsc
--rw-rw-rw-  2.0 fat        7 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/VERSION.txt
--rw-rw-rw-  2.0 fat     1423 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/__init__.py
--rw-rw-rw-  2.0 fat    15686 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/datafile.py
--rw-rw-rw-  2.0 fat    34387 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/io.py
--rw-rw-rw-  2.0 fat    23138 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/ipc.py
--rw-rw-rw-  2.0 fat    12321 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/protocol.py
--rw-rw-rw-  2.0 fat    36528 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/schema.py
--rw-rw-rw-  2.0 fat     5773 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/tool.py
--rw-rw-rw-  2.0 fat     8269 b- defN 23-Mar-22 09:25 gpudb/packages/avro/avro_py3/txipc.py
--rw-rw-rw-  2.0 fat     1104 b- defN 23-Mar-22 09:27 gpudb-7.1.9.1.dist-info/LICENSE
--rw-rw-rw-  2.0 fat      371 b- defN 23-Mar-22 09:27 gpudb-7.1.9.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-Mar-22 09:27 gpudb-7.1.9.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        6 b- defN 23-Mar-22 09:27 gpudb-7.1.9.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     3053 b- defN 23-Mar-22 09:27 gpudb-7.1.9.1.dist-info/RECORD
-34 files, 2882903 bytes uncompressed, 471266 bytes compressed:  83.7%
+Zip file size: 469199 bytes, number of entries: 34
+-rw-rw-rw-  2.0 fat     2276 b- defN 23-Apr-24 09:59 gpudb/__init__.py
+-rw-rw-rw-  2.0 fat  2157957 b- defN 23-Apr-24 09:59 gpudb/gpudb.py
+-rw-rw-rw-  2.0 fat   181209 b- defN 23-Apr-24 09:59 gpudb/gpudb_multihead_io.py
+-rw-rw-rw-  2.0 fat    76983 b- defN 23-Apr-24 09:59 gpudb/gpudb_table_monitor.py
+-rw-rw-rw-  2.0 fat    82432 b- defN 23-Apr-24 10:03 gpudb/protocol.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat    33494 b- defN 23-Apr-24 09:59 gpudb/packages/enum34.py
+-rw-rw-rw-  2.0 fat    40175 b- defN 23-Apr-24 09:59 gpudb/packages/kinetica_tabulate.py
+-rw-rw-rw-  2.0 fat     4413 b- defN 23-Apr-24 09:59 gpudb/packages/ordereddict.py
+-rw-rw-rw-  2.0 fat    14620 b- defN 23-Apr-24 09:59 gpudb/packages/pymmh3.py
+-rw-rw-rw-  2.0 fat      543 b- defN 23-Apr-24 09:59 gpudb/packages/avro/__init__.py
+-rw-rw-rw-  2.0 fat      860 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/__init__.py
+-rw-rw-rw-  2.0 fat    12739 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/datafile.py
+-rw-rw-rw-  2.0 fat    32986 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/io.py
+-rw-rw-rw-  2.0 fat    18581 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/ipc.py
+-rw-rw-rw-  2.0 fat     8181 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/protocol.py
+-rw-rw-rw-  2.0 fat    25722 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/schema.py
+-rw-rw-rw-  2.0 fat     5442 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/tool.py
+-rw-rw-rw-  2.0 fat     8051 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py2/txipc.py
+-rw-rw-rw-  2.0 fat      395 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/HandshakeRequest.avsc
+-rw-rw-rw-  2.0 fat      537 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/HandshakeResponse.avsc
+-rw-rw-rw-  2.0 fat        7 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/VERSION.txt
+-rw-rw-rw-  2.0 fat     1423 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/__init__.py
+-rw-rw-rw-  2.0 fat    15686 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/datafile.py
+-rw-rw-rw-  2.0 fat    34387 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/io.py
+-rw-rw-rw-  2.0 fat    23138 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/ipc.py
+-rw-rw-rw-  2.0 fat    12321 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/protocol.py
+-rw-rw-rw-  2.0 fat    36528 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/schema.py
+-rw-rw-rw-  2.0 fat     5773 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/tool.py
+-rw-rw-rw-  2.0 fat     8269 b- defN 23-Apr-24 09:59 gpudb/packages/avro/avro_py3/txipc.py
+-rw-rw-rw-  2.0 fat     1104 b- defN 23-Apr-24 10:03 gpudb-7.1.9.2.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat      371 b- defN 23-Apr-24 10:03 gpudb-7.1.9.2.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      100 b- defN 23-Apr-24 10:03 gpudb-7.1.9.2.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        6 b- defN 23-Apr-24 10:03 gpudb-7.1.9.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     3053 b- defN 23-Apr-24 10:03 gpudb-7.1.9.2.dist-info/RECORD
+34 files, 2849762 bytes uncompressed, 464269 bytes compressed:  83.7%
```

## zipnote {}

```diff
@@ -81,23 +81,23 @@
 
 Filename: gpudb/packages/avro/avro_py3/tool.py
 Comment: 
 
 Filename: gpudb/packages/avro/avro_py3/txipc.py
 Comment: 
 
-Filename: gpudb-7.1.9.1.dist-info/LICENSE
+Filename: gpudb-7.1.9.2.dist-info/LICENSE
 Comment: 
 
-Filename: gpudb-7.1.9.1.dist-info/METADATA
+Filename: gpudb-7.1.9.2.dist-info/METADATA
 Comment: 
 
-Filename: gpudb-7.1.9.1.dist-info/WHEEL
+Filename: gpudb-7.1.9.2.dist-info/WHEEL
 Comment: 
 
-Filename: gpudb-7.1.9.1.dist-info/top_level.txt
+Filename: gpudb-7.1.9.2.dist-info/top_level.txt
 Comment: 
 
-Filename: gpudb-7.1.9.1.dist-info/RECORD
+Filename: gpudb-7.1.9.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## gpudb/gpudb.py

```diff
@@ -9,23 +9,32 @@
 # gpudb.py - The Python API to interact with a GPUdb server.
 #
 # Copyright (c) 2018 Kinetica DB Inc.
 # ---------------------------------------------------------------------------
 
 from __future__ import print_function
 
+import string
+
 try:
     from io import BytesIO
 except:
     from cStringIO import StringIO as BytesIO
 try:
     import httplib
 except:
     import http.client as httplib
 
+try:
+    #python2
+    from urllib import urlencode
+except ImportError:
+    #python3
+    from urllib.parse import urlencode
+
 import socket
 
 import base64
 import copy
 import os
 import inspect
 import json
@@ -192,24 +201,17 @@
     _ENCODING_JSON   = "JSON"
     _ENCODING_SNAPPY = "SNAPPY"
 
     # Constants used in endpoint responses
     _SHOW_SYSTEM_STATUS_RESPONSE_SYSTEM  = "system"
     _SHOW_SYSTEM_STATUS_RESPONSE_STATUS  = "status"
     _SHOW_SYSTEM_STATUS_RESPONSE_RUNNING = "running"
-    _SHOW_SYSTEM_STATUS_RESPONSE_LEADERLESS = "leaderless"
     _SHOW_SYSTEM_STATUS_RESPONSE_TRUE       = "true"
-    _SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_OPERATION_RUNNING = "cluster_operation_running"
-    _SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_OPERATION_STATUS  = "cluster_operation_status"
-    _SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_IRRECOVERABLE     = "Irrecoverable"
 
     _SYSTEM_PROPERTIES_RESPONSE_ENABLE_HTTPD    = "conf.enable_httpd_proxy"
-    _SYSTEM_PROPERTIES_RESPONSE_HM_PORT         = "conf.hm_http_port"
-    _SYSTEM_PROPERTIES_RESPONSE_HEAD_FAILOVER   = "conf.np1.enable_head_failover"
-    _SYSTEM_PROPERTIES_RESPONSE_WORKER_FAILOVER = "conf.np1.enable_worker_failover"
     _SYSTEM_PROPERTIES_RESPONSE_NUM_HOSTS       = "conf.number_of_hosts"
     _SYSTEM_PROPERTIES_RESPONSE_USE_HTTPS       = "conf.use_https"
     _SYSTEM_PROPERTIES_RESPONSE_HEAD_NODE_URLS  = "conf.ha_ring_head_nodes_full"
     _SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS     = "conf.worker_http_server_urls"
     _SYSTEM_PROPERTIES_RESPONSE_SERVER_VERSION  = "version.gpudb_core_version"
     _SYSTEM_PROPERTIES_RESPONSE_TRUE            = "TRUE"
 
@@ -2572,53 +2574,54 @@
     """
     This is the main class to be used to provide the client functionality to
     interact with the server.
 
     Usage patterns
 
     * Secured setup (Default)
-    This code given below will set up a secured connection. The property 'skip_ssl_cert_verification'
-    is set to 'False' by default. SSL certificate check will be enforced by default.
 
-    ::
+      This code given below will set up a secured connection. The property 'skip_ssl_cert_verification'
+      is set to 'False' by default. SSL certificate check will be enforced by default.
+
+      ::
 
-        options = GPUdb.Options()
-        options.username = "user"
-        options.password = "password"
-        options.logging_level = "debug"
+          options = GPUdb.Options()
+          options.username = "user"
+          options.password = "password"
+          options.logging_level = "debug"
 
-        gpudb = GPUdb(host='https://your_server_ip_or_FQDN:8082/gpudb-0', options=options )
+          gpudb = GPUdb(host='https://your_server_ip_or_FQDN:8082/gpudb-0', options=options )
 
     * Unsecured setup
-    The code given below will set up an unsecured connection to the server. The property 'skip_ssl_cert_verification'
-    has been set explicitly to 'True'. So, irrespective of whether an SSL setup is there or not all certificate checks
-    will be bypassed.
 
-    ::
+      The code given below will set up an unsecured connection to the server. The property 'skip_ssl_cert_verification'
+      has been set explicitly to 'True'. So, irrespective of whether an SSL setup is there or not all certificate checks
+      will be bypassed.
 
-        options = GPUdb.Options()
-        options.username = "user"
-        options.password = "password"
-        options.skip_ssl_cert_verification = True
-        options.logging_level = "debug"
+      ::
 
-        gpudb = GPUdb(host='https://your_server_ip_or_FQDN:8082/gpudb-0', options=options )
+          options = GPUdb.Options()
+          options.username = "user"
+          options.password = "password"
+          options.skip_ssl_cert_verification = True
+          options.logging_level = "debug"
 
-    Another way of setting up an unsecured connection is as given by the code below. In this case, the URL
-    is not a secured one so no SSL setup comes into play.
+          gpudb = GPUdb(host='https://your_server_ip_or_FQDN:8082/gpudb-0', options=options )
 
-    ::
+      Another way of setting up an unsecured connection is as given by the code below. In this case, the URL
+      is not a secured one so no SSL setup comes into play.
 
-        options = GPUdb.Options()
-        options.username = "user"
-        options.password = "password"
-        options.logging_level = "debug"
+      ::
 
-        gpudb = GPUdb(host='http://your_server_ip_or_FQDN:9191', options=options )
+          options = GPUdb.Options()
+          options.username = "user"
+          options.password = "password"
+          options.logging_level = "debug"
 
+          gpudb = GPUdb(host='http://your_server_ip_or_FQDN:9191', options=options )
     """
 
     # Logging related string constants
     # Note that the millisecond is put in the message format due to a shortcoming
     # of the python datetime format shortcoming
     _LOG_MESSAGE_FORMAT  = "%(asctime)s.%(msecs)03d %(levelname)-8s %(message)s"
     _LOG_DATETIME_FORMAT = "%Y-%m-%d %H:%M:%S"
@@ -2702,42 +2705,38 @@
                                options = opts )
             opts.primary_host = "http://7.8.9.0:9191"
             db2 = gpudb.GPUdb( host = "http://1.2.3.4:9191",
                                options = opts )
         """
 
         # Names of properties
-        __cluster_reconnect_count_str            = "cluster_reconnect_count"
         __disable_auto_discovery_str             = "disable_auto_discovery"
         __disable_failover_str                   = "disable_failover"
         __encoding_str                           = "encoding"
         __ha_failover_order_str                  = "ha_failover_order"
         __host_manager_port_str                  = "host_manager_port"
         __hostname_regex_str                     = "hostname_regex"
         __http_headers_str                       = "http_headers"
         __initial_connection_attempt_timeout_str = "initial_connection_attempt_timeout"
-        __intra_cluster_failover_timeout_str     = "intra_cluster_failover_timeout"
         __logging_level_str                      = "logging_level"
         __password_str                           = "password"
         __primary_host_str                       = "primary_host"
         __protocol_str                           = "protocol"
         __skip_ssl_cert_verification_str         = "skip_ssl_cert_verification"
         __timeout_str                            = "timeout"
         __username_str                           = "username"
 
-        _supported_options = [ __cluster_reconnect_count_str,
-                               __disable_auto_discovery_str,
+        _supported_options = [ __disable_auto_discovery_str,
                                __disable_failover_str,
                                __encoding_str,
                                __ha_failover_order_str,
                                __host_manager_port_str,
                                __hostname_regex_str,
                                __http_headers_str,
                                __initial_connection_attempt_timeout_str,
-                               __intra_cluster_failover_timeout_str,
                                __logging_level_str,
                                __password_str,
                                __primary_host_str,
                                __protocol_str,
                                __skip_ssl_cert_verification_str,
                                __timeout_str,
                                __username_str
@@ -2759,24 +2758,22 @@
                     a copy constructor and make a full copy of the input
                     argument.
 
             Returns:
                 An :class:`Options` object.
             """
             # Set default values
-            self.__cluster_reconnect_count            = 1
             self.__disable_auto_discovery             = False
             self.__disable_failover                   = False
             self.__encoding                           = C._ENCODING_BINARY
             self.__ha_failover_order                  = GPUdb.HAFailoverOrder.RANDOM
             self.__host_manager_port                  = GPUdb._DEFAULT_HOST_MANAGER_PORT
             self.__hostname_regex                     = None
             self.__http_headers                       = {}
             self.__initial_connection_attempt_timeout = 0
-            self.__intra_cluster_failover_timeout     = 0 # infinite wait
             self.__logging_level                      = None
             self.__password                           = None
             self.__primary_host                       = None
             self.__protocol                           = None
             self.__skip_ssl_cert_verification         = False
             self.__timeout                            = None # means indefinite wait
             self.__username                           = None
@@ -2800,49 +2797,52 @@
             # * no_init_db_contact -> disable_auto_discovery
             if "connection" in options:
                 options[ self.__protocol_str ] = options.pop( "connection" )
 
             if "no_init_db_contact" in options:
                 options[ self.__disable_auto_discovery_str ] = options.pop( "no_init_db_contact" )
 
+            if "cluster_reconnect_count" in options:
+                del options["cluster_reconnect_count"]
+                
+            if "intra_cluster_failover_timeout" in options:
+                del options["intra_cluster_failover_timeout"]
+
             # Check for invalid options
             unsupported_options = set( options.keys() ).difference( self._supported_options )
             if unsupported_options:
                 raise GPUdbException( "Invalid options: %s" % unsupported_options )
 
             # Extract and save each option
             for (key, val) in options.items():
                 setattr( self, key, val )
         # end __init__
 
 
         def __str__( self ):
             """String representation of the cluster.
             """
-            return ("{{ {cluster_reconnect_count_str}: {cluster_reconnect_count}"
-                    ", {disable_auto_discovery_str}: {disable_auto_discovery}"
-                    ", {disable_failover_str}: {disable_failover}"
-                    ", {encoding_str}: {encoding}"
-                    ", {ha_failover_order_str}: {ha_failover_order}"
-                    ", {host_manager_port_str}: {host_manager_port}"
-                    ", {hostname_regex_str}: {hostname_regex}"
-                    ", {http_headers_str}: {http_headers}"
-                    ", {initial_connection_attempt_timeout_str}: {initial_connection_attempt_timeout}"
-                    ", {intra_cluster_failover_timeout_str}: {intra_cluster_failover_timeout}"
-                    ", {logging_level_str}: {logging_level}"
-                    ", {password_str}: {password}"
-                    ", {primary_host_str}: {primary_host}"
-                    ", {protocol_str}: {protocol}"
-                    ", {skip_ssl_cert_verification_str}: {skip_ssl_cert_verification}"
-                    ", {timeout_str}: {timeout}"
-                    ", {username_str}: {username}"
+            return ("{{"
+                    " {username_str}: {username},"
+                    " {password_str}: {password},"
+                    " {skip_ssl_cert_verification_str}: {skip_ssl_cert_verification},"
+                    " {primary_host_str}: {primary_host},"
+                    " {hostname_regex_str}: {hostname_regex},"
+                    " {disable_failover_str}: {disable_failover},"
+                    " {disable_auto_discovery_str}: {disable_auto_discovery},"
+                    " {ha_failover_order_str}: {ha_failover_order},"
+                    " {http_headers_str}: {http_headers},"
+                    " {host_manager_port_str}: {host_manager_port},"
+                    " {timeout_str}: {timeout},"
+                    " {encoding_str}: {encoding},"
+                    " {initial_connection_attempt_timeout_str}: {initial_connection_attempt_timeout},"
+                    " {logging_level_str}: {logging_level},"
+                    " {protocol_str}: {protocol}"
                     " }}"
                     "".format(
-                        cluster_reconnect_count_str = self.__cluster_reconnect_count_str,
-                        cluster_reconnect_count     = self.cluster_reconnect_count,
                         disable_auto_discovery_str  = self.__disable_auto_discovery_str,
                         disable_auto_discovery      = self.disable_auto_discovery,
                         disable_failover_str        = self.__disable_failover_str,
                         disable_failover            = self.disable_failover,
                         encoding_str                = self.__encoding_str,
                         encoding                    = self.encoding,
                         ha_failover_order_str       = self.__ha_failover_order_str,
@@ -2851,16 +2851,14 @@
                         host_manager_port           = self.host_manager_port,
                         hostname_regex_str          = self.__hostname_regex_str,
                         hostname_regex              = self.hostname_regex,
                         http_headers_str            = self.__http_headers_str,
                         http_headers                = self.http_headers,
                         initial_connection_attempt_timeout_str = self.__initial_connection_attempt_timeout_str,
                         initial_connection_attempt_timeout     = self.initial_connection_attempt_timeout,
-                        intra_cluster_failover_timeout_str  = self.__intra_cluster_failover_timeout_str,
-                        intra_cluster_failover_timeout      = self.intra_cluster_failover_timeout,
                         logging_level_str                   = self.__logging_level_str,
                         logging_level                       = self.logging_level,
                         password_str                        = self.__password_str,
                         password                            = "********",
                         primary_host_str                    = self.__primary_host_str,
                         primary_host                        = self.primary_host,
                         protocol_str                        = self.__protocol_str,
@@ -2879,17 +2877,14 @@
         def __eq__( self, other ):
             """Override the equality operator.
             """
             # Check the type of the other object
             if not isinstance( other, GPUdb.Options ):
                 return False
 
-            if ( self.cluster_reconnect_count != other.cluster_reconnect_count ):
-                return False
-
             if ( self.disable_auto_discovery != other.disable_auto_discovery ):
                 return False
 
             if ( self.disable_failover != other.disable_failover ):
                 return False
 
             if ( self.encoding != other.encoding ):
@@ -2906,17 +2901,14 @@
 
             if ( self.http_headers != other.http_headers ):
                 return False
 
             if ( self.initial_connection_attempt_timeout != other.initial_connection_attempt_timeout ):
                 return False
 
-            if ( self.intra_cluster_failover_timeout != other.intra_cluster_failover_timeout ):
-                return False
-
             if ( self.logging_level != other.logging_level ):
                 return False
 
             if ( self.password != other.password ):
                 return False
 
             # The primary host equivalence is only strict for given hosts;
@@ -2954,23 +2946,21 @@
 
         def as_json(self):
             """Return the options as a JSON.  Will stringify parameters as
             needed.  For example, GPUdb.URL and GPUdb.HAFailoverOrder objects
             will be stringified.
             """
             result = {}
-            result[ self.__cluster_reconnect_count_str ] = self.cluster_reconnect_count
             result[ self.__disable_auto_discovery_str  ] = self.disable_auto_discovery
             result[ self.__disable_failover_str        ] = self.disable_failover
             result[ self.__encoding_str                ] = self.encoding
             result[ self.__host_manager_port_str       ] = self.host_manager_port
             result[ self.__hostname_regex_str          ] = self.hostname_regex
             result[ self.__http_headers_str            ] = self.http_headers
             result[ self.__initial_connection_attempt_timeout_str ] = self.initial_connection_attempt_timeout
-            result[ self.__intra_cluster_failover_timeout_str     ] = self.intra_cluster_failover_timeout
             result[ self.__logging_level_str                      ] = self.logging_level
             result[ self.__password_str                           ] = self.password
             result[ self.__protocol_str                           ] = self.protocol
             result[ self.__skip_ssl_cert_verification_str         ] = self.skip_ssl_cert_verification
             result[ self.__timeout_str                            ] = self.timeout
             result[ self.__username_str                           ] = self.username
 
@@ -2994,39 +2984,41 @@
         @property
         def cluster_reconnect_count(self):
             """Gets the number of times the API tries to reconnect to the
             same cluster (when a failover event has been triggered),
             before actually failing over to any available backup
             cluster.  Does not apply when only a single cluster is
             available.
+            
+            This method is now deprecated.
             """
-            return self.__cluster_reconnect_count
+            return 1
 
         @cluster_reconnect_count.setter
         def cluster_reconnect_count(self, value):
             """Sets the number of times the API tries to reconnect to the
             same cluster (when a failover event has been triggered),
             before actually failing over to any available backup
             cluster.  Does not apply when only a single cluster is
             available.  Must be an integer value greater than or equal to zero.
             The default is 1.
+            
+            This method is now deprecated.
             """
             try:
                 value = int( value )
             except:
                 raise GPUdbException( "Property 'cluster_reconnect_count' must be numeric; "
                                       "given {}".format( str(type(value)) ) )
 
             # Must be >= 0
             if (value < 0):
                 raise GPUdbException( "Property 'cluster_reconnect_count' must be "
                                       "greater than or equal to 0; given {}"
                                       "".format( str(value) ) )
-
-            self.__cluster_reconnect_count = value
         # end setter
 
 
         @property
         def disable_auto_discovery(self):
             """Gets the property indicating whether to disable automatic
             discovery of backup clusters or worker rank URLs.  If set to true,
@@ -3050,26 +3042,22 @@
                                       "".format( value, str(type(value)) ) )
             self.__disable_auto_discovery = value
         # end setter
 
 
         @property
         def disable_failover(self):
-            """Gets the whether failover upon failures (both ring resiliency--or
-            inter-cluster--failover and cluster resiliency--or intra-cluster--
-            failover) is to be completely disabled.
+            """Gets the whether failover upon failures is to be completely disabled.
             """
             return self.__disable_failover
 
 
         @disable_failover.setter
         def disable_failover(self, value):
-            """Sets the whether failover upon failures (both ring resiliency--or
-            inter-cluster--failover and cluster resiliency--or intra-cluster--
-            failover) is to be completely disabled.
+            """Sets the whether failover upon failures is to be completely disabled.
 
             Default is False.
             """
             if not isinstance( value, bool ):
                 raise GPUdbException( "Property 'disable_failover' must be boolean;"
                                       " given '{}' type {}"
                                       "".format( value, str(type(value)) ) )
@@ -3198,14 +3186,17 @@
             """Sets the IP address or hostname regex against which the server's
             rank URLs would be matched when auto-discovering them.  If None, then
             the first URL for any given rank would be used (if multiple are
             available in the system properties).
 
             Note that the regex MUST NOT have the protocol or the port; it
             should be a regular expression ONLY for the hostname/IP address.
+            
+            Note also that the regex must match all servers in all clusters of
+            the ring, as there is only one in use per connection.
 
             Allowed types are string, a compiled regex object, or None (to
             indicate no regex is to be used for URL matching--just take the
             first one from a list of URLs).  The default is None.
             """
             if value is None:
                 self.__hostname_regex = value
@@ -3389,37 +3380,40 @@
 
 
         @property
         def intra_cluster_failover_timeout(self):
             """Gets the timeout used when trying to recover from an intra-cluster
             failover event.  The value is given in seconds.  The default is
             equivalent to 5 minutes.
+            
+            This method is now deprecated.
             """
-            return self.__intra_cluster_failover_timeout
+            return 0
 
 
         @intra_cluster_failover_timeout.setter
         def intra_cluster_failover_timeout(self, value):
             """Sets the timeout used when trying to recover from an intra-cluster
             failover event.  The value is given in seconds.  The default is
             equivalent to 5 minutes.
+            
+            This method is now deprecated.
             """
             try:
                 value = int( value )
             except:
                 raise GPUdbException( "Property 'intra_cluster_failover_timeout' "
                                       "must be numeric; "
                                       "given {}".format( str(type(value)) ) )
 
             # Must be >= 0
             if (value < 0):
                 raise GPUdbException( "Property 'intra_cluster_failover_timeout' "
                                       "must be greater than or equal to zero; "
                                       "given {}".format( value ) )
-            self.__intra_cluster_failover_timeout = value
         # end setter
 
 
         @property
         def logging_level(self):
             """Gets the logging level that will be used by the API.  By default,
             logging is set by the root logger (possibly set by the end user
@@ -4143,26 +4137,26 @@
             return self.__password
 
     # end class URL
 
     class ClusterAddressInfo( object ):
         """Inner class to keep track of all relevant information for a given
         Kinetica cluster.  It mostly keeps track of URLs and hostnames, with
-        some additional information like whether N+1 is enabled or not.
+        some additional information like whether the cluster is primary or not.
         """
 
 
         def __init__( self, head_rank_url,
                       worker_rank_urls   = None,
                       host_names         = None,
                       host_manager_url   = None,
                       host_manager_port  = None,
                       is_primary_cluster = None,
-                      is_intra_cluster_failover_enabled = None,
-                      server_version     = None ):
+                      server_version     = None,
+                      logging_level      = None ):
             """Creates a :class:`ClusterAddressInfo` object with the given
             information.
 
             Parameters:
                 head_rank_url (str or :class:`GPUdb.URL`)
                    Only required argument.  Must be a full URL string or
                    :class:`GPUdb.URL` object.  E.g. "http://1.2.3.4:8082/gpudb-0".
@@ -4185,44 +4179,43 @@
                    Optional argument, mutually exclusive with `host_manager_url`.
                    If given, must be an integer in the range [1, 65535].
 
                 is_primary_cluster (bool)
                    Optional boolean argument.  Indicates if this cluster is to
                    be treated as the primary cluster.  Default is False.
 
-                is_intra_cluster_failover_enabled (bool)
-                   Optional boolean argument.  Indicates if this cluster has
-                   cluster resiliency or intra-cluster failover enabled.  Default
-                   is False.
-
                 server_version (str or :class:`GPUdb.Version`)
                    Optional string containing the server version.  If given,
                    will be parsed as a :class:`GPUdb.Version` object. Default
                    is None.
+            
+                logging_level (int)
+                   Optional level at which logs should be output.  Default is
+                   None. 
             """
             self.__construct( head_rank_url,
                               worker_rank_urls,
                               host_names,
                               host_manager_url,
                               host_manager_port,
                               is_primary_cluster,
-                              is_intra_cluster_failover_enabled,
-                              server_version )
+                              server_version,
+                              logging_level )
         # end __init__
 
 
 
         def __construct( self, head_rank_url,
                          worker_rank_urls   = None,
                          host_names         = None,
                          host_manager_url   = None,
                          host_manager_port  = None,
                          is_primary_cluster = None,
-                         is_intra_cluster_failover_enabled = None,
-                         server_version     = None ):
+                         server_version     = None,
+                         logging_level      = None ):
             """Constructs a :class:`GPUdb.ClusterAddressInfo` object.
 
             Parameters:
                 head_rank_url (str or :class:`GPUdb.URL`)
                    Only required argument.  Must be a full URL string or
                    :class:`GPUdb.URL` object.  E.g. "http://1.2.3.4:8082/gpudb-0".
 
@@ -4244,48 +4237,49 @@
                    Optional argument, mutually exclusive with `host_manager_url`.
                    If given, must be an integer in the range [1, 65535].
 
                 is_primary_cluster (bool)
                    Optional boolean argument.  Indicates if this cluster is to
                    be treated as the primary cluster.  Default is False.
 
-                is_intra_cluster_failover_enabled (bool)
-                   Optional boolean argument.  Indicates if this cluster has
-                   cluster resiliency or intra-cluster failover enabled.  Default
-                   is False.
-
                 server_version (str or :class:`GPUdb.Version`)
                    Optional string containing the server version.  If given,
                    will be parsed as a :class:`GPUdb.Version` object. Default
                    is None.
+            
+                logging_level (int)
+                   Optional level at which logs should be output.  Default is
+                   None. 
             """
-            # Class level logger so that setting it for ond instance doesn't
+            # Class level logger so that setting it for one instance doesn't
             # set it for ALL instances after that change (even if it is
             # outside of the scope of the first instance whose log level was
             # changed
             self.log = logging.getLogger( "gpudb.GPUdb.ClusterAddressInfo_instance_"
                                           + str( uuid.uuid4() ) )
 
             # Handlers need to be instantiated only ONCE for a given module
             # (i.e. not per class instance)
             handler   = logging.StreamHandler()
             formatter = logging.Formatter( fmt     = GPUdb._LOG_MESSAGE_FORMAT,
                                            datefmt = GPUdb._LOG_DATETIME_FORMAT )
             handler.setFormatter( formatter )
             self.log.addHandler( handler )
+            
+            if logging_level:
+                self.log.setLevel(logging_level)
 
             # Prevent logging statements from being duplicated
             self.log.propagate = False
 
             # Set default values
             self.__worker_rank_urls                  = []
             self.__host_names                        = []
             self.__host_manager_url                  = None
             self.__is_primary_cluster                = False
-            self.__is_intra_cluster_failover_enabled = False
             self.__server_version                    = None
 
 
             # Validate all the input arguments and save them.
             # Note that we are using the property setters, rather than directly
             # setting the values of the private members.  This ensures that we
             # validate the values appropriately.
@@ -4321,30 +4315,30 @@
                 # Use this port to create a host manager URL (to be saved later)
                 head_url = self.head_rank_url
                 host_manager_url = ("{protocol}://{ip}:{port}{path}"
                                     "".format( protocol = head_url.protocol.lower(),
                                                ip       = head_url.host,
                                                port     = host_manager_port,
                                                path     = head_url.path ) )
+
+                self.__log_debug( "Created host manager URL: {}".format( host_manager_url ) )
             # end if
 
             # Validate and save the rest.
             # Note that we are using the property setters, rather than directly
             # setting the values of the private members.  This ensures that we
             # validate the values appropriately.
             if worker_rank_urls is not None:
                 self.worker_rank_urls = worker_rank_urls
             if host_names is not None:
                 self.host_names = host_names
             if host_manager_url is not None:
                 self.host_manager_url = host_manager_url
             if is_primary_cluster is not None:
                 self.is_primary_cluster = is_primary_cluster
-            if is_intra_cluster_failover_enabled is not None:
-                self.is_intra_cluster_failover_enabled = is_intra_cluster_failover_enabled
             if server_version is not None:
                 self.server_version = server_version
 
             # Save the protocol for use
             self.__protocol = self.head_rank_url.protocol
 
             # Update the hostnames with all the ranks' hostnames
@@ -4361,17 +4355,14 @@
                     return False
                 if ( self.host_names != other.host_names ):
                     return False
                 if ( self.host_manager_url != other.host_manager_url ):
                     return False
                 if ( self.is_primary_cluster != other.is_primary_cluster ):
                     return False
-                if ( self.is_intra_cluster_failover_enabled
-                     != other.is_intra_cluster_failover_enabled ):
-                    return False
                 if ( self.server_version != other.server_version ):
                     return False
                 return True
             else:
                 return False
         # end __eq__
 
@@ -4384,23 +4375,21 @@
         def __str__(self):
             """String representation of this cluster."""
             return ("{{ head_rank_url: {rank0}"
                     ", worker_rank_urls: {workers}"
                     ", host_names: {hostnames}"
                     ", host_manager_url: {hm}"
                     ", is_primary_cluster: {primary}"
-                    ", is_intra_cluster_failover_enabled: {np1}"
                     ", server_version: {version}"
                     " }}"
                     "".format( rank0     = self.head_rank_url,
                                workers   = [str(u) for u in self.worker_rank_urls],
                                hostnames = self.host_names,
                                hm        = self.host_manager_url,
                                primary   = self.is_primary_cluster,
-                               np1       = self.is_intra_cluster_failover_enabled,
                                version   = str( self.server_version ) ) )
         # end __str__
 
 
         @property
         def head_rank_url( self ):
             """Returns the current head node :class:`GPUdb.URL` for this cluster.
@@ -4557,28 +4546,30 @@
         # end setter
 
 
         @property
         def is_intra_cluster_failover_enabled( self ):
             """Returns whether this cluster has intra-cluster failover
             enabled.
+            
+            This method is now deprecated.
             """
-            return self.__is_intra_cluster_failover_enabled
+            return False
 
 
         @is_intra_cluster_failover_enabled.setter
         def is_intra_cluster_failover_enabled( self, value ):
             """Sets whether this cluster has intra-cluster failover enabled.
             Must be a boolean value.  The default is False.
+            
+            This method is now deprecated.
             """
             if not isinstance( value, bool ):
-                raise GPUdbException( "Property 'is_intra_cluster_failover_enabled'"
-                                      " must be boolean; given '{}' type {}"
+                raise GPUdbException( "Property must be boolean; given '{}' type {}"
                                       "".format( value, str(type(value)) ) )
-            self.__is_intra_cluster_failover_enabled = value
         # end setter
 
 
         @property
         def server_version( self ):
             """Returns the version of this cluster, if known; None otherwise.
             """
@@ -4627,15 +4618,15 @@
                 # Some error occurred with inspect; just log the debug message
                 self.log.debug( "[GPUdb.ClusterAddressInfo]"
                                 "  {msg}"
                                 "".format( msg = message ) )
         # end __debug
 
         def __log_warn( self, message ):
-            self.log.warn( "[GPUdb.ClusterAddressInfo] {}".format( message ) )
+            self.log.warning( "[GPUdb.ClusterAddressInfo] {}".format( message ) )
         # end __warn
 
         def __log_info( self, message ):
             self.log.info( "[GPUdb.ClusterAddressInfo] {}".format( message ) )
         # end __log_info
 
         def __log_error( self, message ):
@@ -4643,30 +4634,34 @@
         # end __log_error
 
 
         def __update_hostnames_based_on_rank_urls( self ):
             """Add the hostnames of the head and worker ranks URLs to the
             list of hostnames if they are not already part of it.
             """
+            self.__log_debug( "Updating hostname list: {}".format([host_name for host_name in self.host_names]) )
+
             # Put the head rank's hostname in the saved hostnames (only if
             # it doesn't exist there already)
             head_rank_hostname = ("{protocol}://{host}"
                                   "".format( protocol = self.head_rank_url.protocol.lower(),
                                              host     = self.head_rank_url.host ) )
             if head_rank_hostname not in self.host_names:
+                self.__log_debug( "Adding head rank's hostname to hostname list: {}".format( head_rank_hostname ) )
                 self.__host_names.append( head_rank_hostname )
 
 
             # Put each worker rank's hostname in the saved hostnames (only if
             # it doesn't exist there already)
             for worker_url in self.worker_rank_urls:
                 worker_rank_hostname = ("{protocol}://{host}"
                                   "".format( protocol = worker_url.protocol.lower(),
                                              host     = worker_url.host ) )
                 if worker_rank_hostname not in self.host_names:
+                    self.__log_debug( "Adding worker rank's hostname to hostname list: {}".format( worker_rank_hostname ) )
                     self.__host_names.append( worker_rank_hostname )
         # end __update_hostnames_based_on_rank_urls
 
 
         # Convenience Methods
         # --------------------
 
@@ -4678,37 +4673,32 @@
                 host_name (str)
                     String containing a hostname or an IP address.
 
             Returns:
                 True if this cluster contains a machine with the given
                 hostname or IP address, False otherwise.
             """
-            self.__log_debug( "Begin checking for hostname: '{}'"
-                              "".format( host_name ) )
+            self.__log_debug( "Check for hostname {} in hostname list".format( host_name ) )
             if not isinstance( host_name, (basestring, unicode)):
                 msg = ("Need a string for the host name, given '{}'"
                        "".format( str(type(host_name)) ) )
                 self.__log_debug( msg )
                 return False
             # end if
 
             for host_name_ in self.host_names:
                 # We need to check for a string subset match since the
                 # hostnames contain the protocol as well as the actual hostname
                 # or IP address
-                self.__log_debug( "Checking for match with '{}'"
-                                  "".format( host_name_ ) )
                 if( host_name in host_name_ ):
-                    self.__log_debug( "Found matching hostname")
+                    self.__log_debug( "Found matching hostname in hostname list")
                     return True
-                else:
-                    self.__log_debug( "Did NOT find matching hostname")
             # end for
 
-            self.__log_debug( "No match; returning false")
+            self.__log_debug( "Hostname not found in hostname list")
             return False # found no match
         # end does_cluster_contain_node
 
 
     # end class ClusterAddressInfo
 
 
@@ -4727,17 +4717,17 @@
         C._DB_CONNECTION_RESET
     ]
 
     # Default host manager port for http and httpd
     _DEFAULT_HOST_MANAGER_PORT       = 9300
     _DEFAULT_HTTPD_HOST_MANAGER_PORT = 8082
 
-    # The timeout (in seconds) used for endpoint calls used during N+1
-    # failover recovery; we use a small timeout so that it does not take
-    # a long time to figure out that a rank is down.  Using 1 second.
+    # The timeout (in seconds) used for checking the status of a node; we
+    # use a small timeout so that it does not take a long time to figure out
+    # that a rank is down.  Using 1 second.
     __DEFAULT_INTERNAL_ENDPOINT_CALL_TIMEOUT = 1
 
     # The number of times that the API will attempt to submit a host
     # manager endpoint request.  We need this in case the user chose
     # a bad host manager port.  We don't want to go into an infinite
     # loop
     __HOST_MANAGER_SUBMIT_REQUEST_RETRY_COUNT = 3
@@ -4751,25 +4741,25 @@
 
     END_OF_SET = -9999
     """(int) Used for indicating that all of the records (till the end of the
     set are desired)--generally used for /get/records/\* functions.
     """
 
     # The version of this API
-    api_version = "7.1.9.1"
+    api_version = "7.1.9.2"
 
     # -------------------------  GPUdb Methods --------------------------------
 
     def __init__( self, host = None, options = None, *args, **kwargs ):
         """
         Construct a new GPUdb client instance.  This object communicates to
         the database server at the given address.  This class implements
-        inter-cluster and intra-cluster failover, which means that upon
-        certain error conditions, this class will try to establish connection
-        with one of the backup processes of the database to continue service.
+        HA failover, which means that upon certain error conditions, this class
+        will try to establish connection with one of the other clusters
+        (specified by the user or known to the ring) to continue service.
         There are several options related to how to control that in the
         :class:`GPUdb.Options` class that can be controlled via `options`.
 
         .. note::
 
             Please read the docstring of `options` about backward-
             compatibility related notes.
@@ -4860,48 +4850,53 @@
         self.log.propagate = False
 
         # Keep track of this API's client version
         self.__client_version = GPUdb.Version( self.api_version )
 
         # Handle constructor arguments in a backward-compatible manner
         port, options = self.__parse_options( options, *args, **kwargs )
-        self.__log_debug( "Got port: {}".format( port ) )
-        self.__log_debug( "Using options: {}".format( str(options) ) )
 
         # Save the options and its individual properties
         self.__options    = options
         self.__encoding   = self.options.encoding
         self.__username   = self.options.username
         self.__password   = self.options.password
         self.__logging_level = self.options.logging_level
         self.__primary_host  = self.options.primary_host
         self.__protocol      = self.options.protocol
         self.__timeout       = self.options.timeout
         self.__custom_http_headers      = self.options.http_headers
         self.__skip_ssl_cert_check      = self.options.skip_ssl_cert_verification
-        self.__cluster_reconnect_count  = self.options.cluster_reconnect_count
         self.__disable_auto_discovery   = self.options.disable_auto_discovery
         self.__disable_failover         = self.options.disable_failover
         self.__ha_failover_order        = self.options.ha_failover_order
         self.__initial_connection_timeout = self.options.initial_connection_attempt_timeout
-        self.__intra_cluster_failover_timeout     = self.options.intra_cluster_failover_timeout
+
+        # Set the logging level (only if the user set something)
+        if self.__logging_level is not None:
+            self.set_client_logger_level( self.__logging_level )
+        # end if
+
+        self.__log_debug( "Host: {}".format( str(host) ) )
+        self.__log_debug( "Port: {}".format( port ) )
+        self.__log_debug( "Options: {}".format( str(options) ) )
+
+        if self.__skip_ssl_cert_check:
+            self.__log_debug( "Bypassing SSL certificate check for HTTPS connections" );
+        else:
+            self.__log_debug( "Using system trust store for HTTPS connections" );
 
         # Validate the encoding
         if (self.encoding.upper() == C._ENCODING_SNAPPY and not HAVE_SNAPPY):
             self.__log_warn('SNAPPY encoding specified but python-snappy is not installed; reverting to BINARY')
             self.__encoding = C._ENCODING_BINARY
 
         # Set default values for some internal information
         self.__use_httpd = False
 
-        # Set the logging level (only if the user set something)
-        if self.__logging_level is not None:
-            self.set_client_logger_level( self.__logging_level )
-        # end if
-
         self.client_to_object_encoding_map = { \
                                                C._ENCODING_BINARY: "binary",
                                                C._ENCODING_SNAPPY: "binary",
                                                C._ENCODING_JSON: "json",
         }
 
         # Set the synchronicity override mode to be default
@@ -4963,40 +4958,37 @@
         # end if
 
         # Check that no duplicate host name was given
         if ( ( len(host) > 1) and (len(host) != len( set(host) )) ):
             self.__log_warn( "Given list of hosts has a duplicate; might cause unpredictable behavior ({})"
                              "".format( host ) )
 
-        self.__log_debug( "Got host: {}".format( host ) )
-
         # If the user explicitly gave a separate port & protocol via
         # the options, reconcile that with the user given URLs.
         hosts = []
         for (host_, port_, protocol_) in zip(host, port, protocol):
-            self.__log_debug( "Working on host '{}' port '{}' protocol '{}'"
+            self.__log_debug( "Normalizing host '{}' port '{}' protocol '{}'"
                               "".format( host_, port_, protocol_ ) )
-            if host_ is None:
-                url = GPUdb.URL( host_, port_, protocol_ )
-            else:
-                url = GPUdb.URL( host_, port_, protocol_ )
 
-                self.__log_debug( "Connection: <%s> @ <%s>" % (url.username, url.url) )
+            url = GPUdb.URL( host_, port_, protocol_ )
+
+            if host_:
+                self.__log_debug( "Converted to user @ host: <%s> @ <%s>" % (url.username, url.url) )
 
                 # If no user/pass set, attempt to pull from any URLs
                 if self.__username is None:
                     self.__username = url.username
                 if self.__password is None:
                     self.__password = url.password
             # end if
 
             # Add the possibly modified host to the final hosts list
             hosts.append( url.url )
         # end for
-        self.__log_debug( "Using (possibly modified) host: {}".format( hosts ) )
+        self.__log_debug( "Using (possibly modified) URLs: {}".format( hosts ) )
 
         # Set up the credentials to be used per POST
         self.auth = None
         if self.username is not None:
             self.__log_debug('Setting up credentials with username <%s>' % self.username)
             if IS_PYTHON_3:
                 # base64 encode the username and password
@@ -5015,15 +5007,14 @@
 
         # Some defaults
         self.__cluster_indices = []
         self.__curr_cluster_index_pointer = 0
 
         # Parse the user given URLs (will throw an error if no connection
         # can be established)
-        self.__log_debug( "Got hosts: {}".format( hosts ) )
         self.__parse_urls( hosts )
 
         # Check version compatibility with the server
         # -------------------------------------------
         self.__update_server_version()
         if( not self.__perform_version_check() ):
             self.__log_warn("API and server versions don't match")
@@ -5235,19 +5226,18 @@
 
         # Try to parse the URLs for a preset amount of time (in case the
         # first attempt fails)
         keep_trying = True
         while ( keep_trying ):
             try:
                 # Parse the URLs (a single attempt)
-                self.__log_debug( "Attempting to parse the user given URLs: {}"
+                self.__log_debug( "Attempting to parse the user-given URLs: {}"
                                   "".format( [str(u) for u in urls]) )
                 self.__parse_urls_once( urls )
-                self.__log_debug( "Parsed the user given URLs successfully; "
-                                  "final list of clusters: {}"
+                self.__log_debug( "Parsed the user-given URLs successfully: {}"
                                   "".format( [ str(c)
                                                for c in self.all_cluster_info ]) )
                 return # one successful attempt is all we need
             except GPUdbUnauthorizedAccessException as ex:
                 # Any permission related problem should get propagated
                 raise
             except GPUdbHostnameRegexFailureException as ex:
@@ -5370,66 +5360,50 @@
             raise GPUdbException( "Unable to parse argument 'urls'; "
                                   "error: {}"
                                   "".format( GPUdbException.stringify_exception( ex ) ) )
         # end try
 
         # Keep a stringified version to be used in logs
         urls_str = [str(u) for u in urls]
-        self.__log_debug( "Given URLs in the order given by the user: {}"
-                          "".format( urls_str ) )
 
         # Convert the list of URLs to a set (to remove duplicates) and then
         # into a queue (so that we can add HA ring addresses as we get them
         # from servers and add them to the end of the queue while iterating
         # over it--other forms of collections don't allow for it)
         # Note: Doing this extra step to maintain order from the original list
         duplicates_removed_in_order = sorted( set( urls ), key = urls.index )
-        self.__log_debug( "Given URLs with duplicates removed (and in the order"
-                          " given by the user): {}"
-                          "".format( [ str(u)
-                                       for u in duplicates_removed_in_order] ) )
         url_deque = collections.deque( duplicates_removed_in_order )
-        self.__log_debug( "URL deque used for processing given URLs: {}"
-                          "".format( [ str(u) for u in url_deque ] ) )
-
-        # If a fully qualified URL is given for the primary URL, process
-        # that, too
-        self.__log_debug( "Primary host str: '{}'".format( self.primary_host ) )
 
         # Save the hostname of the primary URL (which could be an empty string)
         if ( self.primary_host ):
             try:
                 # If it's a full URL, add it to the queue for processing
                 primary_url = GPUdb.URL( self.primary_host,
                                          accept_full_urls_only = True )
-                self.__log_debug( "Parsed primary host: {}"
-                                  "".format( str(primary_url) ) )
 
                 # Add this URL to the list of URLs to process if it's not
                 # already in it
                 if primary_url not in duplicates_removed_in_order:
-                    self.__log_debug( "Primary url not in user given URLs; "
-                                      "adding it to the back of the list" )
+                    self.__log_debug( "Primary URL not in user-given URLs; adding it" )
                     url_deque.append( primary_url )
                 # end if
 
                 # Update the hostname of the primary cluster's URL for
                 # future use (instead of having the full URL)
                 self.__primary_host = primary_url.host
             except GPUdbException as ex:
                 self.__log_debug( "Problem parsing primary host '{}': {}"
                                   "".format( str(self.primary_host),
                                              str(ex) ) )
                 # No-op if it's not a fully qualified URL (e.g. the user
                 # may have only given a hostname)
             # end try
         # end if
-        self.__log_debug( "Primary hostname: '{}'".format( self.primary_host ) )
 
-        self.__log_debug( "User given URLs (size {}): {}"
+        self.__log_debug( "Consolidated list of {} URLs to process: {}"
                           "".format( len(url_deque),
                                      [str(u) for u in list( url_deque )] ) )
 
         # Note that we're updating the member here
         self.__cluster_info = []
 
         # We will store API-discovered URLs even if we cannot communicate with
@@ -5442,298 +5416,259 @@
         # the same cluster (for the purpose of primary choosing)
         cluster_index_for_user_given_urls = []
 
         # Parse each user given URL (until the queue is empty)
         while ( url_deque ):
             url     = url_deque.popleft()
             url_str = str( url )
-            self.__log_debug( "Processing url: {}".format( url_str ) )
-            self.__log_debug( "URLs queue after removing this url (size {}): {}"
+            self.__log_debug( "Processing URL: {}".format( url_str ) )
+            self.__log_debug( "Remaining {} URL(s): {}"
                               "".format( len(url_deque),
                                          [ str(u) for u in list( url_deque ) ] ) )
 
             # Figure out if this URL is user given or discovered by the API
             if (num_processed_urls >= num_user_given_urls):
-                self.__log_debug( "This url is API discovered" )
+                self.__log_debug( "This URL is API-discovered" )
                 is_discovered_url = True
             # end if
             num_processed_urls += 1
 
             # Skip processing this URL if the hostname/IP address is used in
             # any of the known (already registered) clusters
             index_of_hostname_in_ring = self.__get_index_of_cluster_containing_node( url.host )
             if ( index_of_hostname_in_ring != -1 ):
-                self.__log_debug( "Already contains hostname of {}; skipping "
-                                  "processing this one".format( url_str ) )
 
-                # Save the fact that this user given URL belong to an existing
+                # Save the fact that this user given URL belongs to an existing
                 # cluster
                 if not is_discovered_url:
-                    self.__log_debug("Adding index {} for url {} to "
-                                     "cluster_index_for_user_given_urls"
-                                     "".format(index_of_hostname_in_ring, url_str) )
+                    self.__log_debug("Skipping user-given URL {} (already found); adding index {} to user-given processed cluster list"
+                                     "".format(url_str, index_of_hostname_in_ring) )
                     cluster_index_for_user_given_urls.append( index_of_hostname_in_ring )
                 else:
-                    self.__log_debug("NOT adding index url {} to "
-                                     "cluster_index_for_user_given_urls"
-                                     "".format( url_str ) )
+                    self.__log_debug("Skipping discovered URL {} (already found)".format( url_str ) )
                 # end if
 
                 continue
             # end if
 
             # Skip auto-discovery of cluster information if the user says so
-            self.__log_debug( "Auto discovery disabling flag value: {}"
-                              "".format( self.__disable_auto_discovery ) )
             if ( self.__disable_auto_discovery ):
-                self.__log_debug( "Auto discovery disabled; not connecting"
-                                  " to server at '{}' at initialization for "
-                                  "verification".format( url_str ) )
 
-                # Save the fact that this user given URL is being added as a cluster
-                # of its own
                 if not is_discovered_url:
-                    self.__log_debug("Adding index {} for url {} to "
-                                     "cluster_index_for_user_given_urls"
-                                     "".format(len(self.__cluster_info), url_str) )
+                    self.__log_debug("Skipping connect verification of user-given URL {} (auto-discovery disabled); "
+                                     "adding index {} to user-given processed cluster list"
+                                     "".format(url_str, len(self.__cluster_info)) )
+
+                    # Mark this user-given URL as a valid cluster
                     cluster_index_for_user_given_urls.append( len(self.__cluster_info) )
                 else:
-                    self.__log_debug("NOT adding index url {} to "
-                                     "cluster_index_for_user_given_urls"
+                    self.__log_debug("Skipping connect verification of API-discovered URL {} (auto-discovery disabled)"
                                      "".format( url_str ) )
                 # end if
 
                 # Create a cluster info object with just the given URL and the
                 # host manager port in the option
                 cluster_info = GPUdb.ClusterAddressInfo( url,
-                                                         host_manager_port = self.options.host_manager_port )
+                                                         host_manager_port = self.options.host_manager_port,
+                                                         logging_level = self.log.getEffectiveLevel() )
                 self.__cluster_info.append( cluster_info )
                 self.__log_debug( "Added cluster: {}".format( str(cluster_info) ) )
                 continue # skip to the next URL
             # end if
 
             # Skip processing this URL if Kinetica is not running at this address
             if not self.__is_system_running( url = url ):
-                self.__log_debug( "System is not running at {}"
-                                  "".format( url_str ) )
+
                 # If this URL has been discovered by the API, then add it to
                 # the cluster list anyway
                 if ( is_discovered_url ):
-                    self.__log_debug( "API-discovered URL" )
                     # Create a cluster info object with just the given URL and the
                     # host manager port in the option
                     cluster_info = self.__create_cluster_address_info_with_hm_port( url,
                                                                                     self.options.host_manager_port )
                     self.__cluster_info.append( cluster_info )
-                    self.__log_debug( "Added cluster: {}".format( str(cluster_info) ) )
+                    self.__log_debug( "Added non-running cluster with API-discovered URL: {}".format( str(cluster_info) ) )
                 else:
-                    self.__log_debug( "Skipping user-given URL: {}"
-                                      "".format( url_str ) )
+                    self.__log_debug( "Skipping non-running user-given URL: {}".format( url_str ) )
                 # end if
                 continue
             # end if
 
             # Get system properties of the cluster, if can't get it, skip
             # to the next one
             try:
                 sys_props = self.__get_system_properties( url )
-            except GPUdbUnauthorizedAccessException as ex:
-                # Any permission related problem should get propagated
-                raise
             except GPUdbException as ex:
-                # Couldn't get the properties, so can't process this URL
-                self.__log_debug( "Could not get properties from {}"
-                                  "".format( url_str ) )
+
                 # If this URL has been discovered by the API, then add it to
                 # the cluster list anyway
                 if ( is_discovered_url ):
-                    self.__log_debug( "API-discovered URL" )
                     # Create a cluster info object with just the given URL and the
                     # host manager port in the option
                     cluster_info = self.__create_cluster_address_info_with_hm_port( url,
                                                                                     self.options.host_manager_port )
                     self.__cluster_info.append( cluster_info )
-                    self.__log_debug( "Added cluster: {}".format( str(cluster_info) ) )
+                    self.__log_debug( "Added failed system properties lookup cluster with API-discovered URL: {}".format( str(cluster_info) ) )
                 else:
-                    self.__log_debug( "Skipping user-given URL: {}"
-                                      "".format( url_str ) )
+                    self.__log_debug( "Skipping failed system properties lookup user-given URL: {}".format( url_str ) )
                 # end if
                 continue
             # end try
 
             # Create an object to store all the information about this cluster
             # (this could fail due to a host name regex mismatch)
             cluster_info = self.__create_cluster_address_info( url, sys_props )
-            self.__cluster_info.append( cluster_info )
-
-            self.__log_debug( "Added cluster for url: {}".format( url_str ) )
-            self.__log_debug( "Added cluster: {}".format( str(cluster_info) ) )
-            self.__log_debug( "URLs queue after processing this url (size {}): {}"
-                              "".format( len(url_deque),
-                                         [ str(u) for u in list(url_deque) ] ) )
 
-            # Save the fact that this user given URL is being added as a cluster
-            # of its own
+            # We need to evaluate if we should save the user-given addresses
             if not is_discovered_url:
-                self.__log_debug("Got cluster info for user-given URL")
-                self.__log_debug("Adding index {} for url {} to "
-                                 "cluster_index_for_user_given_urls"
-                                 "".format(len(self.__cluster_info), url_str) )
 
+                # Check if the user-given URL is in the server's list of rank URLs;
+                # if not, the connection may need to be handled differently
                 if not cluster_info.does_cluster_contain_node( url.host ):
-                    self.__log_debug("Obtained cluster addresses do not contain user given URL {}".format(url_str) )
-                    if not self.__is_system_running( cluster_info.head_rank_url ):
-                        self.__log_debug("")
+                    self.__log_debug("Obtained cluster addresses do not contain user given URL: {}".format(url_str) )
+
+                    # Check if the server given head node address is reachable.
+                    # If so, use that URL instead of the user-given one.
+                    # If not, the user will not be able to use the server-known
+                    # address for connecting normally.  The API will need to
+                    # reprocess the user-given URLs with auto-discovery
+                    # disabled, so that the user can issue database commands,
+                    # but where multi-head operations will not be available.
+                    if not self.is_kinetica_running( cluster_info.head_rank_url ):
+
+                        self.__log_warn("Disabling auto-discovery & multi-head operations--"
+                                        "cluster reachable with user-given URL <{}> but not with server-known URL <{}>"
+                                        "".format(url_str, cluster_info.head_rank_url))
+
+                        # Disable auto-discovery and throw exception to reprocess user-given URLs
                         self.__disable_auto_discovery = True
-                        self.__disable_failover = True
-                        self.__log_debug( "Disabling auto detection of "
-                                                     + "server addresses" )
-                        self.__log_warn( "Using user-given URL {} over server provided addresses will be unable to "
-                                         "recover during N+1 or intra-cluster failover events.".format(url_str) )
-                        self.__log_warn( "Disabling API failover mechanism!" )
 
-                        raise GPUdbException( "Could not connect to server-given  addresses: {} (user given URL: {} )"
+                        raise GPUdbException( "Could not connect to server-known head node address: {} (user given URL: {})"
                                               .format(cluster_info, url_str) )
                     # end if
                 # end if
 
-                self.__log_debug( "Adding index {} for URL {} to cluster_index_for_user_given_urls".format( len( self.__cluster_info), url_str ) )
+                self.__log_debug( "Verified connectivity with user-given URL {}; adding index {} to user-given processed cluster list"
+                                  "".format( url_str, len( self.__cluster_info) ) )
                 cluster_index_for_user_given_urls.append( len(self.__cluster_info) )
-            else:
-                self.__log_debug("NOT adding index url {} to "
-                                 "cluster_index_for_user_given_urls"
-                                 "".format( url_str ) )
             # end if
 
+            self.__cluster_info.append( cluster_info )
+
+            self.__log_debug( "Added URL {} -> cluster {}".format( url_str, str(cluster_info) ) )
+            self.__log_debug( "URLs queue after processing this URL (size {}): {}"
+                              "".format( len(url_deque),
+                                         [ str(u) for u in list(url_deque) ] ) )
+
             # Parse the HA ring head nodes in the properties and add them
             # to this queue (only if we haven't processed them already).
             # This could fail due to a hostname regex mismatch.
             ha_ring_head_node_urls = self.__get_ha_ring_head_node_urls( sys_props )
-            self.__log_debug( "Got ha ring head urls: {}"
+            self.__log_debug( "Got HA ring head node URLs: {}"
                               "".format( [ str(u)
                                            for u in ha_ring_head_node_urls] ) )
             for ha_url in ha_ring_head_node_urls:
-                self.__log_debug( "Processing ha ring head urls: {}; host is {}"
-                                  "".format( str(ha_url), ha_url.host ) )
-                ha_host = ha_url.host
-                if ( self.__get_index_of_cluster_containing_node( ha_host ) == -1 ):
+                if ( self.__get_index_of_cluster_containing_node( ha_url.host ) == -1 ):
                     # We have not encountered this cluster yet; add it to the
                     # deque of URLs to process
-                    self.__log_debug( "Currently known clusters don't have this"
-                                      " node; adding the url for processing" )
+                    self.__log_debug( "HA ring head node URL {} not found in known clusters; "
+                                      "adding to queue to process".format(str(ha_url)))
                     url_deque.append( ha_url )
                 else:
-                    self.__log_debug( "Currently known clusters DO have this "
-                                      "node; NOT adding the url for processing" )
+                    self.__log_debug( "HA ring head node URL {} found in known clusters; "
+                                      "skipping".format(str(ha_url)))
                 # end if
             # end for
 
-            self.__log_debug( "URLs queue after processing this ha head nodes "
-                              "(size {}: {})"
+            self.__log_debug( "URLs queue after processing this HA ring's head node URLs (size {}: {})"
                               "".format( len(url_deque),
                                          [ str(u) for u in list(url_deque) ] ) )
         # end while
 
         # Check that we have got at least one working URL
         if ( self.__get_ha_ring_size() == 0 ):
             self.__log_error( "No clusters found at user given URLs {}!"
                               "".format( urls_str ) )
-            raise GPUdbException( "Could not connect to any working Kinetica server! "
-                                  "Given URLs: {}".format( urls_str ) )
+            raise GPUdbException( "Could not connect to any working Kinetica server, given URLs: {}"
+                                  "".format( urls_str ) )
         # end if
 
-        self.__log_debug( "Before re-setting primary for a single "
-                          "cluster '{}' (if needed)".format( self.primary_host ) )
-
-        # If we end up with a single cluster, ensure that its head rank URL is
-        # set as the primary (we need this check in case only a single URL was
-        # given to the constructor BUT it was a worker URL)
+        # Set the primary cluster & head node
         if ( self.__get_ha_ring_size() == 1 ):
-            self.__log_debug( "Only one cluster in the ring; "
-                              "(re-)setting this one as the primary" )
+
             # Mark the single cluster as the primary cluster
             self.__cluster_info[ 0 ].is_primary_cluster = True
 
-            # Save the hostname of the single/primary cluster for future use
+            # Update the primary cluster head node hostname, as the original
+            # one may have been a worker node
+            original_primary_host = self.primary_host
             self.__primary_host = self.__cluster_info[ 0 ].head_rank_url.host
 
             # Also save it in the options for the future
             self.options.primary_host = self.primary_host
-            self.__log_debug( "New primary host name: '{}'"
-                              "".format( self.primary_host ) )
+            self.__log_debug( "Updated primary host name {} -> {} for single-cluster connection"
+                              "".format( original_primary_host, self.primary_host ) )
         else:
-            self.__log_debug( "More than one cluster in the ring" )
-
             # If the user has not given any primary host AND all the user
             # given URLs belong to a single cluster, set that as the primary
             if (not self.primary_host):
-                self.__log_debug( "No primary host given & more than one user "
-                                  "given URL: {}".format( urls_str ) )
 
                 all_urls_in_same_cluster = ( cluster_index_for_user_given_urls.count(
                     cluster_index_for_user_given_urls[0] )
                                              == len( cluster_index_for_user_given_urls ) )
-                self.__log_debug( "cluster_index_for_user_given_urls {} "
-                                  "".format( cluster_index_for_user_given_urls ) )
-                self.__log_debug( "all_urls_in_same_cluster {} "
-                                  "".format( all_urls_in_same_cluster ) )
                 if all_urls_in_same_cluster:
                     primary_index = cluster_index_for_user_given_urls[0]
-                    self.__log_debug( "All user given URLs belong to the same "
-                                      "cluster! Index {}".format( primary_index ) )
 
-                    # Save the hostname of the single/primary cluster for future use
+                    # Save the hostname of the newly identified primary cluster
+                    original_primary_host = self.primary_host
                     self.__primary_host = self.__cluster_info[ primary_index ].head_rank_url.host
 
-                    # Also save it in the options for the future
+                    # Also save it in the options
                     self.options.primary_host = self.primary_host
-                    self.__log_debug( "New primary host name: '{}'"
-                                      "".format( self.primary_host ) )
+                    self.__log_debug( "Updated primary host name {} -> {} for multi-cluster connection"
+                                      "".format( original_primary_host, self.primary_host ) )
                 else:
-                    self.__log_debug( "User given URLs belong to different clusters" )
+                    self.__log_debug( "Could not update primary host name for multi-cluster connection, as user-given URLs belong to different clusters" )
                 # end innermost if
             # end if
         # end if
 
         # Flag the primary cluster as such and ensure it's the first element in
         # host_addresses
         # ----------------------------------------------------------------------
-        self.__log_debug( "Before finding the primary cluster in the list of clusters..."  )
-        # Check if the primary host exists in the list of user given hosts
-        primary_index = self.__get_index_of_cluster_containing_node( self.primary_host )
-
-        self.__log_debug( "Checking if the primary cluster is in the"
-                          " ring; index: {}".format( primary_index ) )
-        if ( primary_index != -1 ):
-            self.__log_debug( "Found match!  setting the cluster "
-                              "as primary: {}".format( primary_index ) )
-            # There is a match; mark the respective cluster as the primary cluster
-            primary_cluster = self.__cluster_info[ primary_index ]
-            primary_cluster.is_primary_cluster = True
-
-            if ( primary_index > 0 ):
-                self.__log_debug( "Primary cluster not at the "
-                                  "forefront; put it there" )
-                # Note: Do not combine the nested if with the top level if; will change
-                #       logic and may end up getting duplicates of the primary URL
-
-                # Move the primary URL to the front of the list
-                self.__cluster_info.remove( primary_cluster )
-                self.__cluster_info.insert( 0, primary_cluster )
-            # end inner if
-        else:
-            self.__log_debug( "Did not find match!  This should never "
-                              "happen!!!!!! Index is {}"
+        if self.primary_host:
+            # Check if the primary host exists in the list of user given hosts
+            primary_index = self.__get_index_of_cluster_containing_node( self.primary_host )
+
+            self.__log_debug( "Checking if the primary cluster is in the ring; index: {}"
                               "".format( primary_index ) )
+            if ( primary_index != -1 ):
+                self.__log_debug( "Setting that cluster as primary" )
+                # There is a match; mark the respective cluster as the primary cluster
+                primary_cluster = self.__cluster_info[ primary_index ]
+                primary_cluster.is_primary_cluster = True
+
+                if ( primary_index > 0 ):
+                    self.__log_debug( "Moving primary cluster to the front of the list" )
+                    # Note: Do not combine the nested if with the top level if; will change
+                    #       logic and may end up getting duplicates of the primary URL
+
+                    # Move the primary URL to the front of the list
+                    self.__cluster_info.remove( primary_cluster )
+                    self.__cluster_info.insert( 0, primary_cluster )
+                # end inner if
+            else:
+                # Note that if no primary URL is specified by the user, then primary_index
+                # above would be -1; but we need not handle that case since it would be
+                # a no-op
+                self.__log_debug( "Designated primary cluster with host {} not found in cluster list"
+                                  "".format( self.primary_host ) )
+            # end if
         # end if
 
-        # Note that if no primary URL is specified by the user, then primary_index
-        # above would be -1; but we need not handle that case since it would be
-        # a no-op
-
         # Randomize the URL indices taking care that the primary cluster is
         # always at the front
         self.__randomize_clusters()
     # end __parse_urls_once
 
 
     def __randomize_clusters( self ):
@@ -5742,57 +5677,49 @@
         is given by the user; in that case, we need to keep the primary host's
         index as the first one in the list so that upon failover, when we cricle
         back, we always pick the first/primary host up again.
 
         Also, with the new ha failover order, it's not always random.  We might
         want to keep it in the order found.
         """
-        self.__log_debug( "Ring size {}".format( self.__get_ha_ring_size() ) )
         # Re-create the list of HA URL indices (automatically in an
         # monotonically increasing order)
         self.__cluster_indices = []
         for i in range(0, self.__get_ha_ring_size()):
             self.__cluster_indices.append( i )
         # end
-        self.__log_debug( "Refreshed cluster indices list: {}"
-                          "".format( self.__cluster_indices ) )
 
         # If the user chose to failover in a random fashion, we need to
         # shuffle the list (while ensure the primary always gets chosen
         # first)
-        self.__log_debug( "Failover order: {}".format( self.__ha_failover_order ) )
         if ( self.__ha_failover_order == GPUdb.HAFailoverOrder.RANDOM ):
             if not self.primary_host:
-                self.__log_debug( "No primary host given; shuffling all elements" )
+                self.__log_debug( "Randomizing all clusters for HA failover--no primary host given" )
                 # We don't have any primary URL; so treat all URLs similarly
                 # Randomly order the HA clusters and pick one to start working with
                 random.shuffle( self.__cluster_indices )
             else:
-                self.__log_debug( "Primary host given ({}); shuffling all but first element"
+                self.__log_debug( "Randomizing all cluster for HA failover except for primary host {}"
                                   "".format( str( self.primary_host ) ) )
                 # Shuffle from the 2nd element onward, only if there are more than
                 # two elements, of course
                 if ( len( self.__cluster_indices ) > 2 ):
                     # Shuffle from the 2nd element onward
                     non_primary_host_indices = list( range(1, len(self.__cluster_indices)) )
                     random.shuffle( non_primary_host_indices )
 
                     # Put them back together
                     self.__cluster_indices = ([ 0 ] + non_primary_host_indices)
                 # end inner if
             # end inner if
         # end if
-        self.__log_debug( "Final cluster indices list: {}"
-                          "".format( self.__cluster_indices ) )
 
         # This will keep track of which cluster to pick next (an index of
         # randomly shuffled indices)
         self.__set_curr_cluster_index_pointer( 0 )
-        self.__log_debug( "Cluster index pointer: {}"
-                          "".format( self.__get_curr_cluster_index_pointer() ) )
     # end __randomize_clusters
 
 
 
     def __get_index_of_cluster_containing_node( self, hostname ):
         """Given a hostname or IP address, check if the known clusters
         have/contain it.
@@ -5802,33 +5729,30 @@
                 The hostname or IP address to search for.
 
         Returns:
             The index of the cluster that contains this node; -1
             if not found in the system.
         """
         if ( not self.__cluster_info ):
-            self.__log_debug( "host addresses are empty; returning -1")
             return -1
         # end if
 
         # Check each cluster for the hostname/IP
         i = 0
         for cluster_address in self.__cluster_info:
             if ( cluster_address.does_cluster_contain_node( hostname ) ):
-                self.__log_debug( "Found match at {}th iteration".format( i ) )
+                self.__log_debug( "Host match found in cluster #{}".format( i ) )
                 return i
             # end if
 
-            self.__log_debug( "Did not find match at {}th iteration".format( i ) )
             i += 1 # need to increase the index!
         # end for
 
         # Did not find any cluster that uses/has the given hostname/IP address
-        self.__log_debug( "Did not find any cluster with hostname '{}'; "
-                          "returning -1".format( hostname ) )
+        self.__log_debug( "Did not find any cluster with hostname <{}>".format( hostname ) )
         return -1
     # end __get_index_of_cluster_containing_node
 
 
 
     def __get_system_status_information( self, url ):
         """Given a URL, return the system status information.
@@ -5838,15 +5762,15 @@
                 The URL of the server to get information from.
 
         Returns:
             A dict containing the system status
         """
         # Call /show/system/status at the given URL
         try:
-            self.__log_debug( "Getting system status from: {}".format( str(url) ) )
+            self.__log_debug( "Getting system status for URL: {}".format( str(url) ) )
             sys_status = self.__submit_request( C._ENDPOINT_SHOW_SYSTEM_STATUS,
                                                 {"options": {}},
                                                 url = url,
                                                 timeout = self.__DEFAULT_INTERNAL_ENDPOINT_CALL_TIMEOUT,
                                                 convert_to_attr_dict = True )
             if not sys_status.is_ok():
                 raise GPUdbException( "Could not obtain system status: {}"
@@ -5856,130 +5780,39 @@
             self.__log_debug("Caught unauthorized exception: {}".format( str(ex) ))
             raise
         except (GPUdbConnectionException, GPUdbExitException) as ex:
             # Also propagate special connection or exit errors
             self.__log_debug("Caught conn/exit exception: {}".format( str(ex) ))
             raise
         except Exception as ex:
-            raise GPUdbException( "Error calling /show/sys/status at URL {}: {}"
-                                  "".format( str(url),
+            raise GPUdbException( "Error calling {} at URL {}: {}"
+                                  "".format( C._ENDPOINT_SHOW_SYSTEM_STATUS,
+                                             str(url),
                                              GPUdbException.stringify_exception( ex ) ) )
         # end try
 
         # Get the 'system' entry in the status response and parse it
         if C._SHOW_SYSTEM_STATUS_RESPONSE_SYSTEM not in sys_status.status_map:
-            raise GPUdbException( "No entry for '{}' in /show/system/status status map!"
-                                  "".format( C._SHOW_SYSTEM_STATUS_RESPONSE_SYSTEM ) )
+            raise GPUdbException( "No entry for <{}> in {} status map!"
+                                  "".format( C._SHOW_SYSTEM_STATUS_RESPONSE_SYSTEM, C._ENDPOINT_SHOW_SYSTEM_STATUS ) )
         # end if
 
         system_status_str = sys_status.status_map[ C._SHOW_SYSTEM_STATUS_RESPONSE_SYSTEM ]
-        self.__log_debug( "Got system status: '{}'".format( system_status_str ) )
+        self.__log_debug( "Got system status {} for URL: {}".format( system_status_str, str(url)) )
         try:
             system_status = json.loads( system_status_str )
         except Exception as ex:
-            raise GPUdbException( "Could not parse system status; supposed to be a "
-                                  "valid JSON: '{}'".format( system_status_str ) )
+            raise GPUdbException( "Could not parse system status {} for URL: {}"
+                                  "".format( system_status_str, str(url) ) )
 
         return system_status
     # end __get_system_status_information
 
 
 
-    def __is_cluster_operation_running( self, sys_status_info ):
-        """Given the response to a /show/system/status query, figure out whether
-        the server is performing a cluster operation.
-
-        Parameters:
-            sys_status_info (dict)
-                A dict containing the cluster's status.
-
-        Returns:
-            True if the system is running a cluster operation, False otherwise.
-        """
-        # Then look for 'status' and see if it is 'running'
-        if ( C._SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_OPERATION_RUNNING in
-             sys_status_info ):
-            cluster_operation_running = sys_status_info[ C._SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_OPERATION_RUNNING ]
-            self.__log_debug( "Got status: {}".format( cluster_operation_running ) )
-
-            if ( cluster_operation_running
-                 == C._SHOW_SYSTEM_STATUS_RESPONSE_TRUE
-            ):
-                self.__log_debug( "Returning true")
-                return True
-            # end inner if
-        # end if
-
-        self.__log_debug( "Returning false")
-        return False
-    # end __is_cluster_operation_running
-
-
-
-    def __is_cluster_irrecoverable( self, system_status_info ):
-        """Given the response to a /show/system/status query, figure out whether
-        the server is in an irrecoverable situation.
-
-        Parameters:
-            system_status_info (dict)
-                A dict containing the cluster's status.
-
-        Returns:
-            True if the cluster is in an irrecoverable state, False otherwise.
-        """
-        # Look for 'cluster_operation_status' and see if it is 'irrecoverable'
-        if ( C._SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_OPERATION_STATUS in
-             system_status_info ):
-            cluster_operation_status = system_status_info[ C._SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_OPERATION_STATUS ]
-            self.__log_debug( "Got status: {}".format( cluster_operation_status ) )
-
-            if ( cluster_operation_status
-                 == C._SHOW_SYSTEM_STATUS_RESPONSE_CLUSTER_IRRECOVERABLE
-            ):
-                self.__log_debug( "Returning true")
-                return True
-            # end inner if
-        # end if
-
-        self.__log_debug( "Returning false")
-        return False
-    # end __is_cluster_irrecoverable
-
-
-    def __is_rank_leaderless( self, system_status_info ):
-        """Given the response to a /show/system/status query, figure out whether
-        the rank that responded is leaderless.
-
-        Parameters:
-            system_status_info (dict)
-                A dict containing the cluster's status.
-
-        Returns:
-            True if the cluster is in a leaderless state, False otherwise.
-        """
-        # Look for 'status' and see if it is 'leaderless'
-        if ( C._SHOW_SYSTEM_STATUS_RESPONSE_STATUS in
-             system_status_info ):
-            system_status = system_status_info[ C._SHOW_SYSTEM_STATUS_RESPONSE_STATUS ]
-            self.__log_debug( "Got status: {}".format( system_status ) )
-
-            if ( system_status
-                 == C._SHOW_SYSTEM_STATUS_RESPONSE_LEADERLESS
-            ):
-                self.__log_debug( "Returning true")
-                return True
-            # end inner if
-        # end if
-
-        self.__log_debug( "Returning false")
-        return False
-    # end __is_rank_leaderless
-
-
-
     def __is_system_running( self, url = None, sys_status_info = None ):
         """Given a URL, return whether the server is running at that address.
 
         Parameters:
             url (:class:`GPUdb.URL`)
                 The URL of the server to get information from.
 
@@ -5998,54 +5831,47 @@
             # given
             if sys_status_info is None:
                 raise GPUdbException( "Parameter 'url' is not given; therefore, "
                                       "parameter 'sys_status_info' must be "
                                       "given; but it is not!")
         # end
 
+        is_running = False
+
         try:
             if sys_status_info is None:
                 sys_status_info = self.__get_system_status_information( url )
             # end if
 
             # Then look for 'status' and see if it is 'running'
             # Get the 'system' entry in the status response and parse it
             if C._SHOW_SYSTEM_STATUS_RESPONSE_STATUS not in sys_status_info:
                 raise GPUdbException( "Could not find key '{}' is system status information!"
                                       "".format( C._SHOW_SYSTEM_STATUS_RESPONSE_STATUS ) )
             # end if
 
             system_status_str = sys_status_info[ C._SHOW_SYSTEM_STATUS_RESPONSE_STATUS ]
-            self.__log_debug( "Got system status from {}: '{}'"
-                              "".format( str(url), system_status_str ) )
 
             if ( system_status_str == C._SHOW_SYSTEM_STATUS_RESPONSE_RUNNING ):
-                self.__log_debug( "System at {} is running; returning true"
+                self.__log_debug( "System running at URL {}"
+                                  "".format( str(url) ) )
+                is_running = True
+            else:
+                self.__log_debug( "System not confirmed running at URL {}"
                                   "".format( str(url) ) )
-                return True
         except GPUdbUnauthorizedAccessException as ex:
             # Any permission related problem should get propagated
-            self.__log_debug("Caught unauthorized exception: {}".format( str(ex) ))
             raise
-        except (GPUdbConnectionException, GPUdbExitException) as ex:
-            # Also propagate special connection or exit errors
-            self.__log_debug("Caught conn/exit exception: {}".format( str(ex) ))
-            raise
-        except socket.timeout as ex:
-            # A socket error means we could not reach the system
-            self.__log_error( "{} caught exception: {}"
-                              "".format( str(url), str(ex) ) )
-        except GPUdbException as ex:
+        except Exception as ex:
             # Any error means we don't know whether the system is running
-            self.__log_debug( "{} caught exception: {}"
+            self.__log_warn( "Exception checking running status of URL {} -- {}"
                               "".format( str(url), str(ex) ) )
         # end try
 
-        self.__log_debug( "{} returning false".format( str(url) ) )
-        return False
+        return is_running
     # end __is_system_running
 
 
 
     def __get_system_properties( self, url ):
         """Given a URL, return the system properties information.
 
@@ -6054,50 +5880,50 @@
                 The URL of the server to get information from.
 
         Returns:
             The properties map, a dict object.
         """
         # Call /show/system/properties at the given URL
         try:
-            self.__log_debug( "Getting system status from: {}".format( str(url) ) )
+            self.__log_debug( "Getting system properties for URL: {}".format( str(url) ) )
             sys_prop_resp = self.__submit_request( C._ENDPOINT_SHOW_SYSTEM_PROPERTIES,
                                                    {"options": {}},
                                                    url = url,
                                                    timeout = self.__DEFAULT_INTERNAL_ENDPOINT_CALL_TIMEOUT,
                                                    convert_to_attr_dict = True )
         except GPUdbUnauthorizedAccessException as ex:
             # Any permission related problem should get propagated
             self.__log_debug("Caught unauthorized exception: {}".format( str(ex) ))
             raise
         except (GPUdbConnectionException, GPUdbExitException) as ex:
             # Also propagate special connection or exit errors
             self.__log_debug("Caught conn/exit exception: {}".format( str(ex) ))
             raise
         except Exception as ex:
-            raise GPUdbException( "Error calling /show/sys/properties at URL {}: {}"
-                                  "".format( str(url),
+            raise GPUdbException( "Error calling {} at URL {}: {}"
+                                  "".format( C._ENDPOINT_SHOW_SYSTEM_PROPERTIES,
+                                             str(url),
                                              GPUdbException.stringify_exception( ex ) ) )
         # end try
 
         if not sys_prop_resp.is_ok():
-            raise GPUdbException( "Could not obtain system properties: {}"
-                                  "".format( sys_prop_resp.get_error_msg() ) )
+            raise GPUdbException( "Could not get system properties for URL: {} -- {}"
+                                  "".format( str(url), sys_prop_resp.get_error_msg() ) )
 
         # Get the property map from the response and return it
         property_map = sys_prop_resp.property_map
-        self.__log_debug( "Got system properties from: {}".format( str(url) ) )
+        self.__log_debug( "Got system properties for URL: {}".format( str(url) ) )
 
         # Is HTTPD being used (helps in figuring out the host manager URL)
         if C._SYSTEM_PROPERTIES_RESPONSE_ENABLE_HTTPD in property_map:
-            if (property_map[ C._SYSTEM_PROPERTIES_RESPONSE_ENABLE_HTTPD ].lower() == "true"):
-                self.__log_debug( "Setting use httpd to true" )
+            if (property_map[ C._SYSTEM_PROPERTIES_RESPONSE_ENABLE_HTTPD ].lower() == C._SYSTEM_PROPERTIES_RESPONSE_TRUE):
+                self.__log_debug( "Setting use httpd to true for URL: {}".format( str(url) ) )
                 self.__use_httpd = True
             # end inner if
         # end if
-        self.__log_debug( "Using httpd? {}".format( self.__use_httpd ) )
 
         return property_map
     # end __get_system_properties
 
     def __update_server_version(self):
         """
         Retrieves the server version by calling `__getsystem_properties` and updates
@@ -6109,59 +5935,14 @@
             sys_props = self.__get_system_properties(GPUdb.URL(self.gpudb_full_url))
             if C._SYSTEM_PROPERTIES_RESPONSE_SERVER_VERSION in sys_props:
                 self.server_version = sys_props[C._SYSTEM_PROPERTIES_RESPONSE_SERVER_VERSION]
         except GPUdbException as ex:
             msg = "Failed to get database version from the server; " + str(ex)
             raise GPUdbException(msg)
 
-    def __is_intra_cluster_failover_enabled( self, sys_properties ):
-        """Given system properties, deduce if the given cluster has N+1 failover
-        enabled or not.  For it to be enabled, either head failover or worker
-        failover need to be turned on.
-
-        Parameters:
-            sys_properties (dict)
-                A dict containing system properties.
-
-        Returns:
-            True if the cluster has N+1 or intra-cluster failover enabled.
-            False otherwise.
-        """
-        if not isinstance( sys_properties, (dict, collections.OrderedDict) ):
-            raise GPUdbException( "Argument 'sys_properties' must be a dict, "
-                                  "gave '{}'".format( str(type( sys_properties )) ) )
-
-        is_intra_cluster_failover_enabled = False
-
-        # Get the conf param for N+1 failover for the head rank
-        if C._SYSTEM_PROPERTIES_RESPONSE_HEAD_FAILOVER not in sys_properties:
-            raise GPUdbException( "Missing value for '{}' in system properties"
-                                  "".format( C._SYSTEM_PROPERTIES_RESPONSE_HEAD_FAILOVER ) )
-        head_failover = sys_properties[ C._SYSTEM_PROPERTIES_RESPONSE_HEAD_FAILOVER ]
-
-        # Check if head failover is turned on
-        if ( head_failover == C._SYSTEM_PROPERTIES_RESPONSE_TRUE ):
-            is_intra_cluster_failover_enabled = True
-
-        # Get the conf param for N+1 failover for worker ranks
-        if C._SYSTEM_PROPERTIES_RESPONSE_WORKER_FAILOVER not in sys_properties:
-            raise GPUdbException( "Missing value for '{}' in system properties"
-                                  "".format( C._SYSTEM_PROPERTIES_RESPONSE_WORKER_FAILOVER ) )
-        worker_failover = sys_properties[ C._SYSTEM_PROPERTIES_RESPONSE_WORKER_FAILOVER ]
-
-        # Check if worker failover is turned on
-        if ( worker_failover == C._SYSTEM_PROPERTIES_RESPONSE_TRUE ):
-            is_intra_cluster_failover_enabled = True
-
-        self.__log_debug( "is_intra_cluster_failover_enabled: {}"
-                          "".format( is_intra_cluster_failover_enabled ) )
-        return is_intra_cluster_failover_enabled
-    # end __is_intra_cluster_failover_enabled
-
-
 
     def __get_server_version( self, sys_properties ):
         """Given system properties, extract the version of Kinetica being run.
         If not available, return None.
 
         Parameters:
             sys_properties (dict)
@@ -6176,15 +5957,15 @@
 
         return sys_properties[ C._SYSTEM_PROPERTIES_RESPONSE_SERVER_VERSION ]
     # end __get_server_version
 
 
 
     def __get_rank_urls( self, sys_props, hostname_regex = None ):
-        """Given system properties, extrace the head- and worker rank URLs.
+        """Given system properties, extract the head- and worker rank URLs.
 
         Parameters:
             sys_props (dict)
                 A dictionary containing all relevant system properties.
 
             hostname_regex (str)
                 The regex to match the URLs against; if None, then in case the
@@ -6206,17 +5987,21 @@
         rank_urls = []
 
         # Get the rank URLs and process them
         if ( (C._SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS in sys_props)
              and sys_props[ C._SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS ] ):
 
             server_urls = sys_props[ C._SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS ]
-            self.__log_debug( "Got property '{}' value: '{}'"
-                              "".format( C._SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS,
-                                         server_urls ) )
+            self.__log_debug(
+                    "Known rank URLs <{}> from server: {}{}".format(
+                            C._SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS,
+                            server_urls,
+                            "" if not hostname_regex else " vs. user-given regex: " + hostname_regex
+                    )
+            )
 
             # Get the URL for each of the ranks
             # ---------------------------------
             url_lists = server_urls.split(";")
 
             # Parse each entry (corresponds to a rank, could be an
             # empty slot for a removed rank)
@@ -6242,61 +6027,52 @@
                     try:
                         url = GPUdb.URL( url_str )
                     except Exception as ex:
                         raise GPUdbException( "Unable to parse rank URL '{}' "
                                               "".format( url_str) )
                     # end try
 
-                    if hostname_regex is not None:
+                    if hostname_regex is None:
+                        # No regex is given, so we'll take the first one
+                        self.__log_debug( "Keeping rank URL: {}".format( url_str ) )
+                        do_add = True
+                    else:
                         # Check if this URL matches the given regex
                         do_add = re.match( hostname_regex, url.host )
                         do_add = (do_add is not None)
-                        self.__log_debug( "Does rank URL '{}' match hostname "
-                                          "regex '{}' with host '{}'?: {}"
-                                          "".format( url.url,
-                                                     hostname_regex.pattern,
-                                                     url.host, do_add
-                                        ) )
-                    else:
-                        # No regex is given, so we'll take the first one
-                        self.__log_debug( "No hostname regex given; "
-                                          + "adding rank url: '{}'"
-                                          .format( str(url) ) )
-                        do_add = True
+                        if do_add:
+                            self.__log_debug( "Keeping matching rank URL: {}".format( url_str ) )
+                        else:
+                            self.__log_debug( "Skipping non-matching rank URL: {}".format( url_str ) )
                     # end if
 
                     if do_add:
                         # Found a match (whether a regex is given or not)
                         rank_urls.append( url )
                         found = True
                         break
                     # end if
                 # end for
 
                 if not found:
-                    # It's a problem to not have any URL for this rank!
+                    # If there's no valid URL matching the regex throw a match error
                     if (hostname_regex is not None):
-                        # The reason we don't have a URL is because it didn't
-                        # match the given regex
-                        msg = ("No matching IP/hostname found for worker {} "
-                               "(given hostname regex '{}')"
-                               "".format( i, hostname_regex.pattern ) )
-                        raise GPUdbHostnameRegexFailureException( msg )
+                        raise GPUdbHostnameRegexFailureException(
+                                "No valid matching IP/hostname found for worker: {}".format( i )
+                        )
                     # end if
 
-                    # We couldn't find it for some other reason
-                    raise GPUdbException("No matching IP/hostname found for worker {}"
-                                         "".format( i ) )
+                    # If there's no valid URL throw an error
+                    raise GPUdbException("No valid IP/hostname found for worker: {}".format( i ) )
                 # end if
             # end for
         else:
-            self.__log_debug( "No entry for '{}' in {} response; returning "
-                              "empty list"
-                              "".format( C._SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS,
-                                         C._ENDPOINT_SHOW_SYSTEM_PROPERTIES ) )
+            self.__log_debug( "No entry for <{}> in {} response".format(
+                              C._SYSTEM_PROPERTIES_RESPONSE_SERVER_URLS,
+                              C._ENDPOINT_SHOW_SYSTEM_PROPERTIES ))
         # end if
 
         return rank_urls
     # end __get_rank_urls
 
 
 
@@ -6317,27 +6093,28 @@
                 first one.
 
         Returns:
             A list of strings containing hostnames or IP addresses along with
             the protocol.  These are not full URLs.
         """
 
+        self.__log_debug( "Extracting server-known host names from system properties{}"
+                          "".format( "" if not hostname_regex else " using user-given regex: " + hostname_regex ) )
+
         # Get the total number of hosts/machines in the cluster
         if C._SYSTEM_PROPERTIES_RESPONSE_NUM_HOSTS not in sys_props:
             raise GPUdbException( "Missing value for {}"
                                   "".format( C._SYSTEM_PROPERTIES_RESPONSE_NUM_HOSTS ) )
 
         num_hosts = sys_props[ C._SYSTEM_PROPERTIES_RESPONSE_NUM_HOSTS ]
         try:
             num_hosts = int( num_hosts )
         except:
-            raise GPUdbException( "Unparsable entry for '{}' ({}) in system "
-                                  "properties; need an integer"
-                                  "".format( C._SYSTEM_PROPERTIES_RESPONSE_NUM_HOSTS,
-                                             num_hosts ) )
+            raise GPUdbException( "Unparsable entry for '{}' ({}); need an integer"
+                                  "".format( C._SYSTEM_PROPERTIES_RESPONSE_NUM_HOSTS, num_hosts ) )
         # end try
 
         # Extract the hostnames from the system properties
         cluster_host_names = []
         for i in range(0, num_hosts):
             # Each hostname is listed individually in the system properties
             # as 'conf.host<i>_public_urls'
@@ -6357,33 +6134,34 @@
             for j in range(0, len(hostnames)):
                 hostname = hostnames[ j ]
 
                 # If a regex is given, get a matching hostname--if there isn't
                 # a match, throw an error.  If no regex is given, take
                 # the first hostname.
                 do_add = False
-                if (hostname_regex is not None):
+                if hostname_regex is None:
+                    # No regex is given, so we'll take the first one
+                    self.__log_debug( "Keeping hostname: {}".format( hostname ) )
+                    do_add = True
+                else:
                     # The hostname might have the protocol; strip that out
                     split_hostname = hostname.split( "://" )
                     if ( len(split_hostname) > 1 ):
                         host = split_hostname[ 1 ]
                     else:
                         host = split_hostname[ 0 ]
                     # end if
 
                     # Check if this hostname matches the regex
                     do_add = re.match( hostname_regex, host )
                     do_add = (do_add is not None)
-                    self.__log_debug( "Does hostname {} match hostname regex "
-                                      "'{}'? {}".format( host,
-                                                         hostname_regex.pattern,
-                                                         do_add ) )
-                else:
-                    # No regex given, so take the first one
-                    do_add = True
+                    if do_add:
+                        self.__log_debug( "Keeping matching hostname: {}".format( hostname ) )
+                    else:
+                        self.__log_debug( "Skipping non-matching hostname: {}".format( hostname ) )
                 # end if
 
                 if ( do_add ):
                     # We've decided to use this hostname
                     cluster_host_names.append( hostname )
                     found = True
                     break
@@ -6391,16 +6169,15 @@
             # end for
 
             if not found:
                 # No eligible hostname found!
                 if (hostname_regex is not None):
                     # The reason we don't have a URL is because it didn't
                     # match the given reges
-                    msg = ("No matching hostname found for host #{} (given "
-                           "hostname regex {})"
+                    msg = ("No matching hostname found for host #{} (given hostname regex {})"
                            "".format( i, hostname_regex.pattern ) )
                     raise GPUdbHostnameRegexFailureException( msg )
                 # end inner if
 
                 raise GPUdbException("No matching hostname found for host #{}."
                                      "".format( i ) )
             # end if
@@ -6414,15 +6191,14 @@
     def __create_host_manager_url( self, url, host_manager_port ):
         """Given a :class:`GPUdb.URL` and a host manager port, create
         another :class:`GPUdb.URL` object that represents the host manager
         URL.  Return that.
         """
         # Create the host manager URL
         try:
-            self.__log_debug( "Using httpd? {}".format( self.__use_httpd ) )
             # Create the host manager URL using the user given (or default) port
             if ( ( self.__use_httpd == True )
                  and ( len(url.path) > 0) ):
                 # We're using HTTPD, so use the appropriate URL
                 # (likely, http[s]://hostname_or_IP:port/gpudb-host-manager)
                 # We won't always have a port (e.g. for cloud instances).  So,
                 # just replace the last bit of the path, i.e. gpudb-X with
@@ -6436,15 +6212,15 @@
                 # use the host manager port
                 host_manager_url = GPUdb.URL( "{protocol}://{host}:{port}"
                                               "".format( protocol = url.protocol,
                                                          host = url.host,
                                                          port = host_manager_port ) )
             # end if
         except Exception as ex:
-            raise GPUdbException( GPUdbException.stringify_exception( ex ) )
+            raise GPUdbException( "Error creating the host manager URL: {}".format(GPUdbException.stringify_exception( ex )) )
 
         self.__log_debug( "Created host manager URL: {}".format( host_manager_url ) )
         return host_manager_url
     # end __create_host_manager_url
 
 
 
@@ -6472,15 +6248,16 @@
             host_manager_url = self.__create_host_manager_url( url,
                                                                host_manager_port )
         except Exception as ex:
             raise GPUdbException( GPUdbException.stringify_exception( ex ) )
 
         # Create an object to store all the information about this cluster
         cluster_info = GPUdb.ClusterAddressInfo( url,
-                                                 host_manager_url = host_manager_url )
+                                                 host_manager_url = host_manager_url,
+                                                 logging_level = self.log.getEffectiveLevel() )
 
         # Check if this cluster is the primary cluster
         self.__log_debug( "Checking if this is the primary cluster; "
                           "self.primary_host: {}"
                           "".format( self.primary_host ) )
         if ( self.primary_host
              and cluster_info.does_cluster_contain_node( self.primary_host ) ):
@@ -6511,33 +6288,31 @@
 
             sys_props (dict)
                 A dictionary containing system properties for the cluster.
 
         Returns:
             A :class:`GPUdb.ClusterAddressInfo` object.
         """
-        # Figure out if this cluster has N+1 failover enabled
-        is_intra_cluster_failover_enabled = self.__is_intra_cluster_failover_enabled( sys_props )
-        self.__log_debug( "Is intra-cluster failover enabled?: {}"
-                          "".format( is_intra_cluster_failover_enabled ) )
+        self.__log_debug( "Establishing a cluster record associated with URL: {}"
+                          "".format( str(url) ) )
 
         # Get the rank URLs (head and worker ones)
         rank_urls = self.__get_rank_urls( sys_props, self.options.hostname_regex )
 
         # Get the head node URL and keep it separately
         if ( len(rank_urls) > 0 ):
-            self.__log_debug( "Got rank urls (including rank-0): {}"
-                              "".format( [str(u) for u in rank_urls] ) )
+            self.__log_debug( "Assigning head rank URL {} from server-known rank URLs: {}"
+                              "".format( rank_urls[0], [str(u) for u in rank_urls] ) )
             head_rank_url = rank_urls.pop( 0 )
         else:
             # No ranks were found from system properties; so just use the given
             # URL as the head rank URL
-            head_rank_url = url
-            self.__log_debug( "No worker rank urls; using rank-0: {}"
+            self.__log_debug( "Assigning head rank URL to the user-given one {}, as no server-known worker rank URLs found"
                               "".format( str(url) ) )
+            head_rank_url = url
         # end if
 
         # Get hostnames for all the nodes/machines in the cluster
         cluster_hostnames = self.__get_host_names_from_system_properties( sys_props,
                                                                           self.options.hostname_regex )
 
         # Create the host manager URL
@@ -6551,32 +6326,26 @@
         server_version = self.__get_server_version( sys_props )
 
         # Create an object to store all the information about this cluster
         cluster_info = GPUdb.ClusterAddressInfo( head_rank_url,
                                                  rank_urls,
                                                  cluster_hostnames,
                                                  host_manager_url,
-                                                 None, # no need to give an HM port
-                                                 False,
-                                                 is_intra_cluster_failover_enabled,
-                                                 server_version )
+                                                 is_primary_cluster = False,
+                                                 server_version = server_version,
+                                                 logging_level = self.log.getEffectiveLevel() )
 
         # Check if this cluster is the primary cluster
-        self.__log_debug( "Checking if this is the primary cluster; "
-                          "self.primary_host: {}"
-                          "".format( self.primary_host ) )
         if ( self.primary_host
              and cluster_info.does_cluster_contain_node( self.primary_host ) ):
             # Yes, it is; mark this cluster as the primary cluster
             cluster_info.is_primary_cluster = True
+            self.__log_debug( "Marked this cluster as primary" )
         # end if
 
-        self.__log_debug( "Is primary cluster?: {}"
-                          "".format( cluster_info.is_primary_cluster ) )
-
         return cluster_info
     # end __create_cluster_address_info
 
 
 
 
     def __get_ha_ring_head_node_urls( self, sys_props ):
@@ -6588,14 +6357,19 @@
                 A dictionary containing system properties for some cluster.
 
         Returns:
             A list of full URLs for each of the head nodes in the
             high availability cluster, if any is set up.
         """
 
+        hostname_regex = self.options.hostname_regex
+
+        self.__log_debug( "Extracting server-known HA head node URLs from system properties{}"
+                          "".format( "" if not hostname_regex else " using user-given regex: " + hostname_regex ) )
+
         # If HA is no set up, just return an empty list
         if C._enable_ha not in sys_props:
             return []
 
         # Same deal as above...
         if sys_props[ C._enable_ha ].lower() != "true":
             return []
@@ -6610,16 +6384,14 @@
 
         # Parse the HA ring head node addresses
         # -------------------------------------
         ha_ring_head_node_urls = []
 
         ha_ring_head_nodes_url_lists = ha_ring_head_nodes_str.split(";")
 
-        hostname_regex = self.options.hostname_regex
-
         # Parse each entry (corresponds to a cluster)
         for i in range(0, len(ha_ring_head_nodes_url_lists)):
 
             # Each cluster's head node can have multiple URLs associated with it
             urls = ha_ring_head_nodes_url_lists[ i ].split(",")
             found = False
 
@@ -6635,26 +6407,26 @@
                 try:
                     url = GPUdb.URL( url_str )
                 except Exception as ex:
                     raise GPUdbException( "Unable to parse HA head node URL '{}' "
                                           "".format( url_str) )
                 # end try
 
-                if (hostname_regex is not None):
+                if hostname_regex is None:
+                    # No regex is given, so we'll take the first one
+                    self.__log_debug( "Keeping head node URL: {}".format( url_str ) )
+                    do_add = True
+                else:
                     # Check if this URL matches the given regex
                     do_add = re.match( hostname_regex, url.host )
                     do_add = (do_add is not None)
-                    self.__log_debug( "Does cluster {} head node URL {} match "
-                                      "hostname regex '{}' with host '{}'?: {}"
-                                      "".format( i, str(url),
-                                                 hostname_regex.pattern,
-                                                 url.host, do_add ) )
-                else:
-                    # No regex is given, so we'll take the first one
-                    do_add = True
+                    if do_add:
+                        self.__log_debug( "Keeping matching head node URL: {}".format( url_str ) )
+                    else:
+                        self.__log_debug( "Skipping non-matching head node URL: {}".format( url_str ) )
                 # end if
 
                 if ( do_add ):
                     # Found a match (whether a regex is given or not)
                     ha_ring_head_node_urls.append( url )
                     found = True
                     break
@@ -6663,15 +6435,15 @@
 
             if not found:
                 # No eligible hostname found!
                 if (hostname_regex is not None):
                     # The reason we don't have a URL is because it didn't
                     # match the given reges
                     msg = ("No matching IP/hostname found for cluster with head "
-                           "node URLs '{}' (given hostname regex {})"
+                           "node URLs {} (given hostname regex {})"
                            "".format( ha_ring_head_nodes_url_lists[ i ],
                                       hostname_regex.pattern ) )
                     raise GPUdbHostnameRegexFailureException( msg )
                 # end if
 
                 # We couldn't find it for some other reason
                 raise GPUdbException("No matching IP/hostname found "
@@ -6700,15 +6472,15 @@
         """
         # Return the pointer to the current cluster.  This is the index
         # for `self.__cluster_indices`.  This member is a list of integers
         # which are the *actual* indices for `self.__cluster_info`.  So, this
         # is how it works:
         #
         # `self.__cluster_info` is a list of :class:`GPUdb.ClusterAddressInfo`
-        # objects.  Each member of this list has all the relelvant information
+        # objects.  Each member of this list has all the relevant information
         # for a single Kinetica cluster.  For example, it may be like this:
         # [cluster1, cluster2, cluster3].
         #
         # `self.__cluster_indices` is a list of integers.  This list contains
         # values from range(0, len(self.__cluster_info)).  But they could
         # be in any order.  For example, we could have [2, 0, 1].
         #
@@ -6762,119 +6534,14 @@
         # We pick the "current" cluster as such:
         #  self.__cluster_info[ value_returned_by_this_method ]
 
         return self.__cluster_indices[ self.__get_curr_cluster_index_pointer() ]
     # end __get_curr_cluster_index
 
 
-
-    def __update_cluster_addresses( self, cluster_index ):
-        """For the given cluster in the HA ring, see if an N+1 event happened in the
-        past and try to recover the current list or URLs super quickly.  If N+1
-        is ongoing, simply return rather than spinning and waiting.
-
-        This method is not thread safe.
-
-        Parameters:
-            cluster_index (int)
-                The index of the cluster whose addresses we need to update.
-
-        Returns:
-            True if the cluster addresses were actually updated; False otherwise.
-        """
-        self.__log_debug( "Begin cluster_index {}".format( cluster_index ) )
-        # Retrieve info for the given cluster
-        curr_cluster_info = self.__cluster_info[ cluster_index ]
-        self.__log_debug( "Cluster info: {}".format( str(curr_cluster_info) ) )
-
-        curr_head_rank_url = curr_cluster_info.head_rank_url
-        self.__log_debug( "Given cluster's head rank is at {}"
-                          "".format( str(curr_head_rank_url) ) )
-
-        # Generate the list of the given cluster's rank-0 URL and worker
-        # rank URLs
-        rank_urls = []
-        rank_urls.append( curr_head_rank_url )
-        rank_urls.extend( curr_cluster_info.worker_rank_urls )
-
-        # Try to get the new addresses for shuffled ranks from the
-        # currently known ranks (whichever ones are still in place)
-        for i in range(0, len(rank_urls)):
-            url = rank_urls[ i ]
-            self.__log_debug( "Loop iteration #{}; trying url {}"
-                              "".format( i, str(url) ) )
-
-            # Check the system status (if this rank is responding to requests,
-            # keep pinging until status is back up to running)
-            try:
-                system_status_info = self.__get_system_status_information( url )
-
-                # Check if this rank is in an irrecoverable state
-                if ( self.__is_cluster_irrecoverable( system_status_info ) ):
-                    # The system is hosed; there is no hope of recovery!
-                    self.__log_debug( "Cluster is irrecoverable; returning false ")
-                    return False
-                # end
-
-                # Check if this rank has become leaderless (i.e. no head host
-                # manager can be elected)
-                if ( self.__is_rank_leaderless( system_status_info ) ):
-                    self.__log_debug( "Rank is leaderless; skipping to the next rank ")
-                    continue  # with the next rank
-                # end
-
-                # Check if the system is back up and running
-                if self.__is_system_running( sys_status_info = system_status_info ):
-                    self.__log_debug( "Cluster is running; getting /show/sys/props ")
-                    # System is back up; re-parse the URLs for this cluster
-
-                    # Get the latest system properties of the cluster, if
-                    # can't get it, skip to the next one
-                    sys_props = self.__get_system_properties( url )
-                    cluster_info_refreshed = self.__create_cluster_address_info( url,
-                                                                                 sys_props )
-
-                    self.__log_debug( "Current cluster info:   {}".format( str(curr_cluster_info) ) )
-                    self.__log_debug( "Refreshed cluster info: {}".format( str(cluster_info_refreshed) ) )
-
-                    # Check if the newly gotten addresses are the same as the old
-                    # ones
-                    if ( cluster_info_refreshed == curr_cluster_info ):
-                        # The addresses have remained the same; so we didn't
-                        # make any effective change
-                        self.__log_debug( "Returning false; obtained addresses are the same as the existing one ")
-                        return False
-                    else:
-                        # Replace the stale cluster info with the refreshed one
-                        self.__cluster_info.pop( cluster_index )
-                        self.__cluster_info.insert( cluster_index, cluster_info_refreshed )
-
-                        # We actually changed the addresses for this cluster;
-                        # the caller should know this
-                        self.__log_debug( "Returning true; actually changed addresses ")
-                        return True
-                    # end
-                # end
-            except GPUdbUnauthorizedAccessException as ex:
-                # Any permission related problem should get propagated
-                raise
-            except GPUdbException as ex:
-                self.__log_debug( "Caught GPUdb exception (not doing anything "
-                                  "about it): {}".format( str(ex)) )
-                # Simply try the next rank
-            # end  # end try
-        # end   # end for
-
-        # We couldn't reset the cluster's addresses
-        self.__log_debug( "Returning false (could/did not reset the addresses)")
-        return False
-    # end __update_cluster_addresses
-
-
-
     def __perform_version_check( self, do_print_warning = True ):
         """Perform a version check with the database server.
 
         Parameters:
             do_print_warning (bool)
                 If True, print a warning on version mismatch.
 
@@ -7030,14 +6697,27 @@
         if stringified:
             return str(url)
         else:
             return url
     # end get_hm_url
 
 
+    def get_failover_urls( self ):
+        """Return a list of the head node URLs for each of the clusters in the
+        HA ring in failover order.
+
+        Returns:
+            A list of :class:`GPUdb.URL` objects.
+        """
+        # Get the current URL
+
+        return [ self.__cluster_info[cluster_index].head_rank_url for cluster_index in self.__cluster_indices ]
+    # end get_failover_urls
+
+
     def get_head_node_urls( self ):
         """Return a list of the head node URLs for each of the clusters in the
         HA ring for the database server.
 
         Returns:
             A list of :class:`GPUdb.URL` objects.
         """
@@ -7222,14 +6902,19 @@
 
     @property
     def timeout(self):
         """Gets the timeout used for http connections to GPUdb."""
         return self.__timeout
 
     @property
+    def disable_auto_discovery(self):
+        """Returns whether auto-discovery has been disabled."""
+        return self.__disable_auto_discovery
+
+    @property
     def ha_sync_mode(self):
         return self._ha_sync_mode
 
     @ha_sync_mode.setter
     def ha_sync_mode(self, value ):
         if not isinstance( value, GPUdb.HASynchronicityMode ):
             raise GPUdbException( "HA sync mode must be of type '{}', given {}!"
@@ -7549,15 +7234,15 @@
         except:
             # Some error occurred with inspect; just log the debug message
             self.log.debug( "[GPUdb]  {msg}"
                             "".format( msg = message ) )
     # end __debug
 
     def __log_warn( self, message ):
-        self.log.warn( "[GPUdb] {}".format( message ) )
+        self.log.warning( "[GPUdb] {}".format( message ) )
     # end __warn
 
     def __log_info( self, message ):
         self.log.info( "[GPUdb] {}".format( message ) )
     # end __log_info
 
     def __log_error( self, message ):
@@ -7822,16 +7507,16 @@
                         "code {}: {}".format( url.url, status_code, response_msg ) )
                 self.__log_debug( "Throwing EXIT exception; {}".format( msg ) )
                 raise GPUdbExitException( msg )
             elif ( status_code == httplib.NOT_FOUND ):
                 msg = ( "Endpoint not found ({}) due to status "
                         "code {}: {}".format( url.url, status_code,
                                               response_msg ) )
-                self.__log_debug( "Throwing GPUdb exception; {}".format( msg ) )
-                raise GPUdbException( msg )
+                self.__log_debug( "Throwing EXIT exception; {}".format( msg ) )
+                raise GPUdbExitException( msg )
             # end if
 
             # Decode the http raw response and extract the endpoint response
             # from within it
             decoded_response = self.__read_datum_cext( response_schema,
                                                        response_data,
                                                        None, response_time )
@@ -7878,14 +7563,200 @@
             self.__log_debug( "Throwing GPUdb exception; {}".format( msg ) )
             raise GPUdbException( msg )
         # end try
 
     # end __submit_request_raw
 
 
+    def __submit_request_raw_json( self, url = None, endpoint = None,
+                                  request_body = None,
+                                  timeout = None,
+                                  ):
+        """Submits an arbitrary request to GPUdb via the specified URL and
+        decodes and returns response.  This method is called from the `submit_request_json`
+        generally which handles the *HA Failover* and hence failover is not handled here.
+        The main purpose of this method is to execute a request over HTTP/S to a specific
+        URL and send the response back.
+
+        Parameters:
+            url (GPUdb.URL)
+                The URL to send the request to
+
+            endpoint (str)
+                The endpoint to use (needed for looking up the appropriate
+                request and response avro schema).
+
+            request_body (str)
+                The request body that is either a single JSON record or an array of JSON records
+
+            timeout (int)
+                Optional argument.  If given, then the positive integer would be
+                used for the timeout for the request connection (in seconds).
+                If not given, then the currently configured timeout for this
+                GPUdb object would be used instead.
+
+        Returns:
+            The full JSON (str) response returned by the server. The part carrying relevant information
+            about the output of the operation is the 'data' object.
+        """
+        # Validate the input arguments
+        if not isinstance( url, GPUdb.URL ):
+            msg = ("Argument 'url' must be a GPUdb.URL object; given '{}'"
+                   "".format( str(type(url)) ) )
+            self.__log_debug( msg )
+            raise GPUdbException( msg )
+        # end if
+
+        if not isinstance( endpoint, (basestring, unicode) ):
+            msg = ("Argument 'endpoint' must be a string; given '{}'"
+                   "".format( str(type(endpoint)) ) )
+            self.__log_debug( msg )
+            raise GPUdbException( msg )
+        # end if
+
+        if request_body is None:
+            msg = ("Argument 'request_body' must be provided; given None" )
+            self.__log_debug( msg )
+            raise GPUdbException( msg )
+        # end if
+
+        if type(request_body) != str:
+            raise GPUdbException("'request_body' has to be either a single JSON record or an array of JSON records (as string)")
+
+        # If no user given timeout given, just use the cached one
+        if timeout is None:
+            # Use the cached one
+            timeout = self.timeout
+        else:
+            # The given timeout must be a positive integer
+            try:
+                timeout = int( timeout )
+            except:
+                msg = ("Argument 'timeout' must be an integer value; "
+                       "given '{}'".format( str(type(timeout)) ) )
+                self.__log_debug( msg )
+                raise GPUdbException( msg )
+            # end inner if
+
+            if timeout < 0:
+                msg = ("Argument 'timeout' must be a positive integer value; "
+                       "given '{}'".format( timeout ) )
+                self.__log_debug( msg )
+                raise GPUdbException( msg )
+        # end if
+
+
+        # Log the request and the endpoint at the trace level.  Note that since
+        # string interpolation takes a demonstrably large time (proved via
+        # benchmarking), we need to first check if the log level is on.  That
+        # way, we only create the interpolated string when it will be used.
+        if self.__is_log_level_trace_enabled():
+            self.__log_trace( "Sending {} request {} to {}"
+                              "".format( endpoint, request_body, str(url) ) )
+
+        http_conn = self.__initialize_http_connection( url, timeout )
+
+        headers = {}
+        headers[C._HEADER_CONTENT_TYPE] = "application/json"
+        headers[C._HEADER_ACCEPT] = "text/plain"
+        if self.auth:
+            headers[C._HEADER_AUTHORIZATION] = self.auth
+
+        try:
+            # Post the request
+            path = "{url_path}{endpoint}".format( url_path = url.path,
+                                                  endpoint = endpoint )
+            http_conn.request( C._REQUEST_POST, path, request_body, headers )
+        except ssl.SSLError as ex:
+            msg = ("Unable to execute SSL handshake with '{}' due to: {}"
+                   "".format( url.url,
+                              GPUdbException.stringify_exception( ex ) ))
+            final_msg = self.__SSL_ERROR_MESSAGE_TEMPLATE.format(msg)
+            self.__log_debug( final_msg )
+            raise GPUdbUnauthorizedAccessException( final_msg )
+        except Exception as ex:
+            msg = ("Error posting to '{}' due to: {}"
+                   "".format( url.url,
+                              GPUdbException.stringify_exception( ex ) ) )
+            self.__log_debug( msg )
+            # TODO: In the Java API, this is an GPUdbExitException; decide what this should be here
+            raise GPUdbConnectionException( msg )
+        # end try
+
+        # Get the response
+        try:
+            response = http_conn.getresponse()
+        except Exception as ex: # some error occurred; return a message
+            msg = ( "No response received from {} due to {}"
+                    "".format( url.url,
+                               GPUdbException.stringify_exception( ex ) ) )
+            self.__log_debug( msg )
+            raise GPUdbConnectionException( msg )
+        # end try
+
+        # Read and decode the response, handling any error
+        try:
+            response_data = response.read()
+            response_time = response.getheader('x-request-time-secs', None)
+
+            # Check the HTTP status code and throw an exit exception as appropriate
+            status_code = response.status
+            response_msg = response.reason
+            if ( status_code == httplib.UNAUTHORIZED ):
+                # Unauthorized access gets a different exception
+                msg = ( "Unauthorized access: '{}'".format( response_msg ) )
+                self.__log_debug( msg )
+                raise GPUdbUnauthorizedAccessException( msg )
+            elif ( status_code in self.__http_response_triggering_failover ):
+                msg = ( "Could not connect to database at '{}' due to status "
+                        "code {}: {}".format( url.url, status_code, response_msg ) )
+                self.__log_debug( "Throwing EXIT exception; {}".format( msg ) )
+                raise GPUdbExitException( msg )
+            elif ( status_code == httplib.NOT_FOUND ):
+                msg = ( "Endpoint not found ({}) due to status "
+                        "code {}: {}".format( url.url, status_code,
+                                              response_msg ) )
+                self.__log_debug( "Throwing GPUdb exception; {}".format( msg ) )
+                raise GPUdbException( msg )
+            # end if
+
+            return str(response_data, "UTF-8")
+        except GPUdbUnauthorizedAccessException as ex:
+                # Any permission related problem should get propagated
+            raise
+        except (GPUdbConnectionException, GPUdbExitException) as ex:
+            # For special connection or exit errors, just pass them on
+            self.__log_debug("Caught conn/exit exception: {}".format( str(ex) ))
+            raise
+        except GPUdbException as ex:
+            # An end-of-file problem from the server is also a failover trigger
+            if C._DB_EOF_FROM_SERVER_ERROR_MESSAGE in str(ex):
+                msg = ( "Received failover triggering error when trying to "
+                        "connect to {}: {}"
+                        "".format( url.url, str(ex) ) )
+                self.__log_debug( "Throwing EXIT exception; {}".format( msg ) )
+                raise GPUdbExitException( msg )
+            else:
+                # All other errors are legitimate, and to be passed on to the
+                # user
+                self.__log_debug( "Throwing GPUdb exception; {}".format( str(ex) ) )
+                raise
+            # end if
+        except Exception as ex: # some error occurred; return a message
+            msg = ("Error reading response from {} for endpoint {}: {}"
+                   "".format( url.url, endpoint,
+                              GPUdbException.stringify_exception( ex ) ) )
+            # TODO: Or should this be an exit exception also??
+            self.__log_debug( "Throwing GPUdb exception; {}".format( msg ) )
+            raise GPUdbException( msg )
+        # end try
+
+    # end __submit_request_raw_json
+
+
     def __submit_request( self, endpoint, request_body,
                           url = None,
                           timeout = None,
                           get_req_cext = False,
                           get_rsp_cext = False,
                           request_schema  = None,
                           response_schema = None,
@@ -8040,14 +7911,181 @@
                                                   convert_to_attr_dict    = convert_to_attr_dict,
                                                   return_raw_response_too = return_raw_response_too )
 
                 return response
             except GPUdbUnauthorizedAccessException as ex:
                 # Any permission related problem should get propagated
                 raise
+            except (GPUdbConnectionException, GPUdbExitException, GPUdbDecodingException) as ex:
+                self.__log_debug( "Got exit-level exception when trying endpoint {} at {}: {}; switch URL..."
+                                  "".format( endpoint, str(url), str(ex ) ) )
+                # Handle our special exit exception
+                try:
+                    url = self.__switch_url( original_url, current_cluster_switch_count )
+                    self.__log_debug( "Switched to {}".format( str(url ) ) )
+                except GPUdbHAUnavailableException as ha_ex:
+                    # We've now tried all the HA clusters and circled back
+                    # Get the original cause to propagate to the user
+                    error_message  = ("{orig}; {new}".format( orig = str(ex),
+                                                              new  = str(ha_ex) ) )
+                    raise GPUdbException( error_message, True )
+                except GPUdbFailoverDisabledException as ha_ex:
+                    # Failover is disabled; return the original cause
+                    error_message  = ("{orig}; {new}".format( orig = str(ex),
+                                                              new  = str(ha_ex) ) )
+                    raise GPUdbException( error_message, True )
+                # end try
+            except GPUdbException as ex:
+                # Any other GPUdbException is a valid failure
+                self.__log_debug( "Got GPUdbException, so propagating: {}"
+                                  "".format( str(ex) ) )
+                raise
+            except Exception as ex:
+                orig_ex_str = GPUdbException.stringify_exception( ex )
+                self.__log_debug( "Got regular exception when trying endpoint {}"
+                                  " at {}: {}; switch URL..."
+                                  "".format( endpoint, str(url), orig_ex_str ) )
+                # And other random exceptions probably are also connection errors
+                try:
+                    url = self.__switch_url( original_url, current_cluster_switch_count )
+                    self.__log_debug( "Switched to {}".format( str(url) ) )
+                except GPUdbHAUnavailableException as ha_ex:
+                    # We've now tried all the HA clusters and circled back
+                    # Get the original cause to propagate to the user
+                    error_message  = ("{orig}; {new}".format( orig = orig_ex_str,
+                                                              new  = str(ha_ex) ) )
+                    raise GPUdbException( error_message, True )
+                except GPUdbFailoverDisabledException as ha_ex:
+                    # Failover is disabled; return the original cause
+                    error_message  = ("{orig}; {new}".format( orig = orig_ex_str,
+                                                              new  = str(ha_ex) ) )
+                    raise GPUdbException( error_message, True )
+                # end try
+            # end try
+        # end while
+    # end __submit_request
+
+
+    def __submit_request_json( self, endpoint, request_body,
+                          url = None,
+                          timeout = None,
+                          ):
+        """Submits an arbitrary request to the database server and returns
+        the response.  If a failover trigger is encountered, then either an
+        HA failover occurs (if an HA ring has been set up), or in the case
+        of a stand-alone cluster, a failover recovery is attempted (which
+        may continue indefinitely, based on relevant options set the by the
+        user).  In the case of a successful failover, the internally cached
+        URL will be updated to point to the new URL being used.
+
+        Parameters:
+            endpoint (str)
+                The GPUdb endpoint to send the request to; must be a string.
+                Must be provided.
+
+            request_body (str)
+                The request body.  Either a single JSON record or an array of JSON records
+
+            url (GPUdb.URL)
+                Optional argument.  If given, this URL would be used to connect
+                to the database.  If none given, then the current URL cached
+                internally would be used instead.  If given, then **no failover
+                will be attempted**.
+
+            timeout (int)
+                Optional argument.  If given, then the positive integer would be
+                used for the timeout for the request connection (in seconds).
+                If not given, then the currently configured timeout for this
+                GPUdb object would be used instead.
+
+        Returns:
+            The full JSON (str) response returned by the server. The part carrying relevant information
+            about the output of the operation is the 'data' object.
+        """
+        # Validate input arguments
+        if not isinstance( endpoint, (basestring, unicode) ):
+            msg = ("Argument 'endpoint' must be a string; given '{}'"
+                   "".format( str(type(endpoint)) ) )
+            self.__log_debug( msg )
+            raise GPUdbException( msg )
+        # end if
+
+        if request_body is None:
+            msg = ("Argument 'request_body' must be provided; given None" )
+            self.__log_debug( msg )
+            raise GPUdbException( msg )
+        # end if
+
+        if type(request_body) != str:
+            raise GPUdbException("'request_body' has to be either a single JSON record or an array of JSON records (as string)")
+
+        if timeout is None:
+            # Use the cached one
+            timeout = self.timeout
+        else:
+            # The given timeout must be a positive integer
+            try:
+                timeout = int( timeout )
+            except:
+                msg = ("Argument 'timeout' must be an integer value; "
+                       "given '{}'".format( str(type(timeout)) ) )
+                self.__log_debug( msg )
+                raise GPUdbException( msg )
+            # end inner if
+
+            if timeout < 0:
+                msg = ("Argument 'timeout' must be a positive integer value; "
+                       "given '{}'".format( timeout ) )
+                self.__log_debug( msg )
+                raise GPUdbException( msg )
+        # end if
+
+
+        # If any URL is given, then no failover would be attempted!  The easiest
+        # way to do this is to just call submit request raw, and propagate any
+        # exceptions that that method may throw
+        if url is not None:
+            # First validate it
+            if not isinstance( url, GPUdb.URL ):
+                msg = ("Argument 'url' must be a GPUdb.URL object; given '{}'"
+                       "".format( str(type(url)) ) )
+                self.__log_debug( msg )
+                raise GPUdbException( msg )
+            # end inner if
+
+            response = self.__submit_request_raw_json( url         = url,
+                                                      endpoint     = endpoint,
+                                                      request_body = request_body,
+                                                      timeout      = timeout,
+                                                    )
+            return response
+        # end if
+
+        # We need to send the request to the database server head node
+        url = self.get_url( stringified = False )
+        original_url = url
+
+        while True:
+            # We need a snapshot of the current state re: HA failover.  When
+            # multiple threads work on this object, we'll need to know how
+            # many times we've switched clusters *before* attempting another
+            # request submission.
+            current_cluster_switch_count = self.get_num_cluster_switches()
+
+            try:
+                response = self.__submit_request_json( endpoint,
+                                                  request_body,
+                                                  url = url,
+                                                  timeout = timeout,
+                                                 )
+
+                return response
+            except GPUdbUnauthorizedAccessException as ex:
+                # Any permission related problem should get propagated
+                raise
             except (GPUdbConnectionException, GPUdbExitException) as ex:
                 self.__log_debug( "Got EXIT or Connection exception when trying"
                                   " endpoint {} at {}: {}; switch URL..."
                                   "".format( endpoint, str(url), str(ex ) ) )
                 # Handle our special exit exception
                 try:
                     url = self.__switch_url( original_url, current_cluster_switch_count )
@@ -8088,16 +8126,15 @@
                     # Failover is disabled; return the original cause
                     error_message  = ("{orig}; {new}".format( orig = orig_ex_str,
                                                               new  = str(ha_ex) ) )
                     raise GPUdbException( error_message, True )
                 # end try
             # end try
         # end while
-    # end __submit_request
-
+    # end __submit_request_json
 
 
     def __submit_request_to_hm( self, endpoint, request_body,
                                 url = None,
                                 timeout = None,
                                 get_req_cext = False,
                                 get_rsp_cext = False,
@@ -8211,17 +8248,17 @@
                                                   get_req_cext = get_req_cext,
                                                   get_rsp_cext = get_rsp_cext,
                                                   convert_to_attr_dict    = convert_to_attr_dict,
                                                   return_raw_response_too = return_raw_response_too )
             return response
         # end if
 
-        # We need to send the request to the database server head node
+        # We need to send the request to the host manager
         hm_url = self.get_hm_url( stringified = False )
-        original_url = hm_url
+        original_hm_url = hm_url
 
         # We want to capture the original exception
         original_exception = None
 
         for i in range(0, self.__HOST_MANAGER_SUBMIT_REQUEST_RETRY_COUNT):
             # We need a snapshot of the current state re: HA failover.  When
             # multiple threads work on this object, we'll need to know how
@@ -8250,26 +8287,25 @@
                     # end inner if
                 # end if
 
                 return response
             except GPUdbUnauthorizedAccessException as ex:
                 # Any permission related problem should get propagated
                 raise
-            except GPUdbExitException as ex:
+            except (GPUdbConnectionException, GPUdbExitException, GPUdbDecodingException) as ex:
                 # Save the original exception for later use
                 if original_exception is None:
                     original_exception = GPUdbException( str(ex) )
                 # end if
 
-                self.__log_debug( "Got EXIT exception when trying endpoint {} "
-                                  "at {}: {}; switch URL..."
+                self.__log_debug( "Got exit-level exception when trying endpoint {} at {}: {}; switch URL..."
                                   "".format( endpoint, str(hm_url), str(ex ) ) )
                 # Handle our special exit exception
                 try:
-                    hm_url = self.__switch_hm_url( original_url, current_cluster_switch_count )
+                    hm_url = self.__switch_hm_url( original_hm_url, current_cluster_switch_count )
                     self.__log_debug( "Switched to {}".format( str( hm_url ) ) )
                 except GPUdbHAUnavailableException as ha_ex:
                     # We've now tried all the HA clusters and circled back
                     # Get the original cause to propagate to the user
                     error_message  = ("{orig}; {new}".format( orig = str(ex),
                                                               new  = str(ha_ex) ) )
                     self.__log_debug( error_message )
@@ -8287,15 +8323,15 @@
                     original_exception = ex
                 # end if
 
                 # The host manager can still be going even if the database is down
                 if ( C._DB_HM_OFFLINE_ERROR_MESSAGE in str(ex) ):
                     # Looks like the host manager is down
                     try:
-                        hm_url = self.__switch_hm_url( original_url, current_cluster_switch_count )
+                        hm_url = self.__switch_hm_url( original_hm_url, current_cluster_switch_count )
                         self.__log_debug( "Switched to {}".format( str( hm_url ) ) )
                     except GPUdbHAUnavailableException as ha_ex:
                         # We've now tried all the HA clusters and circled back
                         # Get the original cause to propagate to the user
                         error_message  = ("{orig}; {new}".format( orig = str(ex),
                                                                   new  = str(ha_ex) ) )
                         self.__log_debug( error_message )
@@ -8322,15 +8358,15 @@
                 # end if
 
                 self.__log_debug( "Got regular exception when trying endpoint {}"
                                   " at {}: {}; switch URL..."
                                   "".format( endpoint, str(hm_url), orig_ex_str ) )
                 # And other random exceptions probably are also connection errors
                 try:
-                    hm_url = self.__switch_hm_url( original_url, current_cluster_switch_count )
+                    hm_url = self.__switch_hm_url( original_hm_url, current_cluster_switch_count )
                     self.__log_debug( "Switched to {}".format( str(hm_url) ) )
                 except GPUdbHAUnavailableException as ha_ex:
                     # We've now tried all the HA clusters and circled back
                     # Get the original cause to propagate to the user
                     error_message  = ("{orig}; {new}".format( orig = orig_ex_str,
                                                               new  = str(ha_ex) ) )
                     self.__log_debug( error_message )
@@ -8435,18 +8471,27 @@
         try:
             if (url.protocol == 'HTTP'):
                 conn = httplib.HTTPConnection( host    = url.host,
                                                port    = url.port,
                                                timeout = timeout)
             elif (url.protocol == 'HTTPS'):
                 if self.skip_ssl_cert_verification:
-                    conn = httplib.HTTPSConnection( host    = url.host,
-                                                    port    = url.port,
-                                                    timeout = timeout,
-                                                    context = ssl._create_unverified_context() )
+                    if IS_PYTHON_3:
+                        ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS)
+                        ssl_context.verify_mode = ssl.CERT_NONE
+                        ssl_context.check_hostname = False
+                        conn = httplib.HTTPSConnection(host=url.host,
+                                                       port=url.port,
+                                                       timeout=timeout,
+                                                       context=ssl_context)
+                    else:
+                        conn = httplib.HTTPSConnection( host    = url.host,
+                                                        port    = url.port,
+                                                        timeout = timeout,
+                                                        context = ssl._create_unverified_context() )
                 else:
                     conn = httplib.HTTPSConnection( host    = url.host,
                                                     port    = url.port,
                                                     timeout = timeout)
         except Exception as ex:
             msg = ( "Error connecting to '{}' on port "
                     "'{}' due to (full url '{}'): {}"
@@ -8456,995 +8501,229 @@
             self.__log_debug( msg )
             raise GPUdbConnectionException( msg )
 
         return conn
     # end __initialize_http_connection
 
 
-    def __switch_url( self, old_url, num_cluster_switches ):
+    def __switch_url( self, old_url, old_num_cluster_switches ):
         """Switches the URL of the HA ring cluster.  Check if we've circled back to
         the old URL.  If we've circled back to it, then re-shuffle the list of
         indices so that the next time, we pick up HA clusters in a different random
         manner and throw an exception.
 
-        If a stand-alone cluster, try to recover from a potential N+1 event
-        (and switch the URL accordingly).
-
         This is not a thread-safe method.
 
         Parameters:
             old_url (GPUdb.URL)
-                The URL in use when the first switch was triggered.
-            num_cluster_switches (int)
-                The number of cluster switches that happened at the time of this
-                method call.
+                The head rank :class:`GPUdb.URL` in use at the time of the
+                failover that initiated this switch
+            old_num_cluster_switches (int)
+                The total number of cluster switches that have occurred up to
+                the moment before this thread's switch was initiated; this will
+                be used to determine whether another thread is already trying to
+                fail over to the next cluster and that this thread should stand
+                down
+        Returns:
+            The next cluster head rank :class:`GPUdb.URL` to try
         """
+        self.__log_debug( "Attempting to switch URLs, from: {}; original failing URL: {}"
+                          "".format( self.get_url(), str(old_url) ) )
+
         # The user may disable failover altogether
         if self.__disable_failover:
             self.__log_debug( "Failover is disabled; throwing exception" )
             raise GPUdbFailoverDisabledException( "Failover is disabled!" )
         # end if
 
-        self.__log_debug( "Switching from URL: {}; old url {}"
-                          "".format( self.get_url(), str(old_url) ) )
-
-        self.__log_debug( "Cluster info: {}"
-                          "".format( [ str(c) for c in self.__cluster_info ] ) )
-
         # If there is only one URL, then we can't switch URLs
         if ( self.__get_ha_ring_size() == 1 ):
-            self.__log_debug( "Ring size is 1")
-            raise GPUdbHAUnavailableException("Ring size set to 1; HA Unavailable")
-
-            # try:
-            #     # Try to find out the new cluster configuration and all
-            #     # the relevant URLs; may take a long while
-            #     curr_cluster_index = self.__get_curr_cluster_index()
-            #     self.__log_debug( "curr_cluster_index {}; attempting intra "
-            #                       "cluster failover..."
-            #                       "".format( curr_cluster_index ) )
-            #     if ( self.__do_intra_cluster_failover( curr_cluster_index ) ):
-            #         new_url = self.get_url( stringified = False )
-            #         self.__log_debug( "Intra cluster failover succeeded; "
-            #                           "switched to url: {}"
-            #                           "".format( str(new_url) ) )
-            #         # We have updated all the addresses; return the
-            #         # current/new head rank URL
-            #         return new_url
-            #     else:
-            #         self.__log_debug( "N+1 failover recovery failed; throwing error" )
-            #         msg = ( "N+1 failover at cluster with (possibly stale) "
-            #                 "rank-0 URL {} did not complete successfully "
-            #                 "( no backup clusters available to fall back on)"
-            #                 "".format( self.get_url() ) )
-            #         raise GPUdbHAUnavailableException( msg )
-            #     # end if
-            # except GPUdbHAUnavailableException as ex:
-            #     raise
-            # except GPUdbUnauthorizedAccessException as ex:
-            #     # Any permission related problem should get propagated
-            #     self.__log_debug( "Caught GPUdb UNAUTHORIZED exception: "
-            #                       "{}".format( str(ex) ) )
-            #     raise
-            # except GPUdbException as ex:
-            #     self.__log_debug( "N+1 failover recovery had exception: {}"
-            #                       "".format( str(ex) ) )
-            #     msg = ("N+1 failover at cluster with (possibly stale) "
-            #            "rank-0 URL {} did not complete successfully ("
-            #            "no backup clusters available to fall back on);"
-            #            " error: {}".format( self.get_url(), str(ex) ) )
-            #     raise GPUdbHAUnavailableException( msg )
-            # # end try
+            self.__log_debug( "Only one cluster in ring--no fail-over cluster available")
+            raise GPUdbHAUnavailableException("Only one cluster in ring; HA failover unavailable")
         # end if
 
-        # Get how many times we've switched clusters since the caller called
-        # this function
+        # Get how many more times other threads have switched clusters
+        # since the caller called this function.  If the situation is:
+        #
+        # count = 0             -> the calling thread is the first to get
+        #                          here; switch to the next cluster
+        # 0 < count < ring size -> another thread is either in the process
+        #                          of switching clusters or has switched to
+        #                          a working one; use the new current one
+        # count >= ring size    -> another thread has already tried all
+        #                          failover clusters; throw exception
         count_cluster_switches_since_invocation = (self.get_num_cluster_switches()
-                                                   - num_cluster_switches)
-        # Check if the client has switched clusters more than the number
-        # of clusters available in the HA ring
+                                                   - old_num_cluster_switches)
+
+        # Check if another thread has tried all the clusters in the HA ring
         ha_ring_size = self.__get_ha_ring_size()
         have_switched_clusters_across_the_ring = ( count_cluster_switches_since_invocation
                                                    >= ha_ring_size )
-        self.__log_debug( "Ring size is bigger than 1 ({});"
-                          " count_cluster_switches_since_invocation: {}"
-                          " have_switched_clusters_across_the_ring {}"
-                          "".format( ha_ring_size,
-                                     count_cluster_switches_since_invocation,
-                                     have_switched_clusters_across_the_ring ) )
+        self.__log_debug( "Cluster fail-over attempts across all threads vs. total clusters in ring: {} vs. {}"
+                          "".format( count_cluster_switches_since_invocation, ha_ring_size ) )
         if ( have_switched_clusters_across_the_ring ):
             all_head_rank_urls = [ str(cluster.head_rank_url) for cluster in self.__cluster_info ]
-            raise GPUdbHAUnavailableException(" (all GPUdb clusters with "
-                                              "head nodes {} returned error)"
+            raise GPUdbHAUnavailableException("Fail-over attempted as many times as clusters in the ring; URLs attempted: {}"
                                               "".format( all_head_rank_urls ) )
         # end if
 
         # Check if another thread beat us to switching the URL
         curr_url = self.get_url( stringified = False )
-        self.__log_debug( "Current url: {} oldurl {}"
-                          "".format( str(curr_url), str(old_url) ) )
         if ( (curr_url != old_url)
              and (count_cluster_switches_since_invocation > 0) ):
-            self.__log_debug( "Switched to url: {}".format( str(curr_url) ) )
-            # Another thread must have already switched the URL; nothing
-            # more to do
+            self.__log_debug( "Already failed over to URL: {}".format( str(curr_url) ) )
+            # Another thread must have already switched the URL; use the new
+            # current URL
             return curr_url
         # end if
 
-        # Re-check the health of this cluster and see if maybe an N+1
-        # event happened in the past (and therefore we have stale addresses).
-        # In such a case, update the addresses; do this as many times as
-        # as the client wants us to
-        for i in range(0, self.__cluster_reconnect_count):
-            if ( self.__update_cluster_addresses( self.__get_curr_cluster_index() ) ):
-                self.__log_debug( "Updated cluster address; switched to url: {}"
-                                  "".format( self.get_url() ) )
-                # We actually did update/change the cluster addresses, so just
-                # return the fresh head-rank URL so that we can re-try
-                # endpoint submission
-                return self.get_url( stringified = False )
-            # end if
-        # end loop
-
-        # Select the next cluster to use during this HA failover
+        # This thread is the first one here--select the next cluster to use
+        # during this HA failover
         self.__select_next_cluster()
 
-        # If we've circled back; shuffle the indices again so that future
+        # If we've circled back, shuffle the indices again so that future
         # requests go to a different randomly selected cluster, but also
         # let the caller know that we've circled back
         curr_url = self.get_url( stringified = False )
         if ( curr_url == old_url ):
-            self.__log_debug( "Curr url: {} is the same as the 'old url': {}"
-                              "; randomizing URLs and throwing exception"
-                              "".format( str(curr_url), str(old_url)) )
+            self.__log_debug( "Current URL is the same as the original URL: {}; randomizing URLs and throwing exception"
+                              "".format( str(old_url)) )
             # Re-shuffle and set the index counter to zero
             self.__randomize_clusters()
 
             # Let the user know that we've circled back
             all_head_rank_urls = [ str(cluster.head_rank_url) for cluster in self.__cluster_info ]
-            raise GPUdbHAUnavailableException( " (all GPUdb clusters with "
-                                               "head nodes {} returned error)"
-                                               "".format( all_head_rank_urls ) )
+            raise GPUdbHAUnavailableException("Circled back to original URL; no clusters available for fail-over among these: {}"
+                                              "".format( all_head_rank_urls ) )
         # end if
 
         # Haven't circled back to the old URL; so return the new one
-        self.__log_debug( "Switched to url: {} (NOT the same as the 'old url': "
-                          "{})".format( self.get_url(), str(old_url) ) )
+        self.__log_debug( "Switched to fail-over URL: {}".format( self.get_url() ) )
         return self.get_url( stringified = False )
     # end __switch_url
 
 
-    def __switch_hm_url( self, old_url, num_cluster_switches ):
+    def __switch_hm_url( self, old_url, old_num_cluster_switches ):
         """Switches the host manager URL of the HA ring cluster.  Check if we've
         circled back to the old URL.  If we've circled back to it, then
         re-shuffle the list of indices so that the next time, we pick up HA
         clusters in a different random manner and throw an exception.
 
-        If a stand-alone cluster, try to recover from a potential N+1 event
-        (and switch the URL accordingly).
-
         This is not a thread-safe method.
 
         Parameters:
             old_url (GPUdb.URL)
-                The host manager URL in use when the first switch was triggered.
-            num_cluster_switches (int)
-                The number of cluster switches that happened at the time of this
-                method call.
+                The host manager :class:`GPUdb.URL` in use at the time of the
+                failover that initiated this switch
+            old_num_cluster_switches (int)
+                The total number of cluster switches that have occurred up to
+                the moment before this thread's switch was initiated; this will
+                be used to determine whether another thread is already trying to
+                fail over to the next cluster and that this thread should stand
+                down
+        Returns:
+            The next host manager :class:`GPUdb.URL` to try
         """
+        self.__log_debug( "Attempting to switch Host Manager URLs, from: {}; original failing URL: {}"
+                          "".format( self.get_hm_url(), str(old_url) ) )
+
         # The user may disable failover altogether
         if self.__disable_failover:
             self.__log_debug( "Failover is disabled; throwing exception" )
             raise GPUdbFailoverDisabledException( "Failover is disabled!" )
         # end if
 
-        self.__log_debug( "Switching from URL: {}; old url {}"
-                          "".format( self.get_url(), str(old_url) ) )
-
         # If there is only one URL, then we can't switch URLs
         if ( self.__get_ha_ring_size() == 1 ):
-            self.__log_debug( "Ring size is 1")
-            raise GPUdbHAUnavailableException("Ring size set to 1; HA Unavailable")
-            # try:
-            #     # Try to find out the new cluster configuration and all
-            #     # the relevant URLs; may take a long while
-            #     curr_cluster_index = self.__get_curr_cluster_index()
-            #     self.__log_debug( "curr_cluster_index {}; attempting intra "
-            #                       "cluster failover..."
-            #                       "".format( curr_cluster_index ) )
-            #     if ( self.__do_intra_cluster_failover( curr_cluster_index ) ):
-            #         new_url = self.get_hm_url( stringified = False )
-            #         self.__log_debug( "Intra cluster failover succeeded; "
-            #                           "switched to url: {}"
-            #                           "".format( str(new_url) ) )
-            #         # We have updated all the addresses; return the
-            #         # current/new head rank URL
-            #         return new_url
-            #     else:
-            #         self.__log_debug( "N+1 failover recovery failed; throwing error" )
-            #         msg = ( "N+1 failover at cluster with (possibly stale) "
-            #                 "rank-0 URL {} did not complete successfully "
-            #                 "( no backup clusters available to fall back on)"
-            #                 "".format( self.get_hm_url() ) )
-            #         raise GPUdbHAUnavailableException( msg )
-            #     # end if
-            # except GPUdbHAUnavailableException as ex:
-            #     raise
-            # except GPUdbUnauthorizedAccessException as ex:
-            #     # Any permission related problem should get propagated
-            #     self.__log_debug( "Caught GPUdb UNAUTHORIZED exception: "
-            #                       "{}".format( str(ex) ) )
-            #     raise
-            # except GPUdbException as ex:
-            #     self.__log_debug( "N+1 failover recovery had exception: {}"
-            #                       "".format( str(ex) ) )
-            #     msg = ("N+1 failover at cluster with (possibly stale) "
-            #            "rank-0 URL {} did not complete successfully ("
-            #            "no backup clusters available to fall back on);"
-            #            " error: {}".format( self.get_hm_url(), str(ex) ) )
-            #     raise GPUdbHAUnavailableException( msg )
-            # # end try
+            self.__log_debug( "Only one cluster in ring--no fail-over cluster available")
+            raise GPUdbHAUnavailableException("Only one cluster in ring; HA failover unavailable")
         # end if
 
-        # Get how many times we've switched clusters since the caller called
-        # this function
+        # Get how many more times other threads have switched clusters
+        # since the caller called this function.  If the situation is:
+        #
+        # count = 0             -> the calling thread is the first to get
+        #                          here; switch to the next cluster
+        # 0 < count < ring size -> another thread is either in the process
+        #                          of switching clusters or has switched to
+        #                          a working one; use the new current one
+        # count >= ring size    -> another thread has already tried all
+        #                          failover clusters; throw exception
         count_cluster_switches_since_invocation = (self.get_num_cluster_switches()
-                                                   - num_cluster_switches)
-        # Check if the client has switched clusters more than the number
-        # of clusters available in the HA ring
+                                                   - old_num_cluster_switches)
+        # Check if another thread has tried all the clusters in the HA ring
         ha_ring_size = self.__get_ha_ring_size()
         have_switched_clusters_across_the_ring = ( count_cluster_switches_since_invocation
                                                    >= ha_ring_size )
-        self.__log_debug( "Ring size is bigger than 1 ({});"
-                          " count_cluster_switches_since_invocation: {}"
-                          " have_switched_clusters_across_the_ring {}"
-                          "".format( ha_ring_size,
-                                     count_cluster_switches_since_invocation,
-                                     have_switched_clusters_across_the_ring ) )
+        self.__log_debug( "Host Manager cluster fail-over attempts across all threads vs. total clusters in ring: {} vs. {}"
+                          "".format( count_cluster_switches_since_invocation, ha_ring_size ) )
         if ( have_switched_clusters_across_the_ring ):
             all_hm_urls = [ str(cluster.host_manager_url) for cluster in self.__cluster_info ]
-            raise GPUdbHAUnavailableException(" (all GPUdb clusters with "
-                                              "host manager {} returned error)"
+            raise GPUdbHAUnavailableException("Host Manager fail-over attempted as many times as clusters in the ring; URLs attempted: {}"
                                               "".format( all_hm_urls ) )
         # end if
 
         # Check if another thread beat us to switching the URL
         curr_url = self.get_hm_url( stringified = False )
-        self.__log_debug( "Current url: {} oldurl {}"
-                          "".format( str(curr_url), str(old_url) ) )
         if ( (curr_url != old_url)
              and (count_cluster_switches_since_invocation > 0) ):
-            self.__log_debug( "Switched to hm url: {}".format( str(curr_url) ) )
-            # Another thread must have already switched the URL; nothing
-            # more to do
+            self.__log_debug( "Already failed over to Host Manager URL: {}".format( str(curr_url) ) )
+            # Another thread must have already switched the URL; use the new
+            # current URL
             return curr_url
         # end if
 
-        # Re-check the health of this cluster and see if maybe an N+1
-        # event happened in the past (and therefore we have stale addresses).
-        # In such a case, update the addresses; do this as many times as
-        # as the client wants us to
-        for i in range(0, self.__cluster_reconnect_count):
-            if ( self.__update_cluster_addresses( self.__get_curr_cluster_index() ) ):
-                self.__log_debug( "Updated cluster address; switched to hm url: {}"
-                                  "".format( self.get_hm_url() ) )
-                # We actually did update/change the cluster addresses, so just
-                # return the fresh head-rank URL so that we can re-try
-                # endpoint submission
-                return self.get_hm_url( stringified = False )
-            # end if
-        # end loop
-
-        # Select the next cluster to use during this HA failover
+        # This thread is the first one here--select the next cluster to use
+        # during this HA failover
         self.__select_next_cluster()
 
-        # If we've circled back; shuffle the indices again so that future
+        # If we've circled back, shuffle the indices again so that future
         # requests go to a different randomly selected cluster, but also
         # let the caller know that we've circled back
         curr_url = self.get_hm_url( stringified = False )
         if ( curr_url == old_url ):
-            self.__log_debug( "Curr hm url: {} is the same as the 'old url': {}"
-                              "; randomizing URLs and throwing exception"
-                              "".format( str(curr_url), str(old_url)) )
+            self.__log_debug( "Current Host Manager URL is the same as the original URL: {}; randomizing URLs and throwing exception"
+                              "".format( str(old_url)) )
             # Re-shuffle and set the index counter to zero
             self.__randomize_clusters()
 
             # Let the user know that we've circled back
             all_hm_urls = [ str(cluster.host_manager_url) for cluster in self.__cluster_info ]
-            raise GPUdbHAUnavailableException( " (all GPUdb clusters with "
-                                               "host manager {} returned error)"
-                                               "".format( all_hm_urls ) )
+            raise GPUdbHAUnavailableException("Circled back to original URL; no clusters available for Host Manager fail-over among these: {}"
+                                              "".format( all_hm_urls ) )
         # end if
 
         # Haven't circled back to the old URL; so return the new one
-        self.__log_debug( "Switched to hm url: {} (NOT the same as the 'old url': "
-                          "{})".format( self.get_hm_url(), str(old_url) ) )
+        self.__log_debug( "Switched to Host Manager fail-over URL: {}".format( self.get_hm_url() ) )
         return self.get_hm_url( stringified = False )
     # end __switch_hm_url
 
 
 
-    def __are_all_ranks_ready( self, cluster_info ):
-        """Given a ClusterAddressInfo object, check that all the worker ranks are up
-        by pinging them individually.  Do this in an infinite loop.
-
-        **Caution**: Since this method runs in an infinite loop, be very careful
-                     of how to use it.  Ought to only be called from
-                     :meth:`GPUdb.__do_intra_cluster_failover`.
-        """
-        self.__log_debug( "Start checking all rank http servers' statuses..." )
-        # Generate the list of the given cluster's rank-0 URL and worker
-        # rank URLs
-        rank_urls = []
-        rank_urls.append( cluster_info.head_rank_url )
-        rank_urls.extend( cluster_info.worker_rank_urls )
-
-        # Sleep for a short amount of time (three seconds)
-        sleep_interval = 3
-
-        num_rank_check_attempt = 0
-
-        # Keep pinging all ranks until ALL have their http servers up
-        while True:
-            # Keep track of if any rank does no respond
-            was_some_rank_unresponsive = False
-            self.__log_debug( "Iteration #{}".format( num_rank_check_attempt ) )
-
-            # Check if all the ranks are up and listening
-            for url in rank_urls:
-                # Keep pinging this rank until it is up
-                keep_pinging_this_rank = True
-                while keep_pinging_this_rank:
-                    if self.is_kinetica_running( url ):
-                        # We'll move on to the next rank
-                        keep_pinging_this_rank = False
-                        self.__log_debug( "Rank http server @ {} did respond"
-                                          "".format( str(url) ) )
-                    else:
-                        self.__log_debug( "Rank http server @ {} did NOT respond"
-                                          "".format( str(url) ) )
-                        # Keep track of the fact that this rank's http server
-                        # did NOT respond
-                        was_some_rank_unresponsive = True
-
-                        # Sleep a few seconds before retrying; we will keep
-                        # pinging this rank until its http server comes up
-                        try:
-                            self.__log_debug( "Sleeping for {} seconds..."
-                                              "".format( sleep_interval ) )
-                            time.sleep( sleep_interval )
-                        except ( KeyboardInterrupt, SystemExit ) as ex:
-                            ex_str = GPUdbException.stringify_exception( ex )
-                            self.__log_debug( "Sleep interrupted; throwing "
-                                              "exception: {}"
-                                              "".format( ex_str ) )
-                            raise GPUdbException( "Intra-cluster failover "
-                                                  "interrupted: "
-                                                  "".format( ex_str ) )
-                        # end try
-                    # end if
-                # end inner while
-            # end for loop
-
-            # Success if all ranks responded
-            # Note: If during this iteration even one rank was unresponsive,
-            #       we will ping all the ranks once more to ensure everybody
-            #       is still up
-            if ( not was_some_rank_unresponsive ):
-                # Every single rank responded; the cluster is ready for business!
-                return True
-            # end
-
-            # Set values for the next iteration
-            num_rank_check_attempt += 1
-
-            # Put a blank line for ease of reading the log
-            self.__log_debug( "" )
-        # end while
-    # end __are_all_ranks_ready
-
-
-
-    def __are_all_ranks_ready_check_once( self, cluster_info ):
-        """Given a ClusterAddressInfo object, check whether all the worker ranks
-        are up by pinging them individually.  Do this just once and return
-        whether all the ranks are up or not.
-        """
-        self.__log_debug( "Start checking all rank http servers' statuses..." )
-        # Generate the list of the given cluster's rank-0 URL and worker
-        # rank URLs
-        rank_urls = []
-        rank_urls.append( cluster_info.head_rank_url )
-        rank_urls.extend( cluster_info.worker_rank_urls )
-
-        # Sleep for a short amount of time (three seconds)
-        sleep_interval = 3
-
-        was_some_rank_unresponsive = False
-
-        # Check if all the ranks are up and listening
-        for url in rank_urls:
-            if self.is_kinetica_running( url ):
-                # We'll move on to the next rank
-                self.__log_debug( "Rank http server @ {} did respond"
-                                  "".format( str(url) ) )
-            else:
-                self.__log_debug( "Rank http server @ {} did NOT respond"
-                                  "".format( str(url) ) )
-                # Keep track of the fact that this rank's http server
-                # did NOT respond
-                was_some_rank_unresponsive = True
-            # end if
-        # end for loop
-
-        # Success if all ranks responded
-        if ( not was_some_rank_unresponsive ):
-            # Every single rank responded; the cluster is ready for business!
-            return True
-        else:
-            return False
-        # end if
-    # end __are_all_ranks_ready_check_once
-
-
-
-    def __do_intra_cluster_failover( self, cluster_index ):
-        """
-        THIS METHOD IS NOT USED ANYMORE SINCE N+1 IS NOT HANDLED NOW.
-
-        For the given cluster in the HA ring, try to recover the new set of
-        addresses for all the ranks etc.  If N+1 failover is in progress, spin
-        and wait until it is in a good state and return the result.
-
-        This method is not thread safe.
-
-        Parameters:
-            cluster_index (int)
-                The index of the cluster whose addresses we need to update.
-
-        Returns:
-            True if the addresses were updated, False otherwise.
-        """
-        # We need to keep an eye on the clock
-        start_time = time.time()
-
-        # Retrieve info for the given cluster
-        self.__log_debug( "BEGIN cluster_index: {}".format( cluster_index ) )
-        curr_cluster_info = self.__cluster_info[ cluster_index ]
-        self.__log_debug( "Got cluster info: {}".format( str( curr_cluster_info ) ) )
-
-        curr_head_rank_url = curr_cluster_info.head_rank_url
-        self.__log_info( "Starting N+1 failover recovery for cluster "
-                         "with head rank {}; timeout is: {}"
-                         " seconds (None means infinite waiting)"
-                         "".format( str(curr_head_rank_url),
-                                    self.__intra_cluster_failover_timeout ) )
-
-        # Generate the list of the given cluster's rank-0 URL and worker
-        # rank URLs
-        rank_urls = []
-        rank_urls.append( curr_head_rank_url )
-        rank_urls.extend( curr_cluster_info.worker_rank_urls )
-
-        # We will sleep for 10 seconds when we need to wait and re-ping a cluster
-        sleep_interval_long = 10
-        # Sleep for a shorter amount of time in stage 2 (three seconds)
-        sleep_interval_short = 3
-
-        # Keep track of how many ranks are leaderless as we get system
-        # status from them
-        num_leaderless_ranks = 0
-
-        # Keep track of how many ranks do not respond
-        num_ranks_no_response = 0
-
-        # Keep track of how many ranks returned the current addresses; this
-        # will help us decide if it was merely a network glitch without any
-        # N+1 event happening.  In such a case, we would return the current
-        # addresses.
-        num_ranks_gave_same_address_as_current = 0
-
-        # The intra-cluster failover is done in two stages.
-        # Stage 1:
-        #
-        # The purpose of this stage is to find out from the known ranks
-        # what the state of the cluster is, and update the addresses if
-        # possible.
-        #
-        # * Query all the known ranks for the cluster status and the rank
-        #   addresses.
-        # * If any rank indicates that the cluster is in an irrecoverable
-        #   state, we return false to indicate failure.
-        # * If any rank is in a leaderless state, we skip that rank and go
-        #   to the next one.
-        # * With a good (running) status, if any rank gives a new (different)
-        #   set of rank addresses, we set those addresses and are done (return
-        #   true to indicate success).
-        # * With a good (running) status, if any rank gives addresses that are
-        #   the same as the current ones, we keep track of that and move on
-        #   to the next rank.
-        # * If a cluster operation is running, or the status is not "running",
-        #   we sleep and then query the same rank again.
-        # * We keep querying all the ranks in a loop until one of the following
-        #   conditions are met:
-        #   * Any rank is in the 'running' state and gives us a fresh set of
-        #     of addresses, we return success.
-        #   * All ranks are in the 'running' status and return the same
-        #     addresses as the current ones, we assume all is well and return
-        #     success.
-        #   * If all but one rank are leaderless, we assume we are in a bad
-        #     state and return failure.
-        #   * If we hit the timeout, we return failure.
-        #   * If all the ranks were unresponsive, we break out of stage 1
-        #     and proceed to stage 2.
-        #
-        # Stage 2:
-        #
-        # We are in this stage only if stage 1 failed in a very particular
-        # way: all ranks were unresponsive.  The reasons for which this can
-        # happen are as follows:
-        # 1) The cluster is fully down; we need to wait for the administrator
-        #    to turn it back on.
-        # 2) All the ranks were moved to other hosts.
-        # 3) There is a serious network issue, which also needs to be solved
-        #    by the administrator.
-        #
-        # In either case, we will ping all hosts to find out if rank-0 is
-        # running there.  This will happen infinitely, unless the user has
-        # set a timeout.  We will stop when we hit the timeout.  The logic
-        # for this stage is rather similar to stage 1 with some minor changes.
-        #
-        # The aim of this stage is to keep the client application going until
-        # either the cluster is fixed, or there is human intervention.  It is
-        # not good for client applications to stop working, specially if there
-        # are many long running applications.  We need to be resilient and keep
-        # on working, unless the client tells us to stop at a certain time via
-        # the intraClusterFailoverTimeout parameter.
-
-
-        self.__log_debug( "N+1 failover recovery stage 1" )
-        self.__log_debug( "-----------------------------" )
-
-        # Try to get the new addresses for shuffled ranks from the
-        # currently known ranks (whichever ones are still in place)
-        self.__log_debug( "Before for loop; will attempt until hitting "
-                          "the timeout or all ranks are unresponsive" )
-        i = 0
-        while True:
-            # Keep track of the iteration only for debug logging purpose
-            i += 1
-            self.__log_debug( "N+1 failover; stage 1 attempt #{}"
-                              "".format( i ) )
-
-            # Keep track of how many ranks say they are leaderless
-            num_leaderless_ranks = 0
-            # Keep track of how many ranks did not respond
-            num_ranks_no_response = 0
-            # Keep track of how many ranks gave the same addresses as the
-            # current ones
-            num_ranks_gave_same_address_as_current = 0
-
-            # Get information from the ranks (and try all of them if
-            # one/some don't have useful information)
-            for j in range(0, len(rank_urls)):
-                url = rank_urls[ j ]
-                self.__log_debug( "Attempt #{} rank-{}; URL: {}"
-                                  "".format( i, j, str(url) ) )
-
-                keep_using_this_rank = True
-                while ( keep_using_this_rank ):
-                    # If we've reached the timeout, just return
-                    curr_time = time.time()
-                    elapsed_time = (curr_time - start_time)
-                    self.__log_info( "N+1 failover recovery elapsed time so far: {}"
-                                     " seconds (and trying...)"
-                                     "".format( elapsed_time ) )
-                    if ( ( self.__intra_cluster_failover_timeout != 0 )
-                         and ( elapsed_time >= self.__intra_cluster_failover_timeout ) ):
-                        self.__log_debug( "Hit N+1 failover recovery timeout;"
-                                          " returning false" )
-                        return False
-                    # end if
-
-                    # Check the system status (if this rank is responding to requests,
-                    # keep pinging until status is back up to running)
-                    try:
-                        sys_status_info = self.__get_system_status_information( url )
-
-                        # Check if this rank is in an irrecoverable state
-                        if self.__is_cluster_irrecoverable( sys_status_info ):
-                            # The system is hosed; there is no hope of recovery!
-                            self.__log_debug( "System is irrecoverable; returning false" )
-                            return False
-                        # end if
-
-                        # Check if this rank has become leaderless (i.e. no
-                        # head host manager can be elected)
-                        if self.__is_rank_leaderless( sys_status_info ):
-                            self.__log_debug( "Rank is leaderless; skipping to next rank" )
-                            keep_using_this_rank = False
-                            num_leaderless_ranks += 1
-                            continue
-                        # end if
-
-                        # Check if the system is back up and running
-                        if self.__is_cluster_operation_running( sys_status_info ):
-                            self.__log_debug( "Cluster operation running; will sleep" )
-                            # Some sort of cluster operation is ongoing; wait for
-                            # a certain amount of time before retrying status check
-                            try:
-                                self.__log_debug( "Sleeping for {} seconds..."
-                                                  "".format( sleep_interval_long ) )
-                                time.sleep( sleep_interval_long )
-                            except ( KeyboardInterrupt, SystemExit ) as ex:
-                                ex_str = GPUdbException.stringify_exception( ex )
-                                self.__log_debug( "Sleep interrupted; throwing "
-                                                  "exception: {}"
-                                                  "".format( ex_str ) )
-                                raise GPUdbException( "Intra-cluster failover "
-                                                      "interrupted: {}"
-                                                      "".format( ex_str ) )
-                            # end try
-                        elif self.__is_system_running( sys_status_info = sys_status_info ):
-                            # System is back up; re-parse the URLs for this cluster
-                            self.__log_debug( "System is running; getting sys props" )
-
-                            # Get the latest system properties of the cluster, if
-                            # can't get it, skip to the next one
-                            sys_props = self.__get_system_properties( url )
-                            cluster_info_refreshed = self.__create_cluster_address_info( url,
-                                                                                         sys_props )
-
-                            self.__log_debug( "Refreshed addresses: {}"
-                                              "".format( str(cluster_info_refreshed) ) )
-                            self.__log_debug( "Current addresses:   {}"
-                                              "".format( str(curr_cluster_info) ) )
-                            # Check if the newly gotten addresses are the same as the old
-                            # ones
-                            if ( cluster_info_refreshed == curr_cluster_info ):
-                                # The addresses have remained the same; so we didn't
-                                # make any effective change
-                                self.__log_debug( "Refrehsed addresses the same "
-                                                  "as the old one at rank {}; "
-                                                  "either no N+1 failover "
-                                                  "happening or this rank "
-                                                  "has stale information; moving"
-                                                  " to the next rank, if any."
-                                                  "".format( str(url)) )
-                                keep_using_this_rank = False
-
-                                # Keep track of the fact that this rank gave
-                                # the same address as the current ones
-                                num_ranks_gave_same_address_as_current += 1
-                            else:
-                                # Replace the stale cluster info with the refreshed one
-                                self.__cluster_info.pop( cluster_index )
-                                self.__cluster_info.insert( cluster_index, cluster_info_refreshed )
-
-                                # We actually changed the addresses for this cluster;
-                                self.__log_debug( "Actually changed addresses; "
-                                                  "check for rank readiness...")
-                                self.__are_all_ranks_ready( cluster_info_refreshed )
-
-                                self.__log_debug( "Returning true; all ranks up and ready")
-                                return True
-                            # end inner if
-                        else:
-                            # For all other system statuses, we will retry (but
-                            # we'll wait a certain amount of time before that)
-                            try:
-                                self.__log_debug( "Sleeping for {} seconds..."
-                                                  "".format( sleep_interval_long ) )
-                                time.sleep( sleep_interval_long )
-                            except ( KeyboardInterrupt, SystemExit ) as ex:
-                                ex_str = GPUdbException.stringify_exception( ex )
-                                self.__log_debug( "Sleep interrupted; throwing exception" )
-                                raise GPUdbException( "Intra-cluster failover "
-                                                      "interrupted: {}"
-                                                      "".format( ex_str ) )
-                            # end try
-                        # end if
-                    except GPUdbUnauthorizedAccessException as ex:
-                        # Any permission related problem should get propagated
-                        self.__log_debug( "Caught GPUdb UNAUTHORIZED exception: "
-                                          "{}".format( str(ex) ) )
-                        raise
-                    except (GPUdbConnectionException, GPUdbExitException) as ex:
-                        self.__log_debug( "Caught GPUdb CONN/EXIT exception; "
-                                          "skipping to next rank: {}"
-                                          "".format( str(ex) ) )
-                        # Try the next URL, but keep track of the fact that this
-                        # could not be connected to
-                        keep_using_this_rank = False
-                        num_ranks_no_response += 1
-                    except GPUdbException as ex:
-                        self.__log_debug( "Caught GPUdb exception; skipping to "
-                                          "next rank: {}".format( str(ex) ) )
-                        # If error says system limited fatal then throw the exception;
-                        # in all other cases, try the next URL
-                        keep_using_this_rank = False
-                    # end try
-                # end while
-            # end inner for
-
-            # Check if ALL ranks are claiming that the addresses have not
-            # changed.  If so, then maybe we just had a network glitch or
-            # some other issue, and no real N+1 event is happening.  In
-            # that case, we will just return the current addresses as is.
-            if ( num_ranks_gave_same_address_as_current == len( rank_urls ) ):
-                # There is no need to change any addresses, nor is there any
-                # need to ping all the ranks
-                self.__log_debug( "All ranks claim the addresses are "
-                                  "the same; assuming no N+1 event "
-                                  "happening; returning true")
-                return True
-            # end if
-
-            # If we get to this spot, we've tried all known ranks and it looks
-            # like the cluster has failed to elect a leader; so, we quit trying.
-            # If all but one rank has said they're leaderless, it's good
-            # enough for us to give up.
-            if ( num_leaderless_ranks >= (len(rank_urls) - 1) ):
-                self.__log_debug( "All but one rank are leaderless; "
-                                  "returning false" )
-                return False # we're giving up
-            # end if
-
-            # Check if ALL ranks were UNresponsive.  If so, then break out
-            # of stage 1 and proceed to stage 2.
-            if ( num_ranks_no_response == len(rank_urls) ):
-                # There is no need to change any addresses, nor is there any
-                # need to ping all the ranks
-                self.__log_debug( "All ranks were UNresponsive; "
-                                  " ending stage 1 of N+1 failover "
-                                  "recovery")
-                break # out of the while loop
-            # end if
-
-            # Sleep a little before trying all the ranks again
-            try:
-                self.__log_debug( "Sleeping for {} seconds before trying all "
-                                  "the ranks again".format( sleep_interval_short ) )
-                time.sleep( sleep_interval_short )
-            except ( KeyboardInterrupt, SystemExit ) as ex:
-                ex_str = GPUdbException.stringify_exception( ex )
-                self.__log_debug( "Sleep interrupted; throwing exception" )
-                raise GPUdbException( "Intra-cluster failover interrupted: {}"
-                                      "".format( ex_str ) )
-            # end try
-        # end while (stage 1)
-
-        self.__log_debug( "N+1 failover recovery stage 1 done; at last attempt,"
-                          " # rank with no response: {}; # leaderless ranks: {}"
-                          "".format( num_ranks_no_response,
-                                     num_leaderless_ranks ) )
-
-        # If we get to this spot, then all the known ranks have failed to give
-        # us the current state of the cluster.  Now, we must try to find the new
-        # head rank, hoping it's up.  We will keep searching for it the user
-        # given timeout period.
-
-        self.__log_debug( "N+1 failover recovery stage 2" )
-        self.__log_debug( "-----------------------------" )
-
-        # Generate a list of possible head rank URLs (we know all the hosts
-        # on this machine
-        self.__log_debug( "Generating head rank urls for all hosts" )
-        head_rank_urls = []
-        for host_name in curr_cluster_info.host_names:
-            # Get the hostname (which *may* have the protocol attached)
-            self.__log_debug( "Got hostname: {}".format( host_name ) )
-            # Split the hostname to extract just the host part
-            split_hostname = host_name.split( "://" )
-            if ( len(split_hostname) > 1 ):
-                host = split_hostname[ 1 ]
-            else:
-                host = split_hostname[ 0 ]
-            # end
-            self.__log_debug( "Got host: {}".format( host ) )
-
-            # Create a URL with the same protocol, port, and file as the
-            # current head rank URL, but use the other hostname/IP address
-            try:
-                url_str = ( "{protocol}://{ip}:{port}{path}"
-                            "".format( protocol = curr_head_rank_url.protocol.lower(),
-                                       ip       = host,
-                                       port     = curr_head_rank_url.port,
-                                       path     = curr_head_rank_url.path ) )
-                url = GPUdb.URL( url_str )
-                self.__log_debug( "Created potential head rank url: {}"
-                                  "".format( str(url) ) )
-                # Won't be of any use if we don't add it to the list! :-)
-                head_rank_urls.append( url )
-            except GPUdbException as ex:
-                raise GPUdbException( "Could not form a valid URL for "
-                                      "possible head rank at host '{}': {}"
-                                      "".format( host, str(ex) ) )
-            # end try
-        # end for
-        self.__log_debug( "Head rank urls for all hosts: {}"
-                          "".format( [str(u) for u in head_rank_urls] ) )
-
-
-        # Iterate over the hosts to see where the new head rank has
-        # ended up.  Do this for the given timeout period
-        # Note: This for loop's body is very similar to the previous for loop's
-        #       body; but we need to keep them separate since they're not
-        #       exactly the same.
-        self.__log_debug( "Before starting checking for moved head rank" )
-        i = 0
-        stage2_iter_count = 0
-        while True:
-            # Keep track of the iteration only for debug logging purpose
-            self.__log_debug( "N+1 failover; stage 2 attempt #{}"
-                              "".format( stage2_iter_count ) )
-            stage2_iter_count += 1
-
-            # Get the URL for the head rank if it were to end up at the
-            # current host
-            potential_head_rank_url = head_rank_urls[ i ]
-            self.__log_debug( "URL: {}"
-                              "".format( str(potential_head_rank_url) ) )
-
-            keep_using_this_host = True
-            while ( keep_using_this_host ):
-                # If we've reached the timeout, just return
-                curr_time = time.time()
-                elapsed_time = (curr_time - start_time)
-                self.__log_info( "N+1 failover recovery elapsed time so far: {}"
-                                 " seconds (and trying...)"
-                                 "".format( elapsed_time ) )
-                if ( ( self.__intra_cluster_failover_timeout != 0 )
-                     and ( elapsed_time >= self.__intra_cluster_failover_timeout ) ):
-                    self.__log_debug( "Hit N+1 failover recovery timeout;"
-                                      " returning false" )
-                    return False
-                # end if
-
-                # Check the system status (if this rank is responding to requests,
-                # keep pinging until status is back up to running)
-                try:
-                    sys_status_info = self.__get_system_status_information( potential_head_rank_url )
-
-                    # Check if this rank is in an irrecoverable state
-                    if self.__is_cluster_irrecoverable( sys_status_info ):
-                        # The system is hosed; there is no hope of recovery!
-                        self.__log_debug( "Cluster is irrecoverable; returning false" )
-                        return False
-                    # end if
-
-                    # Note: There is no leaderless check here because it doesn't
-                    #       have any bearing on what we would do.
-
-                    # Check if the system is running
-                    if self.__is_cluster_operation_running( sys_status_info ):
-                        self.__log_debug( "Cluster operation running; will sleep" )
-                        # Some sort of cluster operation is ongoing; wait for
-                        # a certain amount of time before retrying status check
-                        try:
-                            self.__log_debug( "Sleeping for {} seconds..."
-                                              "".format( sleep_interval_long ) )
-                            time.sleep( sleep_interval_long )
-                        except ( KeyboardInterrupt, SystemExit ) as ex:
-                            ex_str = GPUdbException.stringify_exception( ex )
-                            self.__log_debug( "Sleep interrupted; throwing exception" )
-                            raise GPUdbException( "Intra-cluster failover "
-                                                  "interrupted: {}"
-                                                  "".format( ex_str ) )
-                        # end try
-                    elif self.__is_system_running( sys_status_info = sys_status_info ):
-                        # System is back up; re-parse the URLs for this cluster
-                        self.__log_debug( "System is running; getting sys props" )
-
-                        # Get the latest system properties of the cluster, if
-                        # can't get it, skip to the next one
-                        sys_props = self.__get_system_properties( potential_head_rank_url )
-                        cluster_info_refreshed = self.__create_cluster_address_info( potential_head_rank_url,
-                                                                                     sys_props )
-
-
-                        self.__log_debug( "Refreshed addresses: {}"
-                                          "".format( str(cluster_info_refreshed) ) )
-                        self.__log_debug( "Current addresses:   {}"
-                                          "".format( str(curr_cluster_info) ) )
-                        # Check if the newly gotten addresses are the same as the old
-                        # ones
-                        if ( cluster_info_refreshed == curr_cluster_info ):
-                            # The addresses have remained the same; so we didn't
-                            # make any effective change
-                            self.__log_debug( "Refrehsed addresses are the same"
-                                              " as the old ones at rank-0 {}; "
-                                              "possibly no N+1 failover actually"
-                                              " happened (maybe a network glitch?)"
-                                              "".format( str(potential_head_rank_url) ) )
-
-                            # Verify that the ranks are actually up and ready
-                            self.__log_debug( "Verifying that the ranks are ready..." )
-                            is_cluster_ready = self.__are_all_ranks_ready_check_once( cluster_info_refreshed )
-                            if is_cluster_ready:
-                                # No address change is necessary
-                                return True
-                            else:
-                                self.__log_debug( "Not all ranks are ready; will retry")
-                            # end if
-                        else:
-                            # Replace the stale cluster info with the refreshed one
-                            self.__log_debug( "Set the different addresses" )
-                            self.__cluster_info.pop( cluster_index )
-                            self.__cluster_info.insert( cluster_index, cluster_info_refreshed )
-
-                            # We actually changed the addresses for this cluster;
-                            self.__log_debug( "Actually changed addresses; check"
-                                              " for rank readiness...")
-                            self.__are_all_ranks_ready( cluster_info_refreshed )
-
-                            self.__log_debug( "Returning true; all ranks up and "
-                                              "ready")
-                            return True
-                        # end
-                    else:
-                        self.__log_debug( "System is NOT running; skip to the next host" )
-                        # The system is neither up nor is it running a cluster
-                        # operation; continue with the next known rank to see
-                        # what is going on.
-                        keep_using_this_host = False
-                    # end
-                except GPUdbUnauthorizedAccessException as ex:
-                    # Any permission related problem should get propagated
-                    self.__log_debug( "Caught GPUdb UNAUTHORIZED exception: "
-                                      "{}".format( str(ex) ) )
-                    raise
-                except GPUdbException as ex:
-                    self.__log_debug( "Caught GPUdb exception; skipping to next "
-                                      "host: {}".format( str(ex) ) )
-                    # If error says system limited fatal then throw the
-                    # exception; in all other cases, try the next URL
-                    keep_using_this_host = False
-                # end try
-
-                # Sleep a little before retrying
-                try:
-                    self.__log_debug( "Sleeping for {} seconds..."
-                                      "".format( sleep_interval_short ) )
-                    time.sleep( sleep_interval_short )
-                except ( KeyboardInterrupt, SystemExit ) as ex:
-                    ex_str = GPUdbException.stringify_exception( ex )
-                    self.__log_debug( "Sleep interrupted; throwing exception: "
-                                      "{}".format( ex_str ) )
-                    raise GPUdbException( "Intra-cluster failover interrupted: "
-                                          "{}".format( ex_str ) )
-                # end try
-            # end inner while
-
-            # Increment the counter to get the next rank-0 URL (need to loop
-            # over all the URLs)
-            i = ((i + 1) % len(head_rank_urls))
-        # end outer while
-    # end __do_intra_cluster_failover
-
-
     def __select_next_cluster( self ):
         """Select the next cluster based on the HA failover priority set by the
         user.  This is not a thread-safe method.
         """
+        curr_url_index_pointer = self.__get_curr_cluster_index_pointer()
+
+        self.__log_debug(
+            "Cluster switch #{} from cluster #{} ({}) to the next one in {}".format(
+            self.get_num_cluster_switches() + 1, curr_url_index_pointer + 1, self.get_url(), [str(url) for url in self.get_failover_urls()]
+        ))
+
         # Increment the index by one (mod url list length)
-        curr_url_iindex_pointer = self.__get_curr_cluster_index_pointer()
-        self.__log_debug( "Before incrementing 'currl url index pointer': {}"
-                          "".format( curr_url_iindex_pointer ) )
-        self.__set_curr_cluster_index_pointer( (curr_url_iindex_pointer + 1)
-                                               % self.__get_ha_ring_size() )
-        self.__log_debug( "After incrementing 'currl url index pointer': {}"
-                          "".format( self.__get_curr_cluster_index_pointer() ) )
+        self.__set_curr_cluster_index_pointer( (curr_url_index_pointer + 1) % self.__get_ha_ring_size() )
 
         # Keep a running count of how many times we had to switch clusters
-        self.__log_debug( "Before incrementing # cluster switches: {}"
-                          "".format(  self.get_num_cluster_switches() ) )
         self.__increment_num_cluster_switches()
-        self.__log_debug( "After incrementing # cluster switches: {}"
-                          "".format(  self.get_num_cluster_switches() ) )
+
+        self.__log_debug(
+            "Cluster switch #{} to cluster #{} ({})".format(
+            self.get_num_cluster_switches(), self.__get_curr_cluster_index_pointer() + 1, self.get_url()
+        ))
     # end __select_next_cluster
 
 
 
     def __post_and_get( self,
                         host, port, url_path, connection_type,
                         headers, body_data, endpoint ):
@@ -9868,14 +9147,59 @@
     # end encode_datum_cext
 
 
 
     # ------------- Convenience Functions ------------------------------------
 
 
+    @staticmethod
+    def valid_json(self, json_string):
+        """
+        Validates a JSON string by trying to parse it into a Python object
+        """
+        try:
+            json.loads(json_string)
+        except ValueError as err:
+            return False
+        return True
+
+    @staticmethod
+    def merge_dicts(self, *dict_args):
+        """
+        Given any number of dictionaries, shallow copy and merge into a new dict,
+        precedence goes to key-value pairs in latter dictionaries.
+        """
+        result = {}
+        for dictionary in dict_args:
+            result.update(dictionary)
+        return result
+
+
+    @staticmethod
+    def is_json_array(json_string):
+        trimmed = json_string.strip()
+        return trimmed.startswith("[") and trimmed.endswith("]")
+
+
+    @staticmethod
+    def is_json(json_string):
+        try:
+            obj = json.loads(json_string)
+            return isinstance( obj, list), ''
+        except ValueError as err:
+            return False, str(err)
+
+
+    @staticmethod
+    def convert_json_list_to_json_array(json_list):
+        if not isinstance(json_list, list):
+            raise ValueError("Input must be an object of type 'list'")
+        return "[{}]".format(",".join(json_list))
+
+
     def read_trigger_msg(self, encoded_datum):
         RSP_SCHEMA = self.gpudb_schemas[ "trigger_notification" ]["RSP_SCHEMA"]
         return self.__read_orig_datum_cext(RSP_SCHEMA, encoded_datum, C._ENCODING_BINARY)
 
 
 
     def logger(self, ranks, log_levels, options = {}):
@@ -9970,14 +9294,65 @@
         if (params):
             return self.insert_records(set_id, [object_data], None, params)
         else:
             return self.insert_records(set_id, [object_data], None, {"return_record_ids":"true"})
 
 
 
+    def insert_records_from_json(self, json_records, table_name, json_options = None, create_table_options = None, options = None ):
+        """Method to insert a single JSON record or an array of JSON records passed in as a string.
+
+        Parameters:
+            json_records (str) : Either a single JSON record or an array of JSON records (as string). Mandatory.
+            table_name (str) : The name of the table to insert into.
+            json_options (dict) : Only valid option is *validate* which could be True or False
+            create_table_options (dict) : Same options as the *create_table_options* in :meth:`GPUdb.insert_records_from_payload` endpoint
+            options (dict) : Same options as *options* in :meth:`GPUdb.insert_records_from_payload` endpoint
+
+        Example
+        ::
+
+            response = gpudb.insert_records_from_json(records, "test_insert_records_json", json_options={'validate': True}, create_table_options={'truncate_table': 'true'})
+            response_object = json.loads(response)
+            print(response_object['data']['count_inserted'])
+
+        .. seealso:: :meth:`GPUdb.insert_records_from_payload`
+
+        """
+
+        if json_records is None or type(json_records) != str:
+            raise GPUdbException("'json_records' must be a parameter of type 'str' and is mandatory")
+
+        if len(json_records) == 0:
+            raise GPUdbException("'json_records' must be a valid json and cannot be empty")
+
+        if table_name is None or type(table_name) != str or len(table_name) == 0:
+            raise GPUdbException("'table_name' must be a valid non-empty string")
+
+        if json_options and 'validate' in json_options and json_options['validate']:
+            if not GPUdb.valid_json( json_records):
+                raise GPUdbException("'json_records' passed in is not a valid JSON")
+
+        if create_table_options is None :
+            create_table_options = {}
+
+        if options is None or not options:
+            options = {'table_name': table_name}
+
+        # overwrite the value
+        options['table_name'] = table_name
+
+        combined_options = options if create_table_options is None or not create_table_options else GPUdb.merge_dicts( options, create_table_options )
+
+        query_string = urlencode(combined_options)
+        final_endpoint = "/insert/records/json?{}".format(query_string)
+
+        return self.__submit_request_json( final_endpoint, json_records )
+
+
     # Helper for dynamic schema responses
     def parse_dynamic_response(self, retobj, do_print=False, convert_nulls = True):
 
         if (retobj['status_info']['status'] == 'ERROR'):
             return retobj
 
         my_schema = schema.parse(retobj['response_schema_str'])
@@ -11288,17 +10663,17 @@
         self.gpudb_schemas[ name ] = { "REQ_SCHEMA_STR" : REQ_SCHEMA_STR,
                                        "RSP_SCHEMA_STR" : RSP_SCHEMA_STR,
                                        "REQ_SCHEMA" : REQ_SCHEMA,
                                        "RSP_SCHEMA" : RSP_SCHEMA,
                                        "ENDPOINT" : ENDPOINT }
         name = "/delete/files"
         REQ_SCHEMA_STR = """{"type":"record","name":"delete_files_request","fields":[{"name":"file_names","type":{"type":"array","items":"string"}},{"name":"options","type":{"type":"map","values":"string"}}]}"""
-        RSP_SCHEMA_STR = """{"type":"record","name":"delete_files_response","fields":[{"name":"info","type":{"type":"map","values":"string"}}]}"""
+        RSP_SCHEMA_STR = """{"type":"record","name":"delete_files_response","fields":[{"name":"file_names","type":{"type":"array","items":"string"}},{"name":"info","type":{"type":"map","values":"string"}}]}"""
         REQ_SCHEMA = Schema( "record", [("file_names", "array", [("string")]), ("options", "map", [("string")])] )
-        RSP_SCHEMA = Schema( "record", [("info", "map", [("string")])] )
+        RSP_SCHEMA = Schema( "record", [("file_names", "array", [("string")]), ("info", "map", [("string")])] )
         ENDPOINT = "/delete/files"
         self.gpudb_schemas[ name ] = { "REQ_SCHEMA_STR" : REQ_SCHEMA_STR,
                                        "RSP_SCHEMA_STR" : RSP_SCHEMA_STR,
                                        "REQ_SCHEMA" : REQ_SCHEMA,
                                        "RSP_SCHEMA" : RSP_SCHEMA,
                                        "ENDPOINT" : ENDPOINT }
         name = "/delete/graph"
@@ -12851,16 +12226,15 @@
                   * false
 
                   The default value is 'false'.
 
                 * **accepts_failover** --
                   If set to *true*, the host will accept processes (ranks,
                   graph server, etc.) in the event of a failover on another
-                  node in the cluster. See `Cluster Resilience
-                  <../../../../n_plus_1/>`__ for more information.
+                  node in the cluster.
                   Allowed values are:
 
                   * true
                   * false
 
                   The default value is 'false'.
 
@@ -13057,16 +12431,15 @@
                 Optional parameters.  The default value is an empty dict ( {}
                 ).
                 Allowed keys are:
 
                 * **accepts_failover** --
                   If set to *true*, the host will accept processes (ranks,
                   graph server, etc.) in the event of a failover on another
-                  node in the cluster. See `Cluster Resilience
-                  <../../../../n_plus_1/>`__ for more information.
+                  node in the cluster.
                   Allowed values are:
 
                   * true
                   * false
 
                   The default value is 'false'.
 
@@ -17593,14 +16966,24 @@
                   Maximum time (milliseconds) for each poll to get records from
                   kafka.  The default value is '0'.
 
                 * **kafka_wait_time** --
                   Maximum time (seconds) to buffer records received from kafka
                   before ingestion.  The default value is '30'.
 
+                * **egress_parquet_compression** --
+                  Parquet file compression type.
+                  Allowed values are:
+
+                  * uncompressed
+                  * snappy
+                  * gzip
+
+                  The default value is 'snappy'.
+
                 * **egress_single_file_max_size** --
                   Max file size (in MB) to allow saving to a single file. May
                   be overridden by target limitations.  The default value is
                   '100'.
 
                 * **max_concurrent_kernels** --
                   Sets the max_concurrent_kernels value of the conf.
@@ -22774,17 +22157,22 @@
     # begin delete_files
     def delete_files( self, file_names = None, options = {} ):
         """Deletes one or more files from `KiFS <../../../../tools/kifs/>`__.
 
         Parameters:
 
             file_names (list of str)
-                An array of names of files to be deleted.    The user can
-                provide a single element (which will be automatically promoted
-                to a list internally) or a list.
+                An array of names of files to be deleted. File paths may
+                contain wildcard characters after the KiFS directory delimeter.
+
+                Accepted wildcard characters are asterisk (*) to represent any
+                string of zero or more characters, and question mark (?) to
+                indicate a single character.    The user can provide a single
+                element (which will be automatically promoted to a list
+                internally) or a list.
 
             options (dict of str to str)
                 Optional parameters.  The default value is an empty dict ( {}
                 ).
                 Allowed keys are:
 
                 * **no_error_if_not_exists** --
@@ -22796,14 +22184,17 @@
                   * false
 
                   The default value is 'false'.
 
         Returns:
             A dict with the following entries--
 
+            file_names (list of str)
+                Names of the files deleted from KiFS
+
             info (dict of str to str)
                 Additional information.
         """
         file_names = file_names if isinstance( file_names, list ) else ( [] if (file_names is None) else [ file_names ] )
         assert isinstance( options, (dict)), "delete_files(): Argument 'options' must be (one) of type(s) '(dict)'; given %s" % type( options ).__name__
 
         obj = {}
@@ -23116,18 +22507,23 @@
     def download_files( self, file_names = None, read_offsets = None, read_lengths =
                         None, options = {} ):
         """Downloads one or more files from `KiFS <../../../../tools/kifs/>`__.
 
         Parameters:
 
             file_names (list of str)
-                An array of the file names to download from KiFS. The full path
-                must be provided.    The user can provide a single element
-                (which will be automatically promoted to a list internally) or
-                a list.
+                An array of the file names to download from KiFS. File paths
+                may contain wildcard characters after the KiFS directory
+                delimeter.
+
+                Accepted wildcard characters are asterisk (*) to represent any
+                string of zero or more characters, and question mark (?) to
+                indicate a single character.    The user can provide a single
+                element (which will be automatically promoted to a list
+                internally) or a list.
 
             read_offsets (list of longs)
                 An array of starting byte offsets from which to read each
                 respective file in input parameter *file_names*. Must either be
                 empty or the same length
                 as input parameter *file_names*. If empty, files are downloaded
                 in their entirety. If not
@@ -24419,14 +23815,26 @@
                   The default value is 'false'.
 
                 * **kinetica_header_delimiter** --
                   If a Kinetica proprietary header is included, then specify a
                   property separator. Different from column delimiter.  The
                   default value is '|'.
 
+                * **compression_type** --
+                  File compression type. Different file types support different
+                  compresion types. text: uncompressed. parquet: uncompressed,
+                  snappy, gzip.
+                  Allowed values are:
+
+                  * uncompressed
+                  * snappy
+                  * gzip
+
+                  The default value is 'snappy'.
+
                 * **single_file** --
                   Save records to a single file. This option may be ignored if
                   file
                   size exceeds internal file size limits (this limit will
                   differ on different targets).
                   Allowed values are:
 
@@ -32317,17 +31725,17 @@
 
                   * true
                   * false
 
                   The default value is 'false'.
 
                 * **limit** --
-                  When specified, limits the number of query results. The size
-                  of the nodes table will be limited by the *limit* value.  The
-                  default value is an empty dict ( {} ).
+                  When specified (>0), limits the number of query results. The
+                  size of the nodes table will be limited by the *limit* value.
+                  The default value is '0'.
 
                 * **output_wkt_path** --
                   If true then concatenated wkt line segments will be added as
                   the WKT column of the adjacency table.
                   Allowed values are:
 
                   * true
@@ -33293,15 +32701,20 @@
         Can be used for individual files, or to show all files in a given
         directory.
 
         Parameters:
 
             paths (list of str)
                 File paths to show. Each path can be a KiFS directory name, or
-                a full path to a KiFS file.    The user can provide a single
+                a full path to a KiFS file. File paths may contain wildcard
+                characters after the KiFS directory delimeter.
+
+                Accepted wildcard characters are asterisk (*) to represent any
+                string of zero or more characters, and question mark (?) to
+                indicate a single character.    The user can provide a single
                 element (which will be automatically promoted to a list
                 internally) or a list.
 
             options (dict of str to str)
                 Optional parameters.  The default value is an empty dict ( {}
                 ).
```

## gpudb/gpudb_multihead_io.py

```diff
@@ -2371,15 +2371,17 @@
     def __init__( self,
                   gpudb,
                   table_name,
                   record_type,
                   batch_size,
                   options = None,
                   workers = None,
-                  is_table_replicated = False ):
+                  is_table_replicated = False,
+                  json_ingestion = False
+                  ):
         """Initializes the GPUdbIngestor instance.
 
         Parameters:
             gpudb (:class:`gpudb.GPUdb`)
                 The client handle through which the ingestion process
                 is to be conducted.
             table_name (str)
@@ -2401,17 +2403,31 @@
                 Optional parameter.  A list of GPUdb worker rank addresses.
             is_table_replicated (bool)
                 Optional boolean flag indicating whether the table is
                 replicated; if True, then multi-head ingestion will not be used
                 (but the head node would be used for ingestion instead).  This
                 is due to GPUdb not supporting multi-head ingestion on
                 replicated tables.
+            json_ingestion (bool)
+                Indicates whether the `GPUdbIngestor` instance is being used to
+                insert JSON records or not. Default has been set to `False`. To
+                use `GPUdbIngestor` for inserting JSON records it must be set to
+                True.
+
+                `Example`
+
+                ::
+
+                    gpudb_ingestor = GPUdbIngestor(gpudb, table_name, record_type, ingestor_batch_size, ingestor_options, workers, json_ingestion=True)
+
         """
 
         # Validate input parameter 'gpudb'
+        self.json_ingestion = json_ingestion
+
         if not isinstance(gpudb, GPUdb):
             raise GPUdbException( "Parameter 'gpudb' must be of "
                                   "type GPUdb; given %s"
                                   % str( type( gpudb ) ) )
         # Validate input parameter 'table_name'
         if not isinstance(table_name, basestring):
             raise GPUdbException( "Parameter 'table_name' must be a"
@@ -2513,15 +2529,15 @@
 
         self.worker_queues = []
 
         # If no worker URLs are provided, get them from the server
         if not self.worker_list:
             # If the table is replicated, then we use only the head node
             self.worker_list = GPUdbWorkerList( self.gpudb,
-                                                use_head_node_only = self.is_table_replicated )
+                                                use_head_node_only = (self.is_table_replicated or self.gpudb.disable_auto_discovery))
 
         # Create worker queues per worker URL
         for worker in self.worker_list.get_worker_urls():
             # Handle removed ranks
             if not worker:
                 self.worker_queues.append( None )
                 continue
@@ -2544,15 +2560,16 @@
 
         # Very important to know if multi-head IO is actually enabled
         # at the server
         self.is_multihead_enabled = self.worker_list.is_multihead_enabled()
 
         # Flag for whether to use sharding or not
         self.use_head_node = ( (not self.is_multihead_enabled)
-                               or self.is_table_replicated )
+                               or self.is_table_replicated
+                               or self.gpudb.disable_auto_discovery )
 
         # Set the routing table, iff multi-head I/O is turned on
         # AND the table is not replicated
         self.routing_table = None
         self._shard_version = None
         self._shard_update_time = None
         if ( not self.use_head_node
@@ -2564,16 +2581,15 @@
                                          do_reconstruct_worker_queues = False )
         # end if
 
     # end GPUdbIngestor __init__
 
 
     def __force_failover( self, curr_url, curr_count_cluster_switches ):
-        """Force a high-availability cluster (inter-cluster) or ring-resiliency
-        (intra-cluster) failover over, as appropriate.  Check the health of the
+        """Force a high-availability cluster failover.  Check the health of the
         cluster (either head node only, or head node and worker ranks, based on
         the retriever configuration), and use it if healthy.  If no healthy
         cluster is found, then throw an error.  Otherwise, stop at the first
         healthy cluster.
 
         Parameters:
             curr_url (str or :class:`GPUdb.URL`)
@@ -2689,16 +2705,14 @@
                 # Also check if the db client has failed over to a different HA
                 # ring node
                 num_db_ha_switches = self.gpudb.get_num_cluster_switches()
                 if (count_cluster_switches == num_db_ha_switches):
                     self.__log_debug( "# cluster switches and shard versions "
                                       "the same" )
 
-                    # Still using the same cluster; but may have done an N+1
-                    # failover
                     if reconstruct_worker_queues:
                         # The caller needs to know if we ended up updating the
                         # queues
                         return self.__reconstruct_worker_queues_and_requeue_records()
                     # end if
 
                     # Not appropriate to update worker queues; then no change
@@ -3030,45 +3044,58 @@
             record = GPUdbRecord( self.record_type, record )
 
         if not isinstance( is_data_encoded, bool ):
             raise GPUdbException( "Input parameter 'is_data_encoded' must be "
                                   "boolean; given '{}'"
                                   "".format( str(type( is_data_encoded )) ) )
 
-        if not isinstance(record, (list, GPUdbRecord, collections.OrderedDict)):
+        record_is_json = None
+
+        if self.json_ingestion:
+            record_is_json = GPUdb.valid_json(record)
+            is_array = GPUdb.is_json_array(record)
+            if is_array:
+                raise GPUdbException("Input parameter 'record' cannot be a JSON array, must be a single JSON record")
+
+        if not isinstance(record, (list, GPUdbRecord, collections.OrderedDict)) and not record_is_json:
             raise GPUdbException( "Input parameter 'record' must be a GPUdbRecord or an "
-                                  "OrderedDict; given %s" % str(type(record)) )
+                                  "OrderedDict or a valid JSON; given %s" % str(type(record)) )
 
         if record_encoding.lower() not in ("json", "binary"):
             raise GPUdbException( "Input parameter 'record_encoding' must be "
                                   "one of ['json', 'binary']; given '%s'" % record_encoding )
 
         # Build the primary and/or shard key(s) for this record
         primary_key = None
         shard_key   = None
 
-        # Build the primary key
-        if self.primary_key_builder:
-            primary_key = self.primary_key_builder.build( record )
-
-        # Build the shard key
-        if self.shard_key_builder:
-            shard_key = self.shard_key_builder.build( record )
+        if not self.json_ingestion:
+            # Build the primary key
+            if self.primary_key_builder:
+                primary_key = self.primary_key_builder.build( record )
+
+            # Build the shard key
+            if self.shard_key_builder:
+                shard_key = self.shard_key_builder.build( record )
+        # end if not self.json_ingestion
 
         # Create a worker queue
         worker_queue = None
 
         # Get the index of the worker to be used
-        if self.use_head_node:
-            worker_index = 0
-        elif (not shard_key):
+        if self.json_ingestion:
             worker_index = random.randint( 0, (self.num_ranks - 1) )
         else:
-            # Use the routing table and the shard key to find the right worker
-            worker_index = shard_key.route( self.routing_table )
+            if self.use_head_node:
+                worker_index = 0
+            elif (not shard_key):
+                worker_index = random.randint( 0, (self.num_ranks - 1) )
+            else:
+                # Use the routing table and the shard key to find the right worker
+                worker_index = shard_key.route( self.routing_table )
         # end if-else
 
         # Log which rank this record is going to at the trace level.  Note that
         # since string interpolation takes a demonstrably large time (proved via
         # benchmarking), we need to first check if the log level is on.  That
         # way, we only create the interpolated string when it will be used.
         if self.__is_log_level_trace_enabled():
@@ -3086,16 +3113,15 @@
         worker_queue = self.worker_queues[ worker_index ]
 
         # Insert the record for the worker queue
         queue = worker_queue.insert( record, primary_key )
 
         # Flush, if necessary (when the worker queue returns a non-empty queue)
         if queue:
-            self.__flush( queue, worker_queue.get_url(),
-                          is_data_encoded = is_data_encoded )
+            self.__flush( queue, worker_queue.get_url(), is_data_encoded = is_data_encoded )
     # end insert_record
 
 
     def insert_records( self, records, record_encoding = "binary",
                         is_data_encoded = True ):
         """Queues a list of records for insertion into GPUdb. If any queue
         reaches the :meth:`batch size <get_batch_size>`, all records in that
@@ -3121,15 +3147,15 @@
 
             is_data_encoded (bool)
                 Indicates if the data has already been encoded (so that we don't
                 do double encoding).  Use ONLY if the data has already been
                 encoded.  Default is False.
 
         Raises:
-            :class:`InserttionException`
+            :class:`InsertionException`
                 If an error occurs while inserting
         """
         if not records:
             return # nothing to do!
 
         # If a single record is provided, promote it to a list
         records = records if isinstance( records, list ) else [ records ]
@@ -3176,77 +3202,83 @@
 
             is_data_encoded (bool)
                 Indicates if the data has already been encoded (so that we don't
                 do double encoding).  Use ONLY if the data has already been
                 encoded.  Default is False.
 
         Raises:
-            :class:`InserttionException`
+            :class:`InsertionException`
                 If an error occurs while inserting records.
         """
         for worker in self.worker_queues:
             if not worker:
                 continue # skipping empty workers
 
             queue = worker.flush()
-            # Actually insert the records
-            self.__flush( queue, worker.get_url(), forced_flush = forced_flush,
-                          is_data_encoded = is_data_encoded )
+
+            if len(queue) > 0:
+                # Actually insert the records
+                self.__flush( queue, worker.get_url(), forced_flush = forced_flush,
+                              is_data_encoded = is_data_encoded )
     # end flush
 
 
     def __insert_records_to_url( self, url = None, data = None,
                                  encoding = None, options = {} ):
         """Makes an /insert/records call to the given URL using the internally
         stored :class:`GPUdb` object.  The returns value is the same as
         :meth:`GPUdb.insert_records`.
         """
-        data = data if isinstance( data, list ) else ( [] if (data is None) else [ data ] )
-        assert isinstance( encoding, (basestring, type( None ))), "__insert_records_to_url(): Argument 'encoding' must be (one) of type(s) '(basestring, type( None ))'; given %s" % type( encoding ).__name__
-        assert isinstance( options, (dict)), "__insert_records_to_url(): Argument 'options' must be (one) of type(s) '(dict)'; given %s" % type( options ).__name__
+        response = None
 
-        obj = {}
-        obj['table_name'] = self.table_name
-        obj['list_encoding'] = encoding
-        obj['options'] = self.gpudb._GPUdb__sanitize_dicts( options )
-
-        record_type = self.record_type.record_type
-        if (encoding == 'binary'):
-            # Convert the objects to proper Records
-            use_object_array, data = _Util.convert_binary_data_to_cext_records( self.gpudb,
-                                                                                self.table_name,
-                                                                                data,
-                                                                                record_type )
+        if not self.json_ingestion:
+            data = data if isinstance( data, list ) else ( [] if (data is None) else [ data ] )
+            assert isinstance( encoding, (basestring, type( None ))), "__insert_records_to_url(): Argument 'encoding' must be (one) of type(s) '(basestring, type( None ))'; given %s" % type( encoding ).__name__
+            assert isinstance( options, (dict)), "__insert_records_to_url(): Argument 'options' must be (one) of type(s) '(dict)'; given %s" % type( options ).__name__
+
+            obj = {}
+            obj['table_name'] = self.table_name
+            obj['list_encoding'] = encoding
+            obj['options'] = self.gpudb._GPUdb__sanitize_dicts( options )
+
+            record_type = self.record_type.record_type
+            if (encoding == 'binary'):
+                # Convert the objects to proper Records
+                use_object_array, data = _Util.convert_binary_data_to_cext_records( self.gpudb,
+                                                                                    self.table_name,
+                                                                                    data,
+                                                                                    record_type )
+
+                if use_object_array:
+                    # First tuple element must be a RecordType or a Schema from the c-extension
+                    obj['list'] = (data[0].type, data) if data else ()
+                else: # use avro-encoded bytes for the data
+                    obj['list'] = data
 
-            if use_object_array:
-                # First tuple element must be a RecordType or a Schema from the c-extension
-                obj['list'] = (data[0].type, data) if data else ()
-            else: # use avro-encoded bytes for the data
-                obj['list'] = data
-
-            obj['list_str'] = []
-        else:
-            obj['list_str'] = data
-            obj['list'] = () # needs a tuple for the c-extension
-            use_object_array = True
-        # end if
+                obj['list_str'] = []
+            else:
+                obj['list_str'] = data
+                obj['list'] = () # needs a tuple for the c-extension
+                use_object_array = True
+            # end if
 
 
-        if use_object_array:
-            response = self.gpudb._GPUdb__submit_request( '/insert/records', obj,
-                                                          url = url,
-                                                          convert_to_attr_dict = True,
-                                                          get_req_cext = True )
+            if use_object_array:
+                response = self.gpudb._GPUdb__submit_request( '/insert/records', obj,
+                                                              url = url,
+                                                              convert_to_attr_dict = True,
+                                                              get_req_cext = True )
+            else:
+                response = self.gpudb._GPUdb__submit_request( '/insert/records', obj,
+                                                              url = url,
+                                                              convert_to_attr_dict = True )
         else:
-            response = self.gpudb._GPUdb__submit_request( '/insert/records', obj,
-                                                          url = url,
-                                                          convert_to_attr_dict = True )
-
-        if not response.is_ok():
-            return response
+            response = self.gpudb.insert_records_from_json(data, self.table_name,
+                                                      json_options={'validate': True},
+                                                      create_table_options=self.gpudb._GPUdb__sanitize_dicts( options ))
 
         return response
     # end __insert_records_to_url
 
 
     def __flush( self, queue, worker_url,
                  forced_flush = False,
@@ -3283,21 +3315,24 @@
 
         if record_encoding.lower() not in ("json", "binary"):
             raise GPUdbException( "Input parameter 'record_encoding' must be "
                                   "one of ['json', 'binary']; given '%s'" % record_encoding )
 
         retries = self.__retry_count
         try:
-            # Encode the data, if necessary
-            if not is_data_encoded:
-                encoded_data = self.__encode_data_for_insertion( queue,
-                                                                 record_encoding = record_encoding )
+            if not self.json_ingestion:
+                # Encode the data, if necessary
+                if not is_data_encoded:
+                    encoded_data = self.__encode_data_for_insertion( queue,
+                                                                     record_encoding = record_encoding )
+                else:
+                    # The data is already encoded
+                    encoded_data = queue
             else:
-                # The data is already encoded
-                encoded_data = queue
+                encoded_data = GPUdb.convert_json_list_to_json_array(queue)
             # end if
 
             while True:
                 # Save a snapshot of the state of the object pre-insertion attempt
                 insertion_attempt_timestamp = time.time()
                 curr_url = self.__curr_head_node_url
                 current_count_cluster_switches = self.num_cluster_switches
@@ -3315,31 +3350,44 @@
                     insert_rsp =  self.__insert_records_to_url( url = url,
                                                                 data = encoded_data,
                                                                 encoding = record_encoding,
                                                                 options = self.options )
 
                     # Throw an error if there was any problem (the exception
                     # blocks will handle retrying)
-                    if not insert_rsp.is_ok():
-                        raise GPUdbException( insert_rsp.get_error_msg() )
-                    # end if
+                    if not self.json_ingestion:
+                        if not insert_rsp.is_ok():
+                            raise GPUdbException( insert_rsp.get_error_msg() )
+                        # end if
+
+                        # Update the insert and update counts
+                        self.count_inserted += insert_rsp[ C._count_inserted ]
+                        self.count_updated  += insert_rsp[ C._count_updated  ]
+
+                        # Check if shard re-balancing is under way at the server; if so,
+                        # we need to update the shard mapping
+                        if ( (C._data_rerouted in insert_rsp.info)
+                             and (insert_rsp.info[ C._data_rerouted ] ==  C._true) ) :
 
-                    # Update the insert and update counts
-                    self.count_inserted += insert_rsp[ C._count_inserted ]
-                    self.count_updated  += insert_rsp[ C._count_updated  ]
-
-                    # Check if shard re-balancing is under way at the server; if so,
-                    # we need to update the shard mapping
-                    if ( (C._data_rerouted in insert_rsp.info)
-                         and (insert_rsp.info[ C._data_rerouted ] ==  C._true) ) :
+                            self.__update_worker_queues( current_count_cluster_switches )
+                        # end inner if
 
-                        self.__update_worker_queues( current_count_cluster_switches )
-                    # end inner if
+                        break # out of the while loop
+                    else:
+                        # response is in JSON format
+                        resp = json.loads(insert_rsp)
+                        if resp['status'].upper() == 'ERROR':
+                            error_message = resp['message']
+                            raise GPUdbException(error_message)
+
+                        if resp['status'].upper() == 'OK':
+                            self.count_inserted += resp['data'][C._count_inserted]
+                            self.count_updated += resp['data'][C._count_updated]
+                        break
 
-                    break # out of the while loop
                 except GPUdbUnauthorizedAccessException as ex:
                     # Any permission related problem should get propagated
                     self.__log_debug( "Caught GPUdb UNAUTHORIZED exception: "
                                       "{}".format( str(ex) ) )
                     raise
                 except GPUdbException as ex:
                     self.__log_debug( "Caught GPUdb (original) exception: {}"
@@ -3603,15 +3651,15 @@
 
         # Set up the worker queues
         # ------------------------
 
         # If no worker URLs are provided, get them from the server
         if not self.worker_list:
             self.worker_list = GPUdbWorkerList( self.gpudb,
-                                                use_head_node_only = self.is_table_replicated )
+                                                use_head_node_only = (self.is_table_replicated or self.gpudb.disable_auto_discovery))
 
         # Create worker queues per worker URL
         self.worker_queues = []
         for worker in self.worker_list.get_worker_urls():
             # Handle removed ranks
             if not worker:
                 self.worker_queues.append( None )
@@ -3633,15 +3681,16 @@
 
         # Very important to know if multi-head IO is actually enabled
         # at the server
         self.is_multihead_enabled = self.worker_list.is_multihead_enabled()
 
         # Flag for whether to use sharding or not
         self.use_head_node = ( (not self.is_multihead_enabled)
-                               or self.is_table_replicated )
+                               or self.is_table_replicated
+                               or self.gpudb.disable_auto_discovery )
 
         self.routing_table = None
         self._shard_version = None
         self._shard_update_time = None
         if ( self.is_multihead_enabled
              and self.shard_key_builder ):
 
@@ -3713,16 +3762,15 @@
 
     def __log_error( self, message ):
         self.log.error( "[RecordRetriever] {}".format( message ) )
     # end __log_error
 
 
     def __force_failover( self, old_url, curr_count_cluster_switches ):
-        """Force a high-availability cluster (inter-cluster) or ring-resiliency
-        (intra-cluster) failover over, as appropriate.  Check the health of the
+        """Force a high-availability cluster failover.  Check the health of the
         cluster (either head node only, or head node and worker ranks, based on
         the retriever configuration), and use it if healthy.  If no healthy cluster
         is found, then throw an error.  Otherwise, stop at the first healthy cluster.
 
         Parameters:
             old_url (str or GPUdb.URL)
                 The URL being used before forcing failover.
@@ -3851,16 +3899,14 @@
                 # Also check if the db client has failed over to a different HA
                 # ring node
                 num_cluster_switches = self.gpudb.get_num_cluster_switches()
                 if (count_cluster_switches == num_cluster_switches):
                     self.__log_debug( "# cluster switches and shard versions "
                                       "the same" )
 
-                    # Still using the same cluster; but may have done an N+1
-                    # failover
                     if reconstruct_worker_queues:
                         # The caller needs to know if we ended up updating the
                         # queues
                         return self.__reconstruct_worker_queues()
                     # end if
 
                     # Not appropriate to update worker queues; then no change
@@ -3984,15 +4030,15 @@
         assert isinstance( options, (dict)), "__get_records_from_url(): Argument 'options' must be (one) of type(s) '(dict)'; given %s" % type( options ).__name__
 
         # Create the payload
         obj = {}
         obj[ 'table_name'] = self.table_name
         obj[ 'offset'    ] = 0
         obj[ 'limit'     ] = self.gpudb.END_OF_SET
-        obj[ 'encoding'  ] = self.gpudb.encoding
+        obj[ 'encoding'  ] = self.gpudb.encoding.lower()
         obj[ 'options'   ] = self.gpudb._GPUdb__sanitize_dicts( options )
 
         response = self.gpudb._GPUdb__submit_request( '/get/records', obj,
                                                       url = url,
                                                       convert_to_attr_dict = True )
         return response
     # end __get_records_from_url
@@ -4021,15 +4067,15 @@
 
         Returns:
             The decoded records.
         """
         # Validate input parameter 'options'
         if not isinstance( options, (dict, type(None)) ):
             raise GPUdbException( "Parameter 'options' must be a"
-                                  "dicitonary, if given; given %s"
+                                  "dictionary, if given; given %s"
                                   % str( type( options ) ) )
 
 
         # If there is no shard key AND the column names aren't given, we can't do this
         if ( (not self.shard_key_builder)
              and (not isinstance( key_values, dict )) ):
             raise GPUdbException( "Cannot get key from unsharded table '%s'"
```

## Comparing `gpudb-7.1.9.1.dist-info/LICENSE` & `gpudb-7.1.9.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `gpudb-7.1.9.1.dist-info/RECORD` & `gpudb-7.1.9.2.dist-info/RECORD`

 * *Files 9% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 gpudb/__init__.py,sha256=MTfrxWZ7WJ5APTDA90SyH_MMwb9mygIcZsCkvkPZnUo,2276
-gpudb/gpudb.py,sha256=GC1nCPJF7Q-qkDjuyGUjmRWCnpV0olngGeZQj7d1a2k,2193478
-gpudb/gpudb_multihead_io.py,sha256=Sp5BIp527a8Dxp9809VqqBLWjdhT85Pm8axI3qAwCIE,178829
+gpudb/gpudb.py,sha256=s9rmVJghODM7QqEgIg-T8SHt-8dkySA33cbUDzRPel0,2157957
+gpudb/gpudb_multihead_io.py,sha256=akuQZ65VQqMV5xyH65Z-IX5Op_VhDoon4kzTulvDp-A,181209
 gpudb/gpudb_table_monitor.py,sha256=YxzWUzp2FVhLML0XPCGRLq6Vh2a2--8oozEEjjswJ9A,76983
-gpudb/protocol.cp39-win_amd64.pyd,sha256=9bSid8dSYjbJbVKpVlDz7ybM4KfDBVad2pkuvRuRP00,82432
+gpudb/protocol.cp39-win_amd64.pyd,sha256=Cf-nuYrBG_gPViFseyxgjjzre4Nd95KmtTxQ1c4s2E4,82432
 gpudb/packages/enum34.py,sha256=M1JeCFaL3T7ZWVlu_J4OeNuil8SGJ6cNgp9JzEwn8zE,33494
 gpudb/packages/kinetica_tabulate.py,sha256=RTcY5vDKdGwc4WvUyxXLX5dWDoUt2Gt50lVqUxfPf_0,40175
 gpudb/packages/ordereddict.py,sha256=EuzwpZHmxsQnWP2Xa2U5ApZU19YOijgQJCbYx20AvJ4,4413
 gpudb/packages/pymmh3.py,sha256=PkbkLgOTeERrTQZZ9Yrr1JwJHvA9vFbYMS3Tt553Uuc,14620
 gpudb/packages/avro/__init__.py,sha256=2jFb1uc5rCpZQIT6RwnttmJIRMFTg3Pyj4IIVv04L7w,543
 gpudb/packages/avro/avro_py2/__init__.py,sha256=rVcVRktu6_AcNX6Lh19DDds1oFoiZBrnDlSxtw31y8A,860
 gpudb/packages/avro/avro_py2/datafile.py,sha256=I1EswS5UbO_N1U-TMVDBscRFauZSg1ZL3CVMDufaPbM,12739
@@ -23,12 +23,12 @@
 gpudb/packages/avro/avro_py3/datafile.py,sha256=N5W1D8YU7YacVsEFi-1_PDTKWYWXcMa505pSfyRlNuU,15686
 gpudb/packages/avro/avro_py3/io.py,sha256=OZo_LWbeft4NGCelKx2RHukMV955LVJ7t3nVQBdf_Ws,34387
 gpudb/packages/avro/avro_py3/ipc.py,sha256=nPY5A-eo0t9hFHFGqqH4ksl0-ixFItUjE_hajJeUkKM,23138
 gpudb/packages/avro/avro_py3/protocol.py,sha256=9xGYO3_2pxZol6uTg7IVZq6YgXvfyjB6ZgCd1kzGjkY,12321
 gpudb/packages/avro/avro_py3/schema.py,sha256=rRvAXnY_y-CHOp9XPTr_1x2oDFvHW0yPWLBnVEMmHuA,36528
 gpudb/packages/avro/avro_py3/tool.py,sha256=tEHYWcbMgnficW8mIdBVR32VsFt9lV1mH37eqtMG51E,5773
 gpudb/packages/avro/avro_py3/txipc.py,sha256=S21zvYQkxUtW0AmakYIzYDQoUsL_gXnIJbph5xWdBnI,8269
-gpudb-7.1.9.1.dist-info/LICENSE,sha256=mO8T_HZHSioc8ubjlLCgRqkSEqu6jK7tXsBhPGxk6OI,1104
-gpudb-7.1.9.1.dist-info/METADATA,sha256=OJLHBicaCx7zh0e44gFf-T6c6tivnHCdLHDrw5QifR8,371
-gpudb-7.1.9.1.dist-info/WHEEL,sha256=jr7ubY0Lkz_yXH9FfFe9PTtLhGOsf62dZkNvTYrJINE,100
-gpudb-7.1.9.1.dist-info/top_level.txt,sha256=WXblkeM06dfvsdiZ156hrZR9H6m3fEQ6L0rUV7YqDAM,6
-gpudb-7.1.9.1.dist-info/RECORD,,
+gpudb-7.1.9.2.dist-info/LICENSE,sha256=mO8T_HZHSioc8ubjlLCgRqkSEqu6jK7tXsBhPGxk6OI,1104
+gpudb-7.1.9.2.dist-info/METADATA,sha256=Tvczn-6112ehCBGZXnYwZrtot2YVPhYRCtsoD6t64q4,371
+gpudb-7.1.9.2.dist-info/WHEEL,sha256=jr7ubY0Lkz_yXH9FfFe9PTtLhGOsf62dZkNvTYrJINE,100
+gpudb-7.1.9.2.dist-info/top_level.txt,sha256=WXblkeM06dfvsdiZ156hrZR9H6m3fEQ6L0rUV7YqDAM,6
+gpudb-7.1.9.2.dist-info/RECORD,,
```

